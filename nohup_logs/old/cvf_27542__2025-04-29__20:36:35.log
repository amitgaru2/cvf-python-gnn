Starting with 100 epochs and 256 batch size.
Total configs: 243.
Train Datasets: ['implicit_graph_n5']
Train Dataset size: 23,341
Max sequence length: 25
Spectral embedding dim: 1
CausalTransformer(
  (embedding): EmbeddingProjectionModel(
    (projection): Linear(in_features=5, out_features=8, bias=True)
  )
  (transformer): TransformerDecoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)
        )
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)
        )
        (linear1): Linear(in_features=8, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=8, bias=True)
        (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (output_head): Linear(in_features=8, out_features=1, bias=True)
)
Total parameters: 70,953
Training set | Epoch 1 | MSE Loss: 155.1446 | Time taken: 9.7875s
Training set | Epoch 2 | MSE Loss: 123.4792 | Time taken: 9.5461s
Training set | Epoch 3 | MSE Loss: 87.8232 | Time taken: 9.5459s
Training set | Epoch 4 | MSE Loss: 54.2089 | Time taken: 9.5515s
Training set | Epoch 5 | MSE Loss: 28.5422 | Time taken: 9.548s
Training set | Epoch 6 | MSE Loss: 12.897 | Time taken: 9.5381s
Training set | Epoch 7 | MSE Loss: 5.4936 | Time taken: 9.5485s
Training set | Epoch 8 | MSE Loss: 2.8357 | Time taken: 9.5431s
Training set | Epoch 9 | MSE Loss: 2.1129 | Time taken: 9.5489s
Training set | Epoch 10 | MSE Loss: 1.9611 | Time taken: 9.548s
Training set | Epoch 11 | MSE Loss: 1.9371 | Time taken: 9.5479s
Training set | Epoch 12 | MSE Loss: 1.9342 | Time taken: 9.549s
Training set | Epoch 13 | MSE Loss: 1.9332 | Time taken: 9.5488s
Training set | Epoch 14 | MSE Loss: 1.9335 | Time taken: 9.5488s
Training set | Epoch 15 | MSE Loss: 1.9343 | Time taken: 9.551s
Training set | Epoch 16 | MSE Loss: 1.9337 | Time taken: 9.553s
Training set | Epoch 17 | MSE Loss: 1.9342 | Time taken: 9.5459s
Training set | Epoch 18 | MSE Loss: 1.9338 | Time taken: 9.554s
Training set | Epoch 19 | MSE Loss: 1.935 | Time taken: 9.5509s
Training set | Epoch 20 | MSE Loss: 1.9362 | Time taken: 9.5578s
Training set | Epoch 21 | MSE Loss: 1.9363 | Time taken: 9.548s
Training set | Epoch 22 | MSE Loss: 1.9356 | Time taken: 9.5488s
Training set | Epoch 23 | MSE Loss: 1.9356 | Time taken: 9.5519s
Training set | Epoch 24 | MSE Loss: 1.9355 | Time taken: 9.5475s
Training set | Epoch 25 | MSE Loss: 1.9362 | Time taken: 9.5544s
Training set | Epoch 26 | MSE Loss: 1.9353 | Time taken: 9.5828s
Training set | Epoch 27 | MSE Loss: 1.9349 | Time taken: 9.553s
Training set | Epoch 28 | MSE Loss: 1.935 | Time taken: 9.5649s
Training set | Epoch 29 | MSE Loss: 1.9347 | Time taken: 9.5369s
Training set | Epoch 30 | MSE Loss: 1.9337 | Time taken: 9.5398s
Training set | Epoch 31 | MSE Loss: 1.9353 | Time taken: 9.5469s
Training set | Epoch 32 | MSE Loss: 1.9352 | Time taken: 9.5419s
Training set | Epoch 33 | MSE Loss: 1.9344 | Time taken: 9.5346s
Training set | Epoch 34 | MSE Loss: 1.934 | Time taken: 9.5431s
Training set | Epoch 35 | MSE Loss: 1.9334 | Time taken: 9.5447s
Training set | Epoch 36 | MSE Loss: 1.9341 | Time taken: 9.541s
Training set | Epoch 37 | MSE Loss: 1.9337 | Time taken: 9.5459s
Training set | Epoch 38 | MSE Loss: 1.9327 | Time taken: 9.5458s
Training set | Epoch 39 | MSE Loss: 1.9333 | Time taken: 9.542s
Training set | Epoch 40 | MSE Loss: 1.933 | Time taken: 9.5414s
Training set | Epoch 41 | MSE Loss: 1.9331 | Time taken: 9.5452s
Training set | Epoch 42 | MSE Loss: 1.9325 | Time taken: 9.5569s
Training set | Epoch 43 | MSE Loss: 1.9337 | Time taken: 9.547s
Training set | Epoch 44 | MSE Loss: 1.9332 | Time taken: 9.5379s
Training set | Epoch 45 | MSE Loss: 1.933 | Time taken: 9.4015s
Training set | Epoch 46 | MSE Loss: 1.9329 | Time taken: 9.3999s
Training set | Epoch 47 | MSE Loss: 1.9333 | Time taken: 9.3682s
Training set | Epoch 48 | MSE Loss: 1.9332 | Time taken: 9.3737s
Training set | Epoch 49 | MSE Loss: 1.9328 | Time taken: 9.3629s
Training set | Epoch 50 | MSE Loss: 1.9341 | Time taken: 9.3661s
Training set | Epoch 51 | MSE Loss: 1.9324 | Time taken: 9.3617s
Training set | Epoch 52 | MSE Loss: 1.9321 | Time taken: 9.3648s
Training set | Epoch 53 | MSE Loss: 1.9333 | Time taken: 9.3683s
Training set | Epoch 54 | MSE Loss: 1.9338 | Time taken: 9.3627s
Training set | Epoch 55 | MSE Loss: 1.9324 | Time taken: 9.3662s
Training set | Epoch 56 | MSE Loss: 1.9329 | Time taken: 9.3663s
Training set | Epoch 57 | MSE Loss: 1.9334 | Time taken: 9.3699s
Training set | Epoch 58 | MSE Loss: 1.9327 | Time taken: 9.3674s
Training set | Epoch 59 | MSE Loss: 1.9327 | Time taken: 9.3699s
Training set | Epoch 60 | MSE Loss: 1.9323 | Time taken: 9.3683s
Training set | Epoch 61 | MSE Loss: 1.9329 | Time taken: 9.3664s
Training set | Epoch 62 | MSE Loss: 1.9327 | Time taken: 9.3672s
Training set | Epoch 63 | MSE Loss: 1.9328 | Time taken: 9.365s
Training set | Epoch 64 | MSE Loss: 1.9327 | Time taken: 9.3689s
Training set | Epoch 65 | MSE Loss: 1.9327 | Time taken: 9.3683s
Training set | Epoch 66 | MSE Loss: 1.9341 | Time taken: 9.3735s
Training set | Epoch 67 | MSE Loss: 1.9336 | Time taken: 9.3695s
Training set | Epoch 68 | MSE Loss: 1.9327 | Time taken: 9.3671s
Training set | Epoch 69 | MSE Loss: 1.9328 | Time taken: 9.3665s
Training set | Epoch 70 | MSE Loss: 1.9325 | Time taken: 9.3685s
Training set | Epoch 71 | MSE Loss: 1.9343 | Time taken: 9.3653s
Training set | Epoch 72 | MSE Loss: 1.9332 | Time taken: 9.3666s
Training set | Epoch 73 | MSE Loss: 1.9329 | Time taken: 9.3689s
Training set | Epoch 74 | MSE Loss: 1.9336 | Time taken: 9.3679s
Training set | Epoch 75 | MSE Loss: 1.9342 | Time taken: 9.3681s
Training set | Epoch 76 | MSE Loss: 1.9324 | Time taken: 9.361s
Training set | Epoch 77 | MSE Loss: 1.9336 | Time taken: 9.3686s
Training set | Epoch 78 | MSE Loss: 1.9337 | Time taken: 9.365s
Training set | Epoch 79 | MSE Loss: 1.9333 | Time taken: 9.3677s
Training set | Epoch 80 | MSE Loss: 1.9334 | Time taken: 9.3665s
Training set | Epoch 81 | MSE Loss: 1.9339 | Time taken: 9.3655s
Training set | Epoch 82 | MSE Loss: 1.9337 | Time taken: 9.3716s
Training set | Epoch 83 | MSE Loss: 1.9345 | Time taken: 9.3701s
Training set | Epoch 84 | MSE Loss: 1.934 | Time taken: 9.3657s
Training set | Epoch 85 | MSE Loss: 1.9338 | Time taken: 9.3724s
Training set | Epoch 86 | MSE Loss: 1.9343 | Time taken: 9.3666s
Training set | Epoch 87 | MSE Loss: 1.9335 | Time taken: 9.3631s
Training set | Epoch 88 | MSE Loss: 1.9337 | Time taken: 9.3605s
Training set | Epoch 89 | MSE Loss: 1.9341 | Time taken: 9.3646s
Training set | Epoch 90 | MSE Loss: 1.9342 | Time taken: 9.3669s
Training set | Epoch 91 | MSE Loss: 1.933 | Time taken: 9.3667s
Training set | Epoch 92 | MSE Loss: 1.9343 | Time taken: 9.3696s
Training set | Epoch 93 | MSE Loss: 1.9343 | Time taken: 9.3655s
Training set | Epoch 94 | MSE Loss: 1.9348 | Time taken: 9.3718s
Training set | Epoch 95 | MSE Loss: 1.934 | Time taken: 9.3738s
Training set | Epoch 96 | MSE Loss: 1.9349 | Time taken: 9.3702s
Training set | Epoch 97 | MSE Loss: 1.9335 | Time taken: 9.374s
Training set | Epoch 98 | MSE Loss: 1.934 | Time taken: 9.375s
Training set | Epoch 99 | MSE Loss: 1.9338 | Time taken: 9.3647s
Training set | Epoch 100 | MSE Loss: 1.9336 | Time taken: 9.3718s


End Training | Total training time taken 945.0275s


Saving model trained_models/transformer_trained_at_2025_04_29_20_52.pt
Done!
