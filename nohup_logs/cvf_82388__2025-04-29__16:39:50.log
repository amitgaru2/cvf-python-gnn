Starting with 50 epochs and 1024 batch size.
Total configs: 2,187.
Train Datasets: ['implicit_graph_n7']
Train Dataset size: 77,076,249
Max sequence length: 47
Spectral embedding dim: 2
CausalTransformer(
  (embedding): EmbeddingProjectionModel(
    (projection): Linear(in_features=7, out_features=8, bias=True)
  )
  (transformer): TransformerDecoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)
        )
        (multihead_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)
        )
        (linear1): Linear(in_features=8, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=8, bias=True)
        (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((8,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (output_head): Linear(in_features=8, out_features=1, bias=True)
)
Total parameters: 70,969
Training set | Epoch 1 | MSE Loss: 1169.114 | Time taken: 50.4846s
Training set | Epoch 2 | MSE Loss: 1065.2605 | Time taken: 49.825s
Training set | Epoch 3 | MSE Loss: 923.143 | Time taken: 49.1694s
Training set | Epoch 4 | MSE Loss: 759.5574 | Time taken: 49.4212s
Training set | Epoch 5 | MSE Loss: 591.9857 | Time taken: 49.3108s
Training set | Epoch 6 | MSE Loss: 434.6596 | Time taken: 49.2529s
Training set | Epoch 7 | MSE Loss: 298.4655 | Time taken: 49.25s
Training set | Epoch 8 | MSE Loss: 189.9663 | Time taken: 49.3245s
Training set | Epoch 9 | MSE Loss: 111.1198 | Time taken: 49.3809s
Training set | Epoch 10 | MSE Loss: 59.2364 | Time taken: 49.3069s
Training set | Epoch 11 | MSE Loss: 28.5951 | Time taken: 49.2737s
Training set | Epoch 12 | MSE Loss: 12.4672 | Time taken: 49.276s
Training set | Epoch 13 | MSE Loss: 4.9023 | Time taken: 49.2166s
Training set | Epoch 14 | MSE Loss: 1.7575 | Time taken: 49.35s
Training set | Epoch 15 | MSE Loss: 0.5877 | Time taken: 49.531s
Training set | Epoch 16 | MSE Loss: 0.1984 | Time taken: 49.4493s
Training set | Epoch 17 | MSE Loss: 0.0914 | Time taken: 49.4963s
Training set | Epoch 18 | MSE Loss: 0.0749 | Time taken: 49.6286s
Training set | Epoch 19 | MSE Loss: 0.0527 | Time taken: 49.5292s
Training set | Epoch 20 | MSE Loss: 0.0363 | Time taken: 49.6044s
Training set | Epoch 21 | MSE Loss: 0.0404 | Time taken: 49.6052s
Training set | Epoch 22 | MSE Loss: 0.065 | Time taken: 49.4847s
Training set | Epoch 23 | MSE Loss: 0.0493 | Time taken: 49.023s
Training set | Epoch 24 | MSE Loss: 0.0314 | Time taken: 48.9102s
Training set | Epoch 25 | MSE Loss: 0.0448 | Time taken: 49.0814s
Training set | Epoch 26 | MSE Loss: 0.0404 | Time taken: 49.0404s
Training set | Epoch 27 | MSE Loss: 0.0448 | Time taken: 49.0777s
Training set | Epoch 28 | MSE Loss: 0.037 | Time taken: 49.037s
Training set | Epoch 29 | MSE Loss: 0.0426 | Time taken: 49.1895s
Training set | Epoch 30 | MSE Loss: 0.0583 | Time taken: 49.0442s
Training set | Epoch 31 | MSE Loss: 0.0583 | Time taken: 49.0777s
Training set | Epoch 32 | MSE Loss: 0.0371 | Time taken: 49.1902s
Training set | Epoch 33 | MSE Loss: 0.065 | Time taken: 49.1664s
Training set | Epoch 34 | MSE Loss: 0.0448 | Time taken: 49.164s
Training set | Epoch 35 | MSE Loss: 0.055 | Time taken: 49.1817s
Training set | Epoch 36 | MSE Loss: 0.0448 | Time taken: 49.0685s
Training set | Epoch 37 | MSE Loss: 0.0471 | Time taken: 49.1007s
Training set | Epoch 38 | MSE Loss: 0.0314 | Time taken: 49.2409s
Training set | Epoch 39 | MSE Loss: 0.0785 | Time taken: 49.1382s
Training set | Epoch 40 | MSE Loss: 0.0448 | Time taken: 49.0236s
Training set | Epoch 41 | MSE Loss: 0.0426 | Time taken: 49.1326s
Training set | Epoch 42 | MSE Loss: 0.0448 | Time taken: 48.9984s
Training set | Epoch 43 | MSE Loss: 0.0426 | Time taken: 49.209s
Training set | Epoch 44 | MSE Loss: 0.0303 | Time taken: 48.9892s
Training set | Epoch 45 | MSE Loss: 0.0695 | Time taken: 49.0785s
Training set | Epoch 46 | MSE Loss: 0.0381 | Time taken: 49.0562s
Training set | Epoch 47 | MSE Loss: 0.0471 | Time taken: 49.0516s
Training set | Epoch 48 | MSE Loss: 0.0404 | Time taken: 49.0843s
Training set | Epoch 49 | MSE Loss: 0.0448 | Time taken: 49.1318s
Training set | Epoch 50 | MSE Loss: 0.0247 | Time taken: 49.1227s


End Training | Total training time taken 2462.7969s


Saving model trained_models/transformer_trained_at_2025_04_29_17_22.pt
Done!
