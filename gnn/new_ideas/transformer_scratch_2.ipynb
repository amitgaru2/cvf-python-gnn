{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88188fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d711194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CVFConfigForTransformerDataset, CVFConfigForTransformerTestDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae159b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b361fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_local_mask(seq_len):\n",
    "    mask = torch.full((seq_len, seq_len), float(\"-inf\"))\n",
    "    for i in range(1, seq_len):\n",
    "        mask[i, i - 1] = 0  # Only allow attending to the previous token\n",
    "    mask[0, 0] = 0  # Optional: allow first token to attend to itself\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c8ed0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total configs: 243.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "dataset = CVFConfigForTransformerDataset(\n",
    "    device,\n",
    "    \"implicit_graph_n5\",\n",
    "    \"implicit_graph_n5_pt_adj_list.txt\",\n",
    "    \"implicit_graph_n5_config_rank_dataset.csv\",\n",
    "    D=5,\n",
    "    program=\"dijkstra\",\n",
    ")\n",
    "\n",
    "\n",
    "train_size = int(1.0 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e55591ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingProjectionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(EmbeddingProjectionModel, self).__init__()\n",
    "        self.projection = nn.Linear(input_dim, output_dim)  # Project Z to D\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the linear transformation to the input tensor\n",
    "        return self.projection(x)  # Output shape: (B, S, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad4c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = EmbeddingProjectionModel(vocab_size, hidden_dim)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=hidden_dim, nhead=4)\n",
    "        self.transformer = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        self.output_head = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, padding_mask):\n",
    "        # x: [B, T]\n",
    "        x = self.embedding(x).transpose(0, 1)  # [T, B, D]\n",
    "        mask = generate_local_mask(dataset.sequence_length).to(x.device)\n",
    "        # print(\"mask\", mask)\n",
    "        out = self.transformer(\n",
    "            x,\n",
    "            memory=torch.zeros(1, x.size(1), x.size(2)).to(x.device),\n",
    "            tgt_mask=mask,\n",
    "            tgt_key_padding_mask=padding_mask,\n",
    "        )\n",
    "        out = self.output_head(out.transpose(0, 1)).squeeze(-1)  # [B, T]\n",
    "        # return out, x\n",
    "        return out\n",
    "\n",
    "    def fit(self, num_epochs, dataloader):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            total_loss = 0\n",
    "            count = 0\n",
    "            for i, batch in enumerate(dataloader):\n",
    "                x = batch[0][0]\n",
    "                padding_mask = (~batch[0][1]).float()\n",
    "                y = batch[1]\n",
    "                out = self(x, padding_mask)\n",
    "                optimizer.zero_grad()\n",
    "                if (epoch + 1) % 5 == 0 and i == 0:\n",
    "                    print(\"Out\", out)\n",
    "                    print(\"y\", y)\n",
    "                loss = criterion(out, y)\n",
    "                total_loss += loss\n",
    "                count += 1\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            print(\n",
    "                \"Training set | Epoch %s | MSE Loss: %s\"\n",
    "                % (\n",
    "                    epoch + 1,\n",
    "                    round((total_loss / count).item(), 4),\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c670f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set | Epoch 1 | MSE Loss: 18.0051\n",
      "Training set | Epoch 2 | MSE Loss: 9.7928\n",
      "Training set | Epoch 3 | MSE Loss: 2.3927\n",
      "Training set | Epoch 4 | MSE Loss: 0.7498\n",
      "Out tensor([[11.3711, 12.0577, 12.0545,  ..., -0.9653, -0.9117, -1.1657],\n",
      "        [13.1296, 12.8617, 12.7973,  ..., -1.1473, -0.6973, -1.1529],\n",
      "        [12.0110, 12.0203, 10.4924,  ..., -0.9400, -1.0081, -1.1544],\n",
      "        ...,\n",
      "        [12.9280, 13.0854, 11.9656,  ..., -1.1800, -1.0282, -0.4209],\n",
      "        [12.2427, 11.3849, 13.1736,  ..., -0.9184, -1.0417, -0.9462],\n",
      "        [11.6279, 11.7566, 10.4550,  ..., -1.0684, -1.1555, -1.1640]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "y tensor([[12., 12., 11.,  ..., -1., -1., -1.],\n",
      "        [15., 13., 13.,  ..., -1., -1., -1.],\n",
      "        [12., 11., 10.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [15., 13., 13.,  ..., -1., -1., -1.],\n",
      "        [12., 12., 12.,  ..., -1., -1., -1.],\n",
      "        [12., 12., 10.,  ..., -1., -1., -1.]], device='cuda:0')\n",
      "Training set | Epoch 5 | MSE Loss: 0.4107\n",
      "Training set | Epoch 6 | MSE Loss: 0.2809\n",
      "Training set | Epoch 7 | MSE Loss: 0.2074\n",
      "Training set | Epoch 8 | MSE Loss: 0.164\n",
      "Training set | Epoch 9 | MSE Loss: 0.1308\n",
      "Out tensor([[13.7856, 12.7366, 13.1084,  ..., -1.0373, -0.8721, -0.4682],\n",
      "        [14.6765, 14.9334, 14.8155,  ..., -0.8976, -0.9607, -0.8696],\n",
      "        [12.1254, 12.4001, 10.6240,  ..., -0.9823, -1.0664, -0.8795],\n",
      "        ...,\n",
      "        [12.2884, 12.0595, 10.2067,  ..., -0.8492, -1.0165, -1.2368],\n",
      "        [14.6883, 14.2750, 11.1895,  ..., -1.0137, -0.7848, -1.1213],\n",
      "        [14.9376, 13.3968, 12.2521,  ..., -1.0032, -1.1728, -1.0851]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "y tensor([[14., 13., 13.,  ..., -1., -1., -1.],\n",
      "        [15., 15., 15.,  ..., -1., -1., -1.],\n",
      "        [12., 12., 10.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [12., 12., 10.,  ..., -1., -1., -1.],\n",
      "        [15., 14., 12.,  ..., -1., -1., -1.],\n",
      "        [15., 13., 12.,  ..., -1., -1., -1.]], device='cuda:0')\n",
      "Training set | Epoch 10 | MSE Loss: 0.1138\n",
      "Training set | Epoch 11 | MSE Loss: 0.0953\n",
      "Training set | Epoch 12 | MSE Loss: 0.0836\n",
      "Training set | Epoch 13 | MSE Loss: 0.074\n",
      "Training set | Epoch 14 | MSE Loss: 0.0667\n",
      "Out tensor([[11.9572, 12.3124, 10.1954,  ..., -1.0655, -1.0642, -1.0178],\n",
      "        [14.8993, 13.9943, 12.8853,  ..., -0.9388, -1.1739, -1.0180],\n",
      "        [14.6617, 11.8029, 10.6212,  ..., -0.8815, -1.0249, -1.1076],\n",
      "        ...,\n",
      "        [14.8876, 14.0353, 12.0105,  ..., -1.0227, -1.1013, -1.2262],\n",
      "        [14.2148, 13.0568, 13.0995,  ..., -1.0467, -1.1208, -0.9538],\n",
      "        [14.0742, 12.8871, 12.8181,  ..., -0.9081, -0.6952, -0.8148]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "y tensor([[12., 12., 10.,  ..., -1., -1., -1.],\n",
      "        [15., 14., 13.,  ..., -1., -1., -1.],\n",
      "        [15., 12., 11.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [15., 14., 12.,  ..., -1., -1., -1.],\n",
      "        [14., 13., 13.,  ..., -1., -1., -1.],\n",
      "        [14., 13., 13.,  ..., -1., -1., -1.]], device='cuda:0')\n",
      "Training set | Epoch 15 | MSE Loss: 0.0585\n",
      "Training set | Epoch 16 | MSE Loss: 0.0548\n",
      "Training set | Epoch 17 | MSE Loss: 0.0506\n",
      "Training set | Epoch 18 | MSE Loss: 0.0459\n",
      "Training set | Epoch 19 | MSE Loss: 0.042\n",
      "Out tensor([[12.1664, 11.9272, 10.3888,  ..., -1.0306, -0.8098, -1.0374],\n",
      "        [15.0304, 13.6573, 12.9370,  ..., -0.8743, -1.0363, -1.1163],\n",
      "        [11.8542, 11.6916, 10.9743,  ..., -0.9895, -1.0277, -1.0716],\n",
      "        ...,\n",
      "        [13.7101, 12.7031, 12.8181,  ..., -1.0175, -1.0845, -1.0261],\n",
      "        [13.8073, 12.9337, 13.1080,  ..., -0.9308, -1.0248, -1.0384],\n",
      "        [15.0860, 14.1343, 13.3201,  ..., -1.0779, -1.0480, -0.9737]],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "y tensor([[12., 12., 10.,  ..., -1., -1., -1.],\n",
      "        [15., 14., 13.,  ..., -1., -1., -1.],\n",
      "        [12., 12., 11.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [14., 13., 13.,  ..., -1., -1., -1.],\n",
      "        [14., 13., 13.,  ..., -1., -1., -1.],\n",
      "        [15., 14., 13.,  ..., -1., -1., -1.]], device='cuda:0')\n",
      "Training set | Epoch 20 | MSE Loss: 0.0395\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "vocab_size = dataset.D\n",
    "seq_len = dataset.sequence_length\n",
    "batch_size = 128\n",
    "hidden_dim = 32\n",
    "num_layers = 2\n",
    "num_epochs = 20\n",
    "\n",
    "\n",
    "# 3. Training Loop\n",
    "model = CausalTransformer(vocab_size, hidden_dim, num_layers).to(device)\n",
    "model.fit(num_epochs, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb804460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
