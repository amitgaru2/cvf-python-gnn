{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b5bd7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# from torch_geometric.nn.pool import global_mean_pool\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8bb8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CVFConfigForTransformerDataset, CVFConfigForTransformerTestDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a9da82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc52b674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7534561c8ad0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93faa8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc07cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pe = PositionalEncoding(10)\n",
    "# src = torch.randint(0, 5, (2, 2, 10))  # Random token IDs as input\n",
    "# pe(src).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d1f4a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total configs: 243.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "dataset = CVFConfigForTransformerDataset(\n",
    "    device,\n",
    "    \"implicit_graph_n5\",\n",
    "    \"implicit_graph_n5_pt_adj_list.txt\",\n",
    "    \"implicit_graph_n5_config_rank_dataset.csv\",\n",
    "    D=5,\n",
    "    program=\"dijkstra\",\n",
    ")\n",
    "\n",
    "\n",
    "train_size = int(1.0 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd5f7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingProjectionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(EmbeddingProjectionModel, self).__init__()\n",
    "        self.projection = nn.Linear(input_dim, output_dim)  # Project Z to D\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply the linear transformation to the input tensor\n",
    "        return self.projection(x)  # Output shape: (B, S, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a0f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model,\n",
    "        nhead,\n",
    "        num_encoder_layers,\n",
    "        dim_feedforward,\n",
    "        max_len=5000,\n",
    "    ):\n",
    "        super(SimpleTransformer, self).__init__()\n",
    "\n",
    "        # Word Embeddings Layer\n",
    "        self.embedding = EmbeddingProjectionModel(dataset.D, d_model)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "        # Transformer Encoder Layer\n",
    "        self.transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.transformer_encoder_layer, num_layers=num_encoder_layers\n",
    "        )\n",
    "\n",
    "        # Output Layer: For Language Modeling (next token prediction)\n",
    "        self.output_layer = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, src, attention_mask):\n",
    "        # src shape: (batch_size, seq_len)\n",
    "\n",
    "        # Embed the input\n",
    "        src = self.embedding(src)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        # Add positional encoding\n",
    "        src = self.positional_encoding(src)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        # Transform the input using Transformer Encoder\n",
    "        memory = self.transformer_encoder(\n",
    "            src.transpose(0, 1), src_key_padding_mask=attention_mask.transpose(0, 1)\n",
    "        )  # (seq_len, batch_size, d_model)\n",
    "\n",
    "        # Final output layer\n",
    "        output = self.output_layer(\n",
    "            memory.transpose(0, 1)\n",
    "        )  # (batch_size, seq_len, vocab_size)\n",
    "\n",
    "        # output = torch.relu(output)\n",
    "\n",
    "        # output = global_mean_pool(output, torch.zeros(output.size(1)).to(device).long())\n",
    "\n",
    "        return output\n",
    "\n",
    "    def fit(self, epochs, dataloader):\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001, weight_decay=0.00001)\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            self.train()\n",
    "            total_loss = 0\n",
    "            count = 0\n",
    "            for batch in dataloader:\n",
    "                x = batch[0][0]\n",
    "                attention_mask = batch[0][1]\n",
    "                y = batch[1]\n",
    "                out = self(x, attention_mask)\n",
    "                out = out.squeeze(-1)\n",
    "                out = out[attention_mask]\n",
    "                y = y[attention_mask]\n",
    "                # print(\"out\", out)\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(out, y)\n",
    "                total_loss += loss\n",
    "                count += 1\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            print(\n",
    "                \"Training set | Epoch %s | MSE Loss: %s\"\n",
    "                % (\n",
    "                    epoch,\n",
    "                    round((total_loss / count).item(), 4),\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c35d9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set | Epoch 1 | MSE Loss: 59.744\n",
      "Training set | Epoch 2 | MSE Loss: 42.9202\n",
      "Training set | Epoch 3 | MSE Loss: 29.3638\n",
      "Training set | Epoch 4 | MSE Loss: 22.0744\n",
      "Training set | Epoch 5 | MSE Loss: 16.2885\n",
      "Training set | Epoch 6 | MSE Loss: 9.7014\n",
      "Training set | Epoch 7 | MSE Loss: 7.4842\n",
      "Training set | Epoch 8 | MSE Loss: 5.8663\n",
      "Training set | Epoch 9 | MSE Loss: 4.7507\n",
      "Training set | Epoch 10 | MSE Loss: 4.1998\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "d_model = 8  # Embedding dimension (also used in Transformer)\n",
    "nhead = 2  # Number of attention heads\n",
    "num_encoder_layers = 6  # Number of layers in the Transformer Encoder\n",
    "dim_feedforward = 512  # Feedforward layer dimension\n",
    "max_len = 100  # Max sequence length\n",
    "N = dataset.D\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleTransformer(d_model, nhead, num_encoder_layers, dim_feedforward, max_len)\n",
    "model.to(device)\n",
    "\n",
    "model.fit(epochs, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d759d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total configs: 243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set | MSE loss: 66.3446 | Total matched: 45 out of 243 (Accuracy: 18.52%)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "f = open(\n",
    "    f\"test_results/test_result_trans.csv\",\n",
    "    \"w\",\n",
    "    newline=\"\",\n",
    ")\n",
    "csv_writer = csv.writer(f)\n",
    "csv_writer.writerow([\"Dataset\", \"Actual\", \"Predicted\"])\n",
    "\n",
    "\n",
    "test_dataset = CVFConfigForTransformerTestDataset(\n",
    "    device,\n",
    "    \"implicit_graph_n5\",\n",
    "    \"implicit_graph_n5_config_rank_dataset.csv\",\n",
    "    D=5,\n",
    "    program=\"dijkstra\",\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1024)\n",
    "\n",
    "    total_loss = 0\n",
    "    total_matched = 0\n",
    "    count = 0\n",
    "    total_seq_count = 0\n",
    "    for batch in test_dataloader:\n",
    "        x = batch[0][:, 0, :]\n",
    "        padd = torch.full((dataset.sequence_length - 1, dataset.D), -1).to(device)\n",
    "        padded_batches = [torch.cat([batch.unsqueeze(0), padd]) for batch in x]\n",
    "        x = torch.stack(padded_batches)\n",
    "        attention_mask = torch.full(\n",
    "            (x.shape[0], dataset.sequence_length), 0, dtype=torch.bool\n",
    "        ).to(device)\n",
    "        attention_mask[:, 0] = True\n",
    "        y = batch[1]\n",
    "        out = model(x, attention_mask)\n",
    "        # out = out.squeeze(-1)\n",
    "        out = out[attention_mask]\n",
    "        csv_writer.writerows(\n",
    "            (j.item(), k.item())\n",
    "            for (j, k) in zip(y.detach().cpu().numpy(), out.detach().cpu().numpy())\n",
    "        )\n",
    "        loss = criterion(out, y)\n",
    "        total_loss += loss\n",
    "        out = torch.round(out)\n",
    "        matched = (out == y).sum().item()\n",
    "        total_seq_count += out.numel()\n",
    "        total_matched += matched\n",
    "        count += 1\n",
    "\n",
    "    print(\n",
    "        f\"Test set | MSE loss: {round((total_loss / count).item(), 4)} | Total matched: {total_matched:,} out of {total_seq_count:,} (Accuracy: {round(total_matched / total_seq_count * 100, 2):,}%)\",\n",
    "    )\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c301e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
