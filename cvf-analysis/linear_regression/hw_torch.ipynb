{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbdc0758-5b74-4c1e-a881-beda63d6d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33525fea-838c-4815-aefd-4b2f83287d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd60757d-5807-4799-9582-6e9e235d700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import R2Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b4731b-d6eb-4da6-a4c0-fe593a2ecaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abc62117-77ed-4dfa-ad54-7fdb27406e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65.78331</td>\n",
       "      <td>112.9925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>71.51521</td>\n",
       "      <td>136.4873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>69.39874</td>\n",
       "      <td>153.0269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>68.21660</td>\n",
       "      <td>142.3354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>67.78781</td>\n",
       "      <td>144.2971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24996</td>\n",
       "      <td>69.50215</td>\n",
       "      <td>118.0312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24997</td>\n",
       "      <td>64.54826</td>\n",
       "      <td>120.1932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24998</td>\n",
       "      <td>64.69855</td>\n",
       "      <td>118.2655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24999</td>\n",
       "      <td>67.52918</td>\n",
       "      <td>132.2682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>25000</td>\n",
       "      <td>68.87761</td>\n",
       "      <td>124.8742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Index         X         y\n",
       "0          1  65.78331  112.9925\n",
       "1          2  71.51521  136.4873\n",
       "2          3  69.39874  153.0269\n",
       "3          4  68.21660  142.3354\n",
       "4          5  67.78781  144.2971\n",
       "...      ...       ...       ...\n",
       "24995  24996  69.50215  118.0312\n",
       "24996  24997  64.54826  120.1932\n",
       "24997  24998  64.69855  118.2655\n",
       "24998  24999  67.52918  132.2682\n",
       "24999  25000  68.87761  124.8742\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"SOCR-HeightWeight.csv\")\n",
    "df.rename(columns={\"Height(Inches)\": \"X\", \"Weight(Pounds)\": \"y\"}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4d8bf1-2ed2-4d1a-abf3-d5b5c1213213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[65.7833],\n",
       "        [71.5152],\n",
       "        [69.3987],\n",
       "        ...,\n",
       "        [64.6985],\n",
       "        [67.5292],\n",
       "        [68.8776]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[i] for i in df['X'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "065152d8-41cf-4ee5-82d9-bb73a8633a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data_utils.TensorDataset(torch.Tensor([[i] for i in df['X'].values]), torch.Tensor(df['y'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b905b6-7307-4b74-a067-cb03a21bc51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(training_data, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aca3c06-dcfa-43e1-b961-46b1fa4e032d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x777077daa720>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63dd7a73-213e-4da5-a07e-5a7fc6763b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34b8c12a-0dbd-4672-b69a-6dbf2c661c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8b9615-74d0-483d-a905-d7bd856104b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1534d09-79e2-4129-b235-63fafc6e7efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92c7476e-078c-446e-8f3b-8661eb40725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    predicted = torch.Tensor()\n",
    "    all_y = torch.Tensor()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            all_y = torch.cat((all_y, y))\n",
    "            # print(pred)\n",
    "            predicted = torch.cat((predicted, torch.flatten(pred)))\n",
    "            # correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    metric = R2Score()\n",
    "    # print(all_y)\n",
    "    # print(predicted)\n",
    "    metric.update(predicted, all_y)\n",
    "    print('accuracy:', metric.compute())\n",
    "    # print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1f4c3a4-f8f4-4c2b-8b7c-24e7a9eed974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5623.439453  [   10/25000]\n",
      "loss: 4184.526367  [ 1010/25000]\n",
      "loss: 3319.743164  [ 2010/25000]\n",
      "loss: 3099.956299  [ 3010/25000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amitgaru2/anaconda3/envs/cvf/lib/python3.12/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2540.309082  [ 4010/25000]\n",
      "loss: 1940.781616  [ 5010/25000]\n",
      "loss: 1366.541504  [ 6010/25000]\n",
      "loss: 1150.384888  [ 7010/25000]\n",
      "loss: 773.056274  [ 8010/25000]\n",
      "loss: 694.160767  [ 9010/25000]\n",
      "loss: 308.215881  [10010/25000]\n",
      "loss: 279.358612  [11010/25000]\n",
      "loss: 152.124939  [12010/25000]\n",
      "loss: 391.067627  [13010/25000]\n",
      "loss: 220.764252  [14010/25000]\n",
      "loss: 274.008667  [15010/25000]\n",
      "loss: 124.816643  [16010/25000]\n",
      "loss: 190.230759  [17010/25000]\n",
      "loss: 100.080429  [18010/25000]\n",
      "loss: 60.804913  [19010/25000]\n",
      "loss: 230.611328  [20010/25000]\n",
      "loss: 208.466873  [21010/25000]\n",
      "loss: 177.686523  [22010/25000]\n",
      "loss: 231.261841  [23010/25000]\n",
      "loss: 206.177658  [24010/25000]\n",
      "accuracy: tensor(0.2105)\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 207.572876  [   10/25000]\n",
      "loss: 129.258438  [ 1010/25000]\n",
      "loss: 247.230774  [ 2010/25000]\n",
      "loss: 136.167542  [ 3010/25000]\n",
      "loss: 131.769775  [ 4010/25000]\n",
      "loss: 344.206146  [ 5010/25000]\n",
      "loss: 83.138031  [ 6010/25000]\n",
      "loss: 137.111618  [ 7010/25000]\n",
      "loss: 119.563293  [ 8010/25000]\n",
      "loss: 133.925156  [ 9010/25000]\n",
      "loss: 19.290354  [10010/25000]\n",
      "loss: 108.158554  [11010/25000]\n",
      "loss: 119.722374  [12010/25000]\n",
      "loss: 206.418091  [13010/25000]\n",
      "loss: 99.281952  [14010/25000]\n",
      "loss: 269.266357  [15010/25000]\n",
      "loss: 114.788040  [16010/25000]\n",
      "loss: 195.216934  [17010/25000]\n",
      "loss: 83.741493  [18010/25000]\n",
      "loss: 54.269588  [19010/25000]\n",
      "loss: 206.505524  [20010/25000]\n",
      "loss: 195.372711  [21010/25000]\n",
      "loss: 178.896576  [22010/25000]\n",
      "loss: 236.557632  [23010/25000]\n",
      "loss: 206.053040  [24010/25000]\n",
      "accuracy: tensor(0.2113)\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 206.383942  [   10/25000]\n",
      "loss: 128.429947  [ 1010/25000]\n",
      "loss: 247.567261  [ 2010/25000]\n",
      "loss: 136.332642  [ 3010/25000]\n",
      "loss: 131.294220  [ 4010/25000]\n",
      "loss: 344.120239  [ 5010/25000]\n",
      "loss: 84.068146  [ 6010/25000]\n",
      "loss: 137.364258  [ 7010/25000]\n",
      "loss: 119.661652  [ 8010/25000]\n",
      "loss: 135.166962  [ 9010/25000]\n",
      "loss: 20.072920  [10010/25000]\n",
      "loss: 108.162262  [11010/25000]\n",
      "loss: 118.717636  [12010/25000]\n",
      "loss: 207.143326  [13010/25000]\n",
      "loss: 99.018066  [14010/25000]\n",
      "loss: 269.783295  [15010/25000]\n",
      "loss: 115.112022  [16010/25000]\n",
      "loss: 195.691254  [17010/25000]\n",
      "loss: 83.956024  [18010/25000]\n",
      "loss: 54.415161  [19010/25000]\n",
      "loss: 205.587036  [20010/25000]\n",
      "loss: 196.319916  [21010/25000]\n",
      "loss: 178.923477  [22010/25000]\n",
      "loss: 236.774918  [23010/25000]\n",
      "loss: 206.091599  [24010/25000]\n",
      "accuracy: tensor(0.2111)\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 206.652679  [   10/25000]\n",
      "loss: 128.146332  [ 1010/25000]\n",
      "loss: 247.585083  [ 2010/25000]\n",
      "loss: 137.109314  [ 3010/25000]\n",
      "loss: 131.542908  [ 4010/25000]\n",
      "loss: 344.187500  [ 5010/25000]\n",
      "loss: 84.355743  [ 6010/25000]\n",
      "loss: 137.442612  [ 7010/25000]\n",
      "loss: 119.694382  [ 8010/25000]\n",
      "loss: 135.740448  [ 9010/25000]\n",
      "loss: 20.347651  [10010/25000]\n",
      "loss: 108.115036  [11010/25000]\n",
      "loss: 118.466835  [12010/25000]\n",
      "loss: 207.039642  [13010/25000]\n",
      "loss: 98.896729  [14010/25000]\n",
      "loss: 270.003082  [15010/25000]\n",
      "loss: 115.225792  [16010/25000]\n",
      "loss: 195.766449  [17010/25000]\n",
      "loss: 84.058426  [18010/25000]\n",
      "loss: 54.407749  [19010/25000]\n",
      "loss: 205.414810  [20010/25000]\n",
      "loss: 196.532578  [21010/25000]\n",
      "loss: 178.920212  [22010/25000]\n",
      "loss: 236.742981  [23010/25000]\n",
      "loss: 206.091492  [24010/25000]\n",
      "accuracy: tensor(0.2111)\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 206.675873  [   10/25000]\n",
      "loss: 128.098328  [ 1010/25000]\n",
      "loss: 247.568726  [ 2010/25000]\n",
      "loss: 137.217331  [ 3010/25000]\n",
      "loss: 131.583130  [ 4010/25000]\n",
      "loss: 344.186157  [ 5010/25000]\n",
      "loss: 84.368195  [ 6010/25000]\n",
      "loss: 137.447449  [ 7010/25000]\n",
      "loss: 119.690529  [ 8010/25000]\n",
      "loss: 135.795364  [ 9010/25000]\n",
      "loss: 20.373930  [10010/25000]\n",
      "loss: 108.104317  [11010/25000]\n",
      "loss: 118.428497  [12010/25000]\n",
      "loss: 207.006393  [13010/25000]\n",
      "loss: 98.885231  [14010/25000]\n",
      "loss: 270.021240  [15010/25000]\n",
      "loss: 115.231697  [16010/25000]\n",
      "loss: 195.768845  [17010/25000]\n",
      "loss: 84.058380  [18010/25000]\n",
      "loss: 54.394199  [19010/25000]\n",
      "loss: 205.403732  [20010/25000]\n",
      "loss: 196.554810  [21010/25000]\n",
      "loss: 178.908997  [22010/25000]\n",
      "loss: 236.727966  [23010/25000]\n",
      "loss: 206.084457  [24010/25000]\n",
      "accuracy: tensor(0.2110)\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 206.673340  [   10/25000]\n",
      "loss: 128.083725  [ 1010/25000]\n",
      "loss: 247.552872  [ 2010/25000]\n",
      "loss: 137.222580  [ 3010/25000]\n",
      "loss: 131.576447  [ 4010/25000]\n",
      "loss: 344.172241  [ 5010/25000]\n",
      "loss: 84.356689  [ 6010/25000]\n",
      "loss: 137.440369  [ 7010/25000]\n",
      "loss: 119.682243  [ 8010/25000]\n",
      "loss: 135.785202  [ 9010/25000]\n",
      "loss: 20.373159  [10010/25000]\n",
      "loss: 108.096924  [11010/25000]\n",
      "loss: 118.410049  [12010/25000]\n",
      "loss: 206.986206  [13010/25000]\n",
      "loss: 98.884140  [14010/25000]\n",
      "loss: 270.016998  [15010/25000]\n",
      "loss: 115.226166  [16010/25000]\n",
      "loss: 195.764633  [17010/25000]\n",
      "loss: 84.047478  [18010/25000]\n",
      "loss: 54.380844  [19010/25000]\n",
      "loss: 205.406204  [20010/25000]\n",
      "loss: 196.559692  [21010/25000]\n",
      "loss: 178.897034  [22010/25000]\n",
      "loss: 236.715729  [23010/25000]\n",
      "loss: 206.076843  [24010/25000]\n",
      "accuracy: tensor(0.2109)\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 206.668900  [   10/25000]\n",
      "loss: 128.071915  [ 1010/25000]\n",
      "loss: 247.537064  [ 2010/25000]\n",
      "loss: 137.219162  [ 3010/25000]\n",
      "loss: 131.565231  [ 4010/25000]\n",
      "loss: 344.157349  [ 5010/25000]\n",
      "loss: 84.343185  [ 6010/25000]\n",
      "loss: 137.432312  [ 7010/25000]\n",
      "loss: 119.673538  [ 8010/25000]\n",
      "loss: 135.769485  [ 9010/25000]\n",
      "loss: 20.370274  [10010/25000]\n",
      "loss: 108.089798  [11010/25000]\n",
      "loss: 118.393585  [12010/25000]\n",
      "loss: 206.967407  [13010/25000]\n",
      "loss: 98.883919  [14010/25000]\n",
      "loss: 270.010712  [15010/25000]\n",
      "loss: 115.219589  [16010/25000]\n",
      "loss: 195.759964  [17010/25000]\n",
      "loss: 84.035637  [18010/25000]\n",
      "loss: 54.367477  [19010/25000]\n",
      "loss: 205.410202  [20010/25000]\n",
      "loss: 196.562775  [21010/25000]\n",
      "loss: 178.885056  [22010/25000]\n",
      "loss: 236.703354  [23010/25000]\n",
      "loss: 206.069122  [24010/25000]\n",
      "accuracy: tensor(0.2109)\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 206.664001  [   10/25000]\n",
      "loss: 128.060410  [ 1010/25000]\n",
      "loss: 247.521332  [ 2010/25000]\n",
      "loss: 137.215103  [ 3010/25000]\n",
      "loss: 131.554123  [ 4010/25000]\n",
      "loss: 344.142273  [ 5010/25000]\n",
      "loss: 84.329437  [ 6010/25000]\n",
      "loss: 137.423813  [ 7010/25000]\n",
      "loss: 119.664864  [ 8010/25000]\n",
      "loss: 135.753616  [ 9010/25000]\n",
      "loss: 20.367092  [10010/25000]\n",
      "loss: 108.082741  [11010/25000]\n",
      "loss: 118.377052  [12010/25000]\n",
      "loss: 206.948868  [13010/25000]\n",
      "loss: 98.883957  [14010/25000]\n",
      "loss: 270.004333  [15010/25000]\n",
      "loss: 115.213058  [16010/25000]\n",
      "loss: 195.755219  [17010/25000]\n",
      "loss: 84.023834  [18010/25000]\n",
      "loss: 54.354115  [19010/25000]\n",
      "loss: 205.414551  [20010/25000]\n",
      "loss: 196.566010  [21010/25000]\n",
      "loss: 178.873108  [22010/25000]\n",
      "loss: 236.691284  [23010/25000]\n",
      "loss: 206.061478  [24010/25000]\n",
      "accuracy: tensor(0.2108)\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 206.659363  [   10/25000]\n",
      "loss: 128.049011  [ 1010/25000]\n",
      "loss: 247.505630  [ 2010/25000]\n",
      "loss: 137.211044  [ 3010/25000]\n",
      "loss: 131.542984  [ 4010/25000]\n",
      "loss: 344.127350  [ 5010/25000]\n",
      "loss: 84.315773  [ 6010/25000]\n",
      "loss: 137.415710  [ 7010/25000]\n",
      "loss: 119.656151  [ 8010/25000]\n",
      "loss: 135.737228  [ 9010/25000]\n",
      "loss: 20.363922  [10010/25000]\n",
      "loss: 108.075661  [11010/25000]\n",
      "loss: 118.360420  [12010/25000]\n",
      "loss: 206.930023  [13010/25000]\n",
      "loss: 98.883896  [14010/25000]\n",
      "loss: 269.997864  [15010/25000]\n",
      "loss: 115.206474  [16010/25000]\n",
      "loss: 195.750427  [17010/25000]\n",
      "loss: 84.011925  [18010/25000]\n",
      "loss: 54.340801  [19010/25000]\n",
      "loss: 205.418503  [20010/25000]\n",
      "loss: 196.569244  [21010/25000]\n",
      "loss: 178.861191  [22010/25000]\n",
      "loss: 236.678970  [23010/25000]\n",
      "loss: 206.053802  [24010/25000]\n",
      "accuracy: tensor(0.2108)\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 206.654739  [   10/25000]\n",
      "loss: 128.037552  [ 1010/25000]\n",
      "loss: 247.489838  [ 2010/25000]\n",
      "loss: 137.207031  [ 3010/25000]\n",
      "loss: 131.531601  [ 4010/25000]\n",
      "loss: 344.112396  [ 5010/25000]\n",
      "loss: 84.302223  [ 6010/25000]\n",
      "loss: 137.407501  [ 7010/25000]\n",
      "loss: 119.647499  [ 8010/25000]\n",
      "loss: 135.721146  [ 9010/25000]\n",
      "loss: 20.360874  [10010/25000]\n",
      "loss: 108.068733  [11010/25000]\n",
      "loss: 118.344444  [12010/25000]\n",
      "loss: 206.911484  [13010/25000]\n",
      "loss: 98.883942  [14010/25000]\n",
      "loss: 269.991516  [15010/25000]\n",
      "loss: 115.199875  [16010/25000]\n",
      "loss: 195.745834  [17010/25000]\n",
      "loss: 84.000114  [18010/25000]\n",
      "loss: 54.327465  [19010/25000]\n",
      "loss: 205.422424  [20010/25000]\n",
      "loss: 196.571838  [21010/25000]\n",
      "loss: 178.849319  [22010/25000]\n",
      "loss: 236.666840  [23010/25000]\n",
      "loss: 206.046173  [24010/25000]\n",
      "accuracy: tensor(0.2107)\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 206.649948  [   10/25000]\n",
      "loss: 128.026077  [ 1010/25000]\n",
      "loss: 247.474197  [ 2010/25000]\n",
      "loss: 137.202850  [ 3010/25000]\n",
      "loss: 131.520554  [ 4010/25000]\n",
      "loss: 344.097290  [ 5010/25000]\n",
      "loss: 84.288528  [ 6010/25000]\n",
      "loss: 137.399277  [ 7010/25000]\n",
      "loss: 119.638809  [ 8010/25000]\n",
      "loss: 135.705093  [ 9010/25000]\n",
      "loss: 20.357763  [10010/25000]\n",
      "loss: 108.061562  [11010/25000]\n",
      "loss: 118.328033  [12010/25000]\n",
      "loss: 206.892975  [13010/25000]\n",
      "loss: 98.883881  [14010/25000]\n",
      "loss: 269.985107  [15010/25000]\n",
      "loss: 115.193138  [16010/25000]\n",
      "loss: 195.741089  [17010/25000]\n",
      "loss: 83.988205  [18010/25000]\n",
      "loss: 54.314159  [19010/25000]\n",
      "loss: 205.426498  [20010/25000]\n",
      "loss: 196.575455  [21010/25000]\n",
      "loss: 178.837357  [22010/25000]\n",
      "loss: 236.654800  [23010/25000]\n",
      "loss: 206.038513  [24010/25000]\n",
      "accuracy: tensor(0.2106)\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 206.645157  [   10/25000]\n",
      "loss: 128.014679  [ 1010/25000]\n",
      "loss: 247.458511  [ 2010/25000]\n",
      "loss: 137.198853  [ 3010/25000]\n",
      "loss: 131.509186  [ 4010/25000]\n",
      "loss: 344.082397  [ 5010/25000]\n",
      "loss: 84.274979  [ 6010/25000]\n",
      "loss: 137.391052  [ 7010/25000]\n",
      "loss: 119.630104  [ 8010/25000]\n",
      "loss: 135.688980  [ 9010/25000]\n",
      "loss: 20.354660  [10010/25000]\n",
      "loss: 108.054657  [11010/25000]\n",
      "loss: 118.311638  [12010/25000]\n",
      "loss: 206.874451  [13010/25000]\n",
      "loss: 98.883965  [14010/25000]\n",
      "loss: 269.978638  [15010/25000]\n",
      "loss: 115.186478  [16010/25000]\n",
      "loss: 195.736481  [17010/25000]\n",
      "loss: 83.976433  [18010/25000]\n",
      "loss: 54.300938  [19010/25000]\n",
      "loss: 205.430450  [20010/25000]\n",
      "loss: 196.578171  [21010/25000]\n",
      "loss: 178.825546  [22010/25000]\n",
      "loss: 236.642853  [23010/25000]\n",
      "loss: 206.030899  [24010/25000]\n",
      "accuracy: tensor(0.2106)\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 206.640427  [   10/25000]\n",
      "loss: 128.003220  [ 1010/25000]\n",
      "loss: 247.442856  [ 2010/25000]\n",
      "loss: 137.194778  [ 3010/25000]\n",
      "loss: 131.498108  [ 4010/25000]\n",
      "loss: 344.067413  [ 5010/25000]\n",
      "loss: 84.261368  [ 6010/25000]\n",
      "loss: 137.382904  [ 7010/25000]\n",
      "loss: 119.621483  [ 8010/25000]\n",
      "loss: 135.672882  [ 9010/25000]\n",
      "loss: 20.351463  [10010/25000]\n",
      "loss: 108.047531  [11010/25000]\n",
      "loss: 118.295158  [12010/25000]\n",
      "loss: 206.855881  [13010/25000]\n",
      "loss: 98.883728  [14010/25000]\n",
      "loss: 269.972473  [15010/25000]\n",
      "loss: 115.179962  [16010/25000]\n",
      "loss: 195.731735  [17010/25000]\n",
      "loss: 83.964607  [18010/25000]\n",
      "loss: 54.287632  [19010/25000]\n",
      "loss: 205.434631  [20010/25000]\n",
      "loss: 196.581635  [21010/25000]\n",
      "loss: 178.813599  [22010/25000]\n",
      "loss: 236.630646  [23010/25000]\n",
      "loss: 206.023224  [24010/25000]\n",
      "accuracy: tensor(0.2105)\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 206.635727  [   10/25000]\n",
      "loss: 127.991837  [ 1010/25000]\n",
      "loss: 247.427231  [ 2010/25000]\n",
      "loss: 137.190735  [ 3010/25000]\n",
      "loss: 131.486908  [ 4010/25000]\n",
      "loss: 344.052460  [ 5010/25000]\n",
      "loss: 84.247810  [ 6010/25000]\n",
      "loss: 137.374680  [ 7010/25000]\n",
      "loss: 119.612793  [ 8010/25000]\n",
      "loss: 135.656860  [ 9010/25000]\n",
      "loss: 20.348434  [10010/25000]\n",
      "loss: 108.040489  [11010/25000]\n",
      "loss: 118.278702  [12010/25000]\n",
      "loss: 206.837311  [13010/25000]\n",
      "loss: 98.884041  [14010/25000]\n",
      "loss: 269.966095  [15010/25000]\n",
      "loss: 115.173340  [16010/25000]\n",
      "loss: 195.727112  [17010/25000]\n",
      "loss: 83.952805  [18010/25000]\n",
      "loss: 54.274380  [19010/25000]\n",
      "loss: 205.438538  [20010/25000]\n",
      "loss: 196.584183  [21010/25000]\n",
      "loss: 178.801758  [22010/25000]\n",
      "loss: 236.618362  [23010/25000]\n",
      "loss: 206.015625  [24010/25000]\n",
      "accuracy: tensor(0.2105)\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 206.631042  [   10/25000]\n",
      "loss: 127.980476  [ 1010/25000]\n",
      "loss: 247.411545  [ 2010/25000]\n",
      "loss: 137.186615  [ 3010/25000]\n",
      "loss: 131.475876  [ 4010/25000]\n",
      "loss: 344.037537  [ 5010/25000]\n",
      "loss: 84.234169  [ 6010/25000]\n",
      "loss: 137.366440  [ 7010/25000]\n",
      "loss: 119.604179  [ 8010/25000]\n",
      "loss: 135.640823  [ 9010/25000]\n",
      "loss: 20.345259  [10010/25000]\n",
      "loss: 108.033592  [11010/25000]\n",
      "loss: 118.262238  [12010/25000]\n",
      "loss: 206.819061  [13010/25000]\n",
      "loss: 98.883995  [14010/25000]\n",
      "loss: 269.959717  [15010/25000]\n",
      "loss: 115.166786  [16010/25000]\n",
      "loss: 195.722427  [17010/25000]\n",
      "loss: 83.940941  [18010/25000]\n",
      "loss: 54.261166  [19010/25000]\n",
      "loss: 205.442444  [20010/25000]\n",
      "loss: 196.587662  [21010/25000]\n",
      "loss: 178.789917  [22010/25000]\n",
      "loss: 236.606293  [23010/25000]\n",
      "loss: 206.008011  [24010/25000]\n",
      "accuracy: tensor(0.2104)\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 206.626160  [   10/25000]\n",
      "loss: 127.969063  [ 1010/25000]\n",
      "loss: 247.395935  [ 2010/25000]\n",
      "loss: 137.182739  [ 3010/25000]\n",
      "loss: 131.464752  [ 4010/25000]\n",
      "loss: 344.022705  [ 5010/25000]\n",
      "loss: 84.220604  [ 6010/25000]\n",
      "loss: 137.358200  [ 7010/25000]\n",
      "loss: 119.595520  [ 8010/25000]\n",
      "loss: 135.624863  [ 9010/25000]\n",
      "loss: 20.342104  [10010/25000]\n",
      "loss: 108.026474  [11010/25000]\n",
      "loss: 118.246124  [12010/25000]\n",
      "loss: 206.800339  [13010/25000]\n",
      "loss: 98.883942  [14010/25000]\n",
      "loss: 269.953430  [15010/25000]\n",
      "loss: 115.160187  [16010/25000]\n",
      "loss: 195.717697  [17010/25000]\n",
      "loss: 83.929268  [18010/25000]\n",
      "loss: 54.248013  [19010/25000]\n",
      "loss: 205.446381  [20010/25000]\n",
      "loss: 196.590744  [21010/25000]\n",
      "loss: 178.778061  [22010/25000]\n",
      "loss: 236.594376  [23010/25000]\n",
      "loss: 206.000397  [24010/25000]\n",
      "accuracy: tensor(0.2104)\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 206.621246  [   10/25000]\n",
      "loss: 127.957695  [ 1010/25000]\n",
      "loss: 247.380325  [ 2010/25000]\n",
      "loss: 137.178558  [ 3010/25000]\n",
      "loss: 131.453506  [ 4010/25000]\n",
      "loss: 344.007782  [ 5010/25000]\n",
      "loss: 84.207069  [ 6010/25000]\n",
      "loss: 137.350006  [ 7010/25000]\n",
      "loss: 119.586937  [ 8010/25000]\n",
      "loss: 135.608902  [ 9010/25000]\n",
      "loss: 20.339062  [10010/25000]\n",
      "loss: 108.019592  [11010/25000]\n",
      "loss: 118.229912  [12010/25000]\n",
      "loss: 206.781952  [13010/25000]\n",
      "loss: 98.884163  [14010/25000]\n",
      "loss: 269.947144  [15010/25000]\n",
      "loss: 115.153694  [16010/25000]\n",
      "loss: 195.713043  [17010/25000]\n",
      "loss: 83.917488  [18010/25000]\n",
      "loss: 54.234776  [19010/25000]\n",
      "loss: 205.450455  [20010/25000]\n",
      "loss: 196.594177  [21010/25000]\n",
      "loss: 178.766251  [22010/25000]\n",
      "loss: 236.582397  [23010/25000]\n",
      "loss: 205.992813  [24010/25000]\n",
      "accuracy: tensor(0.2103)\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 206.616699  [   10/25000]\n",
      "loss: 127.946320  [ 1010/25000]\n",
      "loss: 247.364792  [ 2010/25000]\n",
      "loss: 137.174576  [ 3010/25000]\n",
      "loss: 131.442154  [ 4010/25000]\n",
      "loss: 343.992920  [ 5010/25000]\n",
      "loss: 84.193542  [ 6010/25000]\n",
      "loss: 137.341934  [ 7010/25000]\n",
      "loss: 119.578308  [ 8010/25000]\n",
      "loss: 135.592972  [ 9010/25000]\n",
      "loss: 20.336044  [10010/25000]\n",
      "loss: 108.012482  [11010/25000]\n",
      "loss: 118.213440  [12010/25000]\n",
      "loss: 206.763550  [13010/25000]\n",
      "loss: 98.884109  [14010/25000]\n",
      "loss: 269.940735  [15010/25000]\n",
      "loss: 115.147110  [16010/25000]\n",
      "loss: 195.708450  [17010/25000]\n",
      "loss: 83.905701  [18010/25000]\n",
      "loss: 54.221603  [19010/25000]\n",
      "loss: 205.454224  [20010/25000]\n",
      "loss: 196.596832  [21010/25000]\n",
      "loss: 178.754440  [22010/25000]\n",
      "loss: 236.570374  [23010/25000]\n",
      "loss: 205.985214  [24010/25000]\n",
      "accuracy: tensor(0.2102)\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 206.612167  [   10/25000]\n",
      "loss: 127.935028  [ 1010/25000]\n",
      "loss: 247.349197  [ 2010/25000]\n",
      "loss: 137.170593  [ 3010/25000]\n",
      "loss: 131.430862  [ 4010/25000]\n",
      "loss: 343.978119  [ 5010/25000]\n",
      "loss: 84.179932  [ 6010/25000]\n",
      "loss: 137.333618  [ 7010/25000]\n",
      "loss: 119.569748  [ 8010/25000]\n",
      "loss: 135.576859  [ 9010/25000]\n",
      "loss: 20.332859  [10010/25000]\n",
      "loss: 108.005486  [11010/25000]\n",
      "loss: 118.197166  [12010/25000]\n",
      "loss: 206.745331  [13010/25000]\n",
      "loss: 98.883865  [14010/25000]\n",
      "loss: 269.934418  [15010/25000]\n",
      "loss: 115.140518  [16010/25000]\n",
      "loss: 195.703690  [17010/25000]\n",
      "loss: 83.893982  [18010/25000]\n",
      "loss: 54.208408  [19010/25000]\n",
      "loss: 205.458694  [20010/25000]\n",
      "loss: 196.599960  [21010/25000]\n",
      "loss: 178.742676  [22010/25000]\n",
      "loss: 236.558044  [23010/25000]\n",
      "loss: 205.977676  [24010/25000]\n",
      "accuracy: tensor(0.2102)\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 206.607361  [   10/25000]\n",
      "loss: 127.923630  [ 1010/25000]\n",
      "loss: 247.333649  [ 2010/25000]\n",
      "loss: 137.166550  [ 3010/25000]\n",
      "loss: 131.419830  [ 4010/25000]\n",
      "loss: 343.963287  [ 5010/25000]\n",
      "loss: 84.166512  [ 6010/25000]\n",
      "loss: 137.325638  [ 7010/25000]\n",
      "loss: 119.561180  [ 8010/25000]\n",
      "loss: 135.561157  [ 9010/25000]\n",
      "loss: 20.329786  [10010/25000]\n",
      "loss: 107.998489  [11010/25000]\n",
      "loss: 118.180977  [12010/25000]\n",
      "loss: 206.726700  [13010/25000]\n",
      "loss: 98.884201  [14010/25000]\n",
      "loss: 269.928101  [15010/25000]\n",
      "loss: 115.133919  [16010/25000]\n",
      "loss: 195.699173  [17010/25000]\n",
      "loss: 83.882195  [18010/25000]\n",
      "loss: 54.195297  [19010/25000]\n",
      "loss: 205.462738  [20010/25000]\n",
      "loss: 196.603455  [21010/25000]\n",
      "loss: 178.730835  [22010/25000]\n",
      "loss: 236.546051  [23010/25000]\n",
      "loss: 205.970078  [24010/25000]\n",
      "accuracy: tensor(0.2101)\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 206.602661  [   10/25000]\n",
      "loss: 127.912346  [ 1010/25000]\n",
      "loss: 247.318161  [ 2010/25000]\n",
      "loss: 137.162704  [ 3010/25000]\n",
      "loss: 131.408981  [ 4010/25000]\n",
      "loss: 343.948425  [ 5010/25000]\n",
      "loss: 84.153046  [ 6010/25000]\n",
      "loss: 137.317413  [ 7010/25000]\n",
      "loss: 119.552567  [ 8010/25000]\n",
      "loss: 135.545044  [ 9010/25000]\n",
      "loss: 20.326666  [10010/25000]\n",
      "loss: 107.991432  [11010/25000]\n",
      "loss: 118.164696  [12010/25000]\n",
      "loss: 206.708237  [13010/25000]\n",
      "loss: 98.884270  [14010/25000]\n",
      "loss: 269.921936  [15010/25000]\n",
      "loss: 115.127480  [16010/25000]\n",
      "loss: 195.694534  [17010/25000]\n",
      "loss: 83.870438  [18010/25000]\n",
      "loss: 54.182182  [19010/25000]\n",
      "loss: 205.466797  [20010/25000]\n",
      "loss: 196.606369  [21010/25000]\n",
      "loss: 178.719101  [22010/25000]\n",
      "loss: 236.534332  [23010/25000]\n",
      "loss: 205.962479  [24010/25000]\n",
      "accuracy: tensor(0.2101)\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 206.598206  [   10/25000]\n",
      "loss: 127.901047  [ 1010/25000]\n",
      "loss: 247.302597  [ 2010/25000]\n",
      "loss: 137.158478  [ 3010/25000]\n",
      "loss: 131.397781  [ 4010/25000]\n",
      "loss: 343.933685  [ 5010/25000]\n",
      "loss: 84.139427  [ 6010/25000]\n",
      "loss: 137.309174  [ 7010/25000]\n",
      "loss: 119.543983  [ 8010/25000]\n",
      "loss: 135.529205  [ 9010/25000]\n",
      "loss: 20.323532  [10010/25000]\n",
      "loss: 107.984589  [11010/25000]\n",
      "loss: 118.148552  [12010/25000]\n",
      "loss: 206.689957  [13010/25000]\n",
      "loss: 98.884232  [14010/25000]\n",
      "loss: 269.915619  [15010/25000]\n",
      "loss: 115.120949  [16010/25000]\n",
      "loss: 195.689880  [17010/25000]\n",
      "loss: 83.858826  [18010/25000]\n",
      "loss: 54.169033  [19010/25000]\n",
      "loss: 205.470703  [20010/25000]\n",
      "loss: 196.609512  [21010/25000]\n",
      "loss: 178.707306  [22010/25000]\n",
      "loss: 236.522339  [23010/25000]\n",
      "loss: 205.954926  [24010/25000]\n",
      "accuracy: tensor(0.2100)\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 206.593399  [   10/25000]\n",
      "loss: 127.889748  [ 1010/25000]\n",
      "loss: 247.287094  [ 2010/25000]\n",
      "loss: 137.154770  [ 3010/25000]\n",
      "loss: 131.386536  [ 4010/25000]\n",
      "loss: 343.918854  [ 5010/25000]\n",
      "loss: 84.125954  [ 6010/25000]\n",
      "loss: 137.301086  [ 7010/25000]\n",
      "loss: 119.535461  [ 8010/25000]\n",
      "loss: 135.513504  [ 9010/25000]\n",
      "loss: 20.320494  [10010/25000]\n",
      "loss: 107.977615  [11010/25000]\n",
      "loss: 118.132454  [12010/25000]\n",
      "loss: 206.671890  [13010/25000]\n",
      "loss: 98.884338  [14010/25000]\n",
      "loss: 269.909180  [15010/25000]\n",
      "loss: 115.114395  [16010/25000]\n",
      "loss: 195.685211  [17010/25000]\n",
      "loss: 83.847099  [18010/25000]\n",
      "loss: 54.155987  [19010/25000]\n",
      "loss: 205.474915  [20010/25000]\n",
      "loss: 196.612839  [21010/25000]\n",
      "loss: 178.695511  [22010/25000]\n",
      "loss: 236.510468  [23010/25000]\n",
      "loss: 205.947418  [24010/25000]\n",
      "accuracy: tensor(0.2100)\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 206.588806  [   10/25000]\n",
      "loss: 127.878494  [ 1010/25000]\n",
      "loss: 247.271637  [ 2010/25000]\n",
      "loss: 137.150665  [ 3010/25000]\n",
      "loss: 131.375443  [ 4010/25000]\n",
      "loss: 343.904114  [ 5010/25000]\n",
      "loss: 84.112595  [ 6010/25000]\n",
      "loss: 137.292984  [ 7010/25000]\n",
      "loss: 119.526917  [ 8010/25000]\n",
      "loss: 135.497574  [ 9010/25000]\n",
      "loss: 20.317369  [10010/25000]\n",
      "loss: 107.970764  [11010/25000]\n",
      "loss: 118.116112  [12010/25000]\n",
      "loss: 206.653320  [13010/25000]\n",
      "loss: 98.884308  [14010/25000]\n",
      "loss: 269.903015  [15010/25000]\n",
      "loss: 115.107864  [16010/25000]\n",
      "loss: 195.680649  [17010/25000]\n",
      "loss: 83.835457  [18010/25000]\n",
      "loss: 54.142857  [19010/25000]\n",
      "loss: 205.478943  [20010/25000]\n",
      "loss: 196.615845  [21010/25000]\n",
      "loss: 178.683731  [22010/25000]\n",
      "loss: 236.498413  [23010/25000]\n",
      "loss: 205.939850  [24010/25000]\n",
      "accuracy: tensor(0.2099)\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 206.584076  [   10/25000]\n",
      "loss: 127.867188  [ 1010/25000]\n",
      "loss: 247.256210  [ 2010/25000]\n",
      "loss: 137.146606  [ 3010/25000]\n",
      "loss: 131.364441  [ 4010/25000]\n",
      "loss: 343.889343  [ 5010/25000]\n",
      "loss: 84.099144  [ 6010/25000]\n",
      "loss: 137.284790  [ 7010/25000]\n",
      "loss: 119.518349  [ 8010/25000]\n",
      "loss: 135.481735  [ 9010/25000]\n",
      "loss: 20.314287  [10010/25000]\n",
      "loss: 107.963753  [11010/25000]\n",
      "loss: 118.099899  [12010/25000]\n",
      "loss: 206.634903  [13010/25000]\n",
      "loss: 98.884598  [14010/25000]\n",
      "loss: 269.896881  [15010/25000]\n",
      "loss: 115.101379  [16010/25000]\n",
      "loss: 195.676132  [17010/25000]\n",
      "loss: 83.823845  [18010/25000]\n",
      "loss: 54.129829  [19010/25000]\n",
      "loss: 205.482956  [20010/25000]\n",
      "loss: 196.618591  [21010/25000]\n",
      "loss: 178.672104  [22010/25000]\n",
      "loss: 236.486481  [23010/25000]\n",
      "loss: 205.932388  [24010/25000]\n",
      "accuracy: tensor(0.2098)\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 206.579605  [   10/25000]\n",
      "loss: 127.855995  [ 1010/25000]\n",
      "loss: 247.240738  [ 2010/25000]\n",
      "loss: 137.142853  [ 3010/25000]\n",
      "loss: 131.353592  [ 4010/25000]\n",
      "loss: 343.874603  [ 5010/25000]\n",
      "loss: 84.085762  [ 6010/25000]\n",
      "loss: 137.276871  [ 7010/25000]\n",
      "loss: 119.509811  [ 8010/25000]\n",
      "loss: 135.465759  [ 9010/25000]\n",
      "loss: 20.311312  [10010/25000]\n",
      "loss: 107.956764  [11010/25000]\n",
      "loss: 118.083832  [12010/25000]\n",
      "loss: 206.616562  [13010/25000]\n",
      "loss: 98.884621  [14010/25000]\n",
      "loss: 269.890472  [15010/25000]\n",
      "loss: 115.094788  [16010/25000]\n",
      "loss: 195.671585  [17010/25000]\n",
      "loss: 83.812088  [18010/25000]\n",
      "loss: 54.116756  [19010/25000]\n",
      "loss: 205.486633  [20010/25000]\n",
      "loss: 196.622360  [21010/25000]\n",
      "loss: 178.660355  [22010/25000]\n",
      "loss: 236.474457  [23010/25000]\n",
      "loss: 205.924805  [24010/25000]\n",
      "accuracy: tensor(0.2098)\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 206.574921  [   10/25000]\n",
      "loss: 127.844719  [ 1010/25000]\n",
      "loss: 247.225311  [ 2010/25000]\n",
      "loss: 137.138870  [ 3010/25000]\n",
      "loss: 131.342224  [ 4010/25000]\n",
      "loss: 343.859802  [ 5010/25000]\n",
      "loss: 84.072266  [ 6010/25000]\n",
      "loss: 137.268707  [ 7010/25000]\n",
      "loss: 119.501266  [ 8010/25000]\n",
      "loss: 135.450012  [ 9010/25000]\n",
      "loss: 20.308201  [10010/25000]\n",
      "loss: 107.949890  [11010/25000]\n",
      "loss: 118.067703  [12010/25000]\n",
      "loss: 206.598236  [13010/25000]\n",
      "loss: 98.884560  [14010/25000]\n",
      "loss: 269.884460  [15010/25000]\n",
      "loss: 115.088280  [16010/25000]\n",
      "loss: 195.666916  [17010/25000]\n",
      "loss: 83.800468  [18010/25000]\n",
      "loss: 54.103806  [19010/25000]\n",
      "loss: 205.491409  [20010/25000]\n",
      "loss: 196.625229  [21010/25000]\n",
      "loss: 178.648651  [22010/25000]\n",
      "loss: 236.462799  [23010/25000]\n",
      "loss: 205.917297  [24010/25000]\n",
      "accuracy: tensor(0.2097)\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 206.570328  [   10/25000]\n",
      "loss: 127.833450  [ 1010/25000]\n",
      "loss: 247.209946  [ 2010/25000]\n",
      "loss: 137.135132  [ 3010/25000]\n",
      "loss: 131.331146  [ 4010/25000]\n",
      "loss: 343.845245  [ 5010/25000]\n",
      "loss: 84.058876  [ 6010/25000]\n",
      "loss: 137.260498  [ 7010/25000]\n",
      "loss: 119.492714  [ 8010/25000]\n",
      "loss: 135.434052  [ 9010/25000]\n",
      "loss: 20.305109  [10010/25000]\n",
      "loss: 107.942932  [11010/25000]\n",
      "loss: 118.051559  [12010/25000]\n",
      "loss: 206.580078  [13010/25000]\n",
      "loss: 98.884628  [14010/25000]\n",
      "loss: 269.878204  [15010/25000]\n",
      "loss: 115.081894  [16010/25000]\n",
      "loss: 195.662292  [17010/25000]\n",
      "loss: 83.788849  [18010/25000]\n",
      "loss: 54.090771  [19010/25000]\n",
      "loss: 205.495407  [20010/25000]\n",
      "loss: 196.628693  [21010/25000]\n",
      "loss: 178.636917  [22010/25000]\n",
      "loss: 236.450638  [23010/25000]\n",
      "loss: 205.909805  [24010/25000]\n",
      "accuracy: tensor(0.2097)\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 206.565567  [   10/25000]\n",
      "loss: 127.822220  [ 1010/25000]\n",
      "loss: 247.194565  [ 2010/25000]\n",
      "loss: 137.130981  [ 3010/25000]\n",
      "loss: 131.320084  [ 4010/25000]\n",
      "loss: 343.830475  [ 5010/25000]\n",
      "loss: 84.045677  [ 6010/25000]\n",
      "loss: 137.252533  [ 7010/25000]\n",
      "loss: 119.484261  [ 8010/25000]\n",
      "loss: 135.418304  [ 9010/25000]\n",
      "loss: 20.301996  [10010/25000]\n",
      "loss: 107.936012  [11010/25000]\n",
      "loss: 118.035469  [12010/25000]\n",
      "loss: 206.561523  [13010/25000]\n",
      "loss: 98.884880  [14010/25000]\n",
      "loss: 269.871887  [15010/25000]\n",
      "loss: 115.075363  [16010/25000]\n",
      "loss: 195.657776  [17010/25000]\n",
      "loss: 83.777267  [18010/25000]\n",
      "loss: 54.077774  [19010/25000]\n",
      "loss: 205.499588  [20010/25000]\n",
      "loss: 196.631363  [21010/25000]\n",
      "loss: 178.625259  [22010/25000]\n",
      "loss: 236.438812  [23010/25000]\n",
      "loss: 205.902298  [24010/25000]\n",
      "accuracy: tensor(0.2096)\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 206.561172  [   10/25000]\n",
      "loss: 127.811035  [ 1010/25000]\n",
      "loss: 247.179123  [ 2010/25000]\n",
      "loss: 137.127167  [ 3010/25000]\n",
      "loss: 131.309280  [ 4010/25000]\n",
      "loss: 343.815826  [ 5010/25000]\n",
      "loss: 84.032288  [ 6010/25000]\n",
      "loss: 137.244400  [ 7010/25000]\n",
      "loss: 119.475731  [ 8010/25000]\n",
      "loss: 135.402695  [ 9010/25000]\n",
      "loss: 20.299013  [10010/25000]\n",
      "loss: 107.929100  [11010/25000]\n",
      "loss: 118.019249  [12010/25000]\n",
      "loss: 206.543457  [13010/25000]\n",
      "loss: 98.884895  [14010/25000]\n",
      "loss: 269.865753  [15010/25000]\n",
      "loss: 115.068802  [16010/25000]\n",
      "loss: 195.653198  [17010/25000]\n",
      "loss: 83.765633  [18010/25000]\n",
      "loss: 54.064804  [19010/25000]\n",
      "loss: 205.503128  [20010/25000]\n",
      "loss: 196.634842  [21010/25000]\n",
      "loss: 178.613632  [22010/25000]\n",
      "loss: 236.427109  [23010/25000]\n",
      "loss: 205.894821  [24010/25000]\n",
      "accuracy: tensor(0.2095)\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 206.556442  [   10/25000]\n",
      "loss: 127.799881  [ 1010/25000]\n",
      "loss: 247.163834  [ 2010/25000]\n",
      "loss: 137.123230  [ 3010/25000]\n",
      "loss: 131.298157  [ 4010/25000]\n",
      "loss: 343.801208  [ 5010/25000]\n",
      "loss: 84.018829  [ 6010/25000]\n",
      "loss: 137.236237  [ 7010/25000]\n",
      "loss: 119.467247  [ 8010/25000]\n",
      "loss: 135.386917  [ 9010/25000]\n",
      "loss: 20.295948  [10010/25000]\n",
      "loss: 107.922218  [11010/25000]\n",
      "loss: 118.003212  [12010/25000]\n",
      "loss: 206.525208  [13010/25000]\n",
      "loss: 98.884911  [14010/25000]\n",
      "loss: 269.859406  [15010/25000]\n",
      "loss: 115.062370  [16010/25000]\n",
      "loss: 195.648590  [17010/25000]\n",
      "loss: 83.754143  [18010/25000]\n",
      "loss: 54.051834  [19010/25000]\n",
      "loss: 205.507385  [20010/25000]\n",
      "loss: 196.638138  [21010/25000]\n",
      "loss: 178.601974  [22010/25000]\n",
      "loss: 236.415176  [23010/25000]\n",
      "loss: 205.887344  [24010/25000]\n",
      "accuracy: tensor(0.2095)\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 206.551758  [   10/25000]\n",
      "loss: 127.788673  [ 1010/25000]\n",
      "loss: 247.148514  [ 2010/25000]\n",
      "loss: 137.119370  [ 3010/25000]\n",
      "loss: 131.286972  [ 4010/25000]\n",
      "loss: 343.786530  [ 5010/25000]\n",
      "loss: 84.005394  [ 6010/25000]\n",
      "loss: 137.228363  [ 7010/25000]\n",
      "loss: 119.458809  [ 8010/25000]\n",
      "loss: 135.371033  [ 9010/25000]\n",
      "loss: 20.292797  [10010/25000]\n",
      "loss: 107.915459  [11010/25000]\n",
      "loss: 117.987190  [12010/25000]\n",
      "loss: 206.506790  [13010/25000]\n",
      "loss: 98.885048  [14010/25000]\n",
      "loss: 269.853333  [15010/25000]\n",
      "loss: 115.055977  [16010/25000]\n",
      "loss: 195.644043  [17010/25000]\n",
      "loss: 83.742439  [18010/25000]\n",
      "loss: 54.038910  [19010/25000]\n",
      "loss: 205.511673  [20010/25000]\n",
      "loss: 196.641068  [21010/25000]\n",
      "loss: 178.590347  [22010/25000]\n",
      "loss: 236.403397  [23010/25000]\n",
      "loss: 205.879883  [24010/25000]\n",
      "accuracy: tensor(0.2094)\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 206.547058  [   10/25000]\n",
      "loss: 127.777489  [ 1010/25000]\n",
      "loss: 247.133118  [ 2010/25000]\n",
      "loss: 137.115295  [ 3010/25000]\n",
      "loss: 131.276016  [ 4010/25000]\n",
      "loss: 343.771881  [ 5010/25000]\n",
      "loss: 83.992195  [ 6010/25000]\n",
      "loss: 137.220322  [ 7010/25000]\n",
      "loss: 119.450310  [ 8010/25000]\n",
      "loss: 135.355423  [ 9010/25000]\n",
      "loss: 20.289770  [10010/25000]\n",
      "loss: 107.908485  [11010/25000]\n",
      "loss: 117.971115  [12010/25000]\n",
      "loss: 206.488632  [13010/25000]\n",
      "loss: 98.885101  [14010/25000]\n",
      "loss: 269.847198  [15010/25000]\n",
      "loss: 115.049515  [16010/25000]\n",
      "loss: 195.639496  [17010/25000]\n",
      "loss: 83.730949  [18010/25000]\n",
      "loss: 54.026031  [19010/25000]\n",
      "loss: 205.515488  [20010/25000]\n",
      "loss: 196.644226  [21010/25000]\n",
      "loss: 178.578751  [22010/25000]\n",
      "loss: 236.391647  [23010/25000]\n",
      "loss: 205.872421  [24010/25000]\n",
      "accuracy: tensor(0.2094)\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 206.542572  [   10/25000]\n",
      "loss: 127.766350  [ 1010/25000]\n",
      "loss: 247.117813  [ 2010/25000]\n",
      "loss: 137.111694  [ 3010/25000]\n",
      "loss: 131.265121  [ 4010/25000]\n",
      "loss: 343.757263  [ 5010/25000]\n",
      "loss: 83.978928  [ 6010/25000]\n",
      "loss: 137.212173  [ 7010/25000]\n",
      "loss: 119.441833  [ 8010/25000]\n",
      "loss: 135.339630  [ 9010/25000]\n",
      "loss: 20.286772  [10010/25000]\n",
      "loss: 107.901588  [11010/25000]\n",
      "loss: 117.954910  [12010/25000]\n",
      "loss: 206.470688  [13010/25000]\n",
      "loss: 98.885284  [14010/25000]\n",
      "loss: 269.841003  [15010/25000]\n",
      "loss: 115.043068  [16010/25000]\n",
      "loss: 195.634918  [17010/25000]\n",
      "loss: 83.719353  [18010/25000]\n",
      "loss: 54.013126  [19010/25000]\n",
      "loss: 205.519806  [20010/25000]\n",
      "loss: 196.647446  [21010/25000]\n",
      "loss: 178.567108  [22010/25000]\n",
      "loss: 236.379578  [23010/25000]\n",
      "loss: 205.864960  [24010/25000]\n",
      "accuracy: tensor(0.2093)\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 206.538025  [   10/25000]\n",
      "loss: 127.755219  [ 1010/25000]\n",
      "loss: 247.102539  [ 2010/25000]\n",
      "loss: 137.107727  [ 3010/25000]\n",
      "loss: 131.254257  [ 4010/25000]\n",
      "loss: 343.742645  [ 5010/25000]\n",
      "loss: 83.965668  [ 6010/25000]\n",
      "loss: 137.204178  [ 7010/25000]\n",
      "loss: 119.433388  [ 8010/25000]\n",
      "loss: 135.323822  [ 9010/25000]\n",
      "loss: 20.283636  [10010/25000]\n",
      "loss: 107.894730  [11010/25000]\n",
      "loss: 117.939178  [12010/25000]\n",
      "loss: 206.452423  [13010/25000]\n",
      "loss: 98.885391  [14010/25000]\n",
      "loss: 269.834778  [15010/25000]\n",
      "loss: 115.036491  [16010/25000]\n",
      "loss: 195.630432  [17010/25000]\n",
      "loss: 83.707840  [18010/25000]\n",
      "loss: 54.000214  [19010/25000]\n",
      "loss: 205.523422  [20010/25000]\n",
      "loss: 196.650894  [21010/25000]\n",
      "loss: 178.555466  [22010/25000]\n",
      "loss: 236.367889  [23010/25000]\n",
      "loss: 205.857498  [24010/25000]\n",
      "accuracy: tensor(0.2093)\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 206.533508  [   10/25000]\n",
      "loss: 127.744102  [ 1010/25000]\n",
      "loss: 247.087311  [ 2010/25000]\n",
      "loss: 137.103821  [ 3010/25000]\n",
      "loss: 131.243515  [ 4010/25000]\n",
      "loss: 343.728149  [ 5010/25000]\n",
      "loss: 83.952362  [ 6010/25000]\n",
      "loss: 137.196289  [ 7010/25000]\n",
      "loss: 119.424950  [ 8010/25000]\n",
      "loss: 135.308228  [ 9010/25000]\n",
      "loss: 20.280668  [10010/25000]\n",
      "loss: 107.887863  [11010/25000]\n",
      "loss: 117.923203  [12010/25000]\n",
      "loss: 206.434494  [13010/25000]\n",
      "loss: 98.885567  [14010/25000]\n",
      "loss: 269.828674  [15010/25000]\n",
      "loss: 115.030136  [16010/25000]\n",
      "loss: 195.625793  [17010/25000]\n",
      "loss: 83.696388  [18010/25000]\n",
      "loss: 53.987301  [19010/25000]\n",
      "loss: 205.527847  [20010/25000]\n",
      "loss: 196.653793  [21010/25000]\n",
      "loss: 178.543945  [22010/25000]\n",
      "loss: 236.356369  [23010/25000]\n",
      "loss: 205.850052  [24010/25000]\n",
      "accuracy: tensor(0.2092)\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 206.528885  [   10/25000]\n",
      "loss: 127.732979  [ 1010/25000]\n",
      "loss: 247.072006  [ 2010/25000]\n",
      "loss: 137.100357  [ 3010/25000]\n",
      "loss: 131.232559  [ 4010/25000]\n",
      "loss: 343.713501  [ 5010/25000]\n",
      "loss: 83.939079  [ 6010/25000]\n",
      "loss: 137.188126  [ 7010/25000]\n",
      "loss: 119.416504  [ 8010/25000]\n",
      "loss: 135.292664  [ 9010/25000]\n",
      "loss: 20.277653  [10010/25000]\n",
      "loss: 107.881027  [11010/25000]\n",
      "loss: 117.906845  [12010/25000]\n",
      "loss: 206.416367  [13010/25000]\n",
      "loss: 98.885498  [14010/25000]\n",
      "loss: 269.822510  [15010/25000]\n",
      "loss: 115.023682  [16010/25000]\n",
      "loss: 195.621399  [17010/25000]\n",
      "loss: 83.684753  [18010/25000]\n",
      "loss: 53.974491  [19010/25000]\n",
      "loss: 205.532028  [20010/25000]\n",
      "loss: 196.657089  [21010/25000]\n",
      "loss: 178.532288  [22010/25000]\n",
      "loss: 236.344391  [23010/25000]\n",
      "loss: 205.842651  [24010/25000]\n",
      "accuracy: tensor(0.2091)\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 206.524551  [   10/25000]\n",
      "loss: 127.721855  [ 1010/25000]\n",
      "loss: 247.056763  [ 2010/25000]\n",
      "loss: 137.096237  [ 3010/25000]\n",
      "loss: 131.221466  [ 4010/25000]\n",
      "loss: 343.699036  [ 5010/25000]\n",
      "loss: 83.925842  [ 6010/25000]\n",
      "loss: 137.180176  [ 7010/25000]\n",
      "loss: 119.408112  [ 8010/25000]\n",
      "loss: 135.276794  [ 9010/25000]\n",
      "loss: 20.274538  [10010/25000]\n",
      "loss: 107.874207  [11010/25000]\n",
      "loss: 117.891327  [12010/25000]\n",
      "loss: 206.398254  [13010/25000]\n",
      "loss: 98.885887  [14010/25000]\n",
      "loss: 269.816498  [15010/25000]\n",
      "loss: 115.017342  [16010/25000]\n",
      "loss: 195.616898  [17010/25000]\n",
      "loss: 83.673264  [18010/25000]\n",
      "loss: 53.961636  [19010/25000]\n",
      "loss: 205.535950  [20010/25000]\n",
      "loss: 196.660004  [21010/25000]\n",
      "loss: 178.520767  [22010/25000]\n",
      "loss: 236.332657  [23010/25000]\n",
      "loss: 205.835190  [24010/25000]\n",
      "accuracy: tensor(0.2091)\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 206.520020  [   10/25000]\n",
      "loss: 127.710800  [ 1010/25000]\n",
      "loss: 247.041595  [ 2010/25000]\n",
      "loss: 137.092377  [ 3010/25000]\n",
      "loss: 131.210510  [ 4010/25000]\n",
      "loss: 343.684448  [ 5010/25000]\n",
      "loss: 83.912567  [ 6010/25000]\n",
      "loss: 137.172134  [ 7010/25000]\n",
      "loss: 119.399658  [ 8010/25000]\n",
      "loss: 135.261230  [ 9010/25000]\n",
      "loss: 20.271482  [10010/25000]\n",
      "loss: 107.867264  [11010/25000]\n",
      "loss: 117.875252  [12010/25000]\n",
      "loss: 206.380249  [13010/25000]\n",
      "loss: 98.886192  [14010/25000]\n",
      "loss: 269.810242  [15010/25000]\n",
      "loss: 115.010941  [16010/25000]\n",
      "loss: 195.612396  [17010/25000]\n",
      "loss: 83.661766  [18010/25000]\n",
      "loss: 53.948799  [19010/25000]\n",
      "loss: 205.539734  [20010/25000]\n",
      "loss: 196.663437  [21010/25000]\n",
      "loss: 178.509232  [22010/25000]\n",
      "loss: 236.320801  [23010/25000]\n",
      "loss: 205.827789  [24010/25000]\n",
      "accuracy: tensor(0.2090)\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 206.515335  [   10/25000]\n",
      "loss: 127.699707  [ 1010/25000]\n",
      "loss: 247.026321  [ 2010/25000]\n",
      "loss: 137.088638  [ 3010/25000]\n",
      "loss: 131.199203  [ 4010/25000]\n",
      "loss: 343.670013  [ 5010/25000]\n",
      "loss: 83.899368  [ 6010/25000]\n",
      "loss: 137.164246  [ 7010/25000]\n",
      "loss: 119.391266  [ 8010/25000]\n",
      "loss: 135.245758  [ 9010/25000]\n",
      "loss: 20.268492  [10010/25000]\n",
      "loss: 107.860527  [11010/25000]\n",
      "loss: 117.859299  [12010/25000]\n",
      "loss: 206.362000  [13010/25000]\n",
      "loss: 98.886009  [14010/25000]\n",
      "loss: 269.804352  [15010/25000]\n",
      "loss: 115.004501  [16010/25000]\n",
      "loss: 195.607864  [17010/25000]\n",
      "loss: 83.650322  [18010/25000]\n",
      "loss: 53.936039  [19010/25000]\n",
      "loss: 205.544418  [20010/25000]\n",
      "loss: 196.666489  [21010/25000]\n",
      "loss: 178.497818  [22010/25000]\n",
      "loss: 236.309433  [23010/25000]\n",
      "loss: 205.820374  [24010/25000]\n",
      "accuracy: tensor(0.2090)\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 206.510666  [   10/25000]\n",
      "loss: 127.688576  [ 1010/25000]\n",
      "loss: 247.011185  [ 2010/25000]\n",
      "loss: 137.084839  [ 3010/25000]\n",
      "loss: 131.188400  [ 4010/25000]\n",
      "loss: 343.655396  [ 5010/25000]\n",
      "loss: 83.886169  [ 6010/25000]\n",
      "loss: 137.156265  [ 7010/25000]\n",
      "loss: 119.382912  [ 8010/25000]\n",
      "loss: 135.229996  [ 9010/25000]\n",
      "loss: 20.265419  [10010/25000]\n",
      "loss: 107.853714  [11010/25000]\n",
      "loss: 117.843361  [12010/25000]\n",
      "loss: 206.344086  [13010/25000]\n",
      "loss: 98.886307  [14010/25000]\n",
      "loss: 269.798218  [15010/25000]\n",
      "loss: 114.998093  [16010/25000]\n",
      "loss: 195.603317  [17010/25000]\n",
      "loss: 83.638824  [18010/25000]\n",
      "loss: 53.923241  [19010/25000]\n",
      "loss: 205.547943  [20010/25000]\n",
      "loss: 196.669647  [21010/25000]\n",
      "loss: 178.486176  [22010/25000]\n",
      "loss: 236.297455  [23010/25000]\n",
      "loss: 205.813004  [24010/25000]\n",
      "accuracy: tensor(0.2089)\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 206.506119  [   10/25000]\n",
      "loss: 127.677513  [ 1010/25000]\n",
      "loss: 246.996033  [ 2010/25000]\n",
      "loss: 137.081039  [ 3010/25000]\n",
      "loss: 131.177658  [ 4010/25000]\n",
      "loss: 343.640991  [ 5010/25000]\n",
      "loss: 83.872833  [ 6010/25000]\n",
      "loss: 137.148254  [ 7010/25000]\n",
      "loss: 119.374550  [ 8010/25000]\n",
      "loss: 135.214478  [ 9010/25000]\n",
      "loss: 20.262398  [10010/25000]\n",
      "loss: 107.846970  [11010/25000]\n",
      "loss: 117.827522  [12010/25000]\n",
      "loss: 206.325897  [13010/25000]\n",
      "loss: 98.886292  [14010/25000]\n",
      "loss: 269.791962  [15010/25000]\n",
      "loss: 114.991676  [16010/25000]\n",
      "loss: 195.598770  [17010/25000]\n",
      "loss: 83.627419  [18010/25000]\n",
      "loss: 53.910469  [19010/25000]\n",
      "loss: 205.552597  [20010/25000]\n",
      "loss: 196.673157  [21010/25000]\n",
      "loss: 178.474686  [22010/25000]\n",
      "loss: 236.285736  [23010/25000]\n",
      "loss: 205.805588  [24010/25000]\n",
      "accuracy: tensor(0.2088)\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 206.501953  [   10/25000]\n",
      "loss: 127.666504  [ 1010/25000]\n",
      "loss: 246.980835  [ 2010/25000]\n",
      "loss: 137.077209  [ 3010/25000]\n",
      "loss: 131.166550  [ 4010/25000]\n",
      "loss: 343.626434  [ 5010/25000]\n",
      "loss: 83.859795  [ 6010/25000]\n",
      "loss: 137.140381  [ 7010/25000]\n",
      "loss: 119.366142  [ 8010/25000]\n",
      "loss: 135.198990  [ 9010/25000]\n",
      "loss: 20.259422  [10010/25000]\n",
      "loss: 107.840027  [11010/25000]\n",
      "loss: 117.811531  [12010/25000]\n",
      "loss: 206.308105  [13010/25000]\n",
      "loss: 98.886414  [14010/25000]\n",
      "loss: 269.785889  [15010/25000]\n",
      "loss: 114.985252  [16010/25000]\n",
      "loss: 195.594299  [17010/25000]\n",
      "loss: 83.615974  [18010/25000]\n",
      "loss: 53.897728  [19010/25000]\n",
      "loss: 205.556427  [20010/25000]\n",
      "loss: 196.676270  [21010/25000]\n",
      "loss: 178.463242  [22010/25000]\n",
      "loss: 236.274063  [23010/25000]\n",
      "loss: 205.798248  [24010/25000]\n",
      "accuracy: tensor(0.2088)\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 206.497498  [   10/25000]\n",
      "loss: 127.655495  [ 1010/25000]\n",
      "loss: 246.965683  [ 2010/25000]\n",
      "loss: 137.073669  [ 3010/25000]\n",
      "loss: 131.155914  [ 4010/25000]\n",
      "loss: 343.612030  [ 5010/25000]\n",
      "loss: 83.846581  [ 6010/25000]\n",
      "loss: 137.132233  [ 7010/25000]\n",
      "loss: 119.357758  [ 8010/25000]\n",
      "loss: 135.183334  [ 9010/25000]\n",
      "loss: 20.256393  [10010/25000]\n",
      "loss: 107.833229  [11010/25000]\n",
      "loss: 117.795860  [12010/25000]\n",
      "loss: 206.289993  [13010/25000]\n",
      "loss: 98.886711  [14010/25000]\n",
      "loss: 269.779907  [15010/25000]\n",
      "loss: 114.978912  [16010/25000]\n",
      "loss: 195.589844  [17010/25000]\n",
      "loss: 83.604599  [18010/25000]\n",
      "loss: 53.884964  [19010/25000]\n",
      "loss: 205.560394  [20010/25000]\n",
      "loss: 196.679321  [21010/25000]\n",
      "loss: 178.451752  [22010/25000]\n",
      "loss: 236.262421  [23010/25000]\n",
      "loss: 205.790863  [24010/25000]\n",
      "accuracy: tensor(0.2087)\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 206.492691  [   10/25000]\n",
      "loss: 127.644432  [ 1010/25000]\n",
      "loss: 246.950607  [ 2010/25000]\n",
      "loss: 137.069702  [ 3010/25000]\n",
      "loss: 131.144958  [ 4010/25000]\n",
      "loss: 343.597656  [ 5010/25000]\n",
      "loss: 83.833427  [ 6010/25000]\n",
      "loss: 137.124420  [ 7010/25000]\n",
      "loss: 119.349434  [ 8010/25000]\n",
      "loss: 135.167984  [ 9010/25000]\n",
      "loss: 20.253317  [10010/25000]\n",
      "loss: 107.826508  [11010/25000]\n",
      "loss: 117.780060  [12010/25000]\n",
      "loss: 206.272110  [13010/25000]\n",
      "loss: 98.886887  [14010/25000]\n",
      "loss: 269.773865  [15010/25000]\n",
      "loss: 114.972580  [16010/25000]\n",
      "loss: 195.585464  [17010/25000]\n",
      "loss: 83.593132  [18010/25000]\n",
      "loss: 53.872265  [19010/25000]\n",
      "loss: 205.564713  [20010/25000]\n",
      "loss: 196.682495  [21010/25000]\n",
      "loss: 178.440277  [22010/25000]\n",
      "loss: 236.250931  [23010/25000]\n",
      "loss: 205.783493  [24010/25000]\n",
      "accuracy: tensor(0.2087)\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 206.488068  [   10/25000]\n",
      "loss: 127.633438  [ 1010/25000]\n",
      "loss: 246.935455  [ 2010/25000]\n",
      "loss: 137.066223  [ 3010/25000]\n",
      "loss: 131.133713  [ 4010/25000]\n",
      "loss: 343.583191  [ 5010/25000]\n",
      "loss: 83.820290  [ 6010/25000]\n",
      "loss: 137.116302  [ 7010/25000]\n",
      "loss: 119.341095  [ 8010/25000]\n",
      "loss: 135.152405  [ 9010/25000]\n",
      "loss: 20.250324  [10010/25000]\n",
      "loss: 107.819717  [11010/25000]\n",
      "loss: 117.764084  [12010/25000]\n",
      "loss: 206.254135  [13010/25000]\n",
      "loss: 98.886917  [14010/25000]\n",
      "loss: 269.767700  [15010/25000]\n",
      "loss: 114.966156  [16010/25000]\n",
      "loss: 195.580994  [17010/25000]\n",
      "loss: 83.581711  [18010/25000]\n",
      "loss: 53.859562  [19010/25000]\n",
      "loss: 205.568832  [20010/25000]\n",
      "loss: 196.685547  [21010/25000]\n",
      "loss: 178.428864  [22010/25000]\n",
      "loss: 236.239120  [23010/25000]\n",
      "loss: 205.776154  [24010/25000]\n",
      "accuracy: tensor(0.2086)\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 206.483627  [   10/25000]\n",
      "loss: 127.622459  [ 1010/25000]\n",
      "loss: 246.920334  [ 2010/25000]\n",
      "loss: 137.062347  [ 3010/25000]\n",
      "loss: 131.122986  [ 4010/25000]\n",
      "loss: 343.568756  [ 5010/25000]\n",
      "loss: 83.807098  [ 6010/25000]\n",
      "loss: 137.108444  [ 7010/25000]\n",
      "loss: 119.332703  [ 8010/25000]\n",
      "loss: 135.136841  [ 9010/25000]\n",
      "loss: 20.247311  [10010/25000]\n",
      "loss: 107.812889  [11010/25000]\n",
      "loss: 117.748116  [12010/25000]\n",
      "loss: 206.236313  [13010/25000]\n",
      "loss: 98.887100  [14010/25000]\n",
      "loss: 269.761627  [15010/25000]\n",
      "loss: 114.959846  [16010/25000]\n",
      "loss: 195.576569  [17010/25000]\n",
      "loss: 83.570312  [18010/25000]\n",
      "loss: 53.846855  [19010/25000]\n",
      "loss: 205.573090  [20010/25000]\n",
      "loss: 196.689041  [21010/25000]\n",
      "loss: 178.417358  [22010/25000]\n",
      "loss: 236.227448  [23010/25000]\n",
      "loss: 205.768784  [24010/25000]\n",
      "accuracy: tensor(0.2086)\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 206.479156  [   10/25000]\n",
      "loss: 127.611473  [ 1010/25000]\n",
      "loss: 246.905258  [ 2010/25000]\n",
      "loss: 137.058578  [ 3010/25000]\n",
      "loss: 131.112152  [ 4010/25000]\n",
      "loss: 343.554382  [ 5010/25000]\n",
      "loss: 83.793983  [ 6010/25000]\n",
      "loss: 137.100586  [ 7010/25000]\n",
      "loss: 119.324394  [ 8010/25000]\n",
      "loss: 135.121460  [ 9010/25000]\n",
      "loss: 20.244335  [10010/25000]\n",
      "loss: 107.806107  [11010/25000]\n",
      "loss: 117.732422  [12010/25000]\n",
      "loss: 206.218323  [13010/25000]\n",
      "loss: 98.887352  [14010/25000]\n",
      "loss: 269.755768  [15010/25000]\n",
      "loss: 114.953445  [16010/25000]\n",
      "loss: 195.572083  [17010/25000]\n",
      "loss: 83.558937  [18010/25000]\n",
      "loss: 53.834206  [19010/25000]\n",
      "loss: 205.577026  [20010/25000]\n",
      "loss: 196.691757  [21010/25000]\n",
      "loss: 178.405899  [22010/25000]\n",
      "loss: 236.215958  [23010/25000]\n",
      "loss: 205.761459  [24010/25000]\n",
      "accuracy: tensor(0.2085)\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 206.474701  [   10/25000]\n",
      "loss: 127.600479  [ 1010/25000]\n",
      "loss: 246.890198  [ 2010/25000]\n",
      "loss: 137.054886  [ 3010/25000]\n",
      "loss: 131.101410  [ 4010/25000]\n",
      "loss: 343.540039  [ 5010/25000]\n",
      "loss: 83.780754  [ 6010/25000]\n",
      "loss: 137.092682  [ 7010/25000]\n",
      "loss: 119.316017  [ 8010/25000]\n",
      "loss: 135.105896  [ 9010/25000]\n",
      "loss: 20.241295  [10010/25000]\n",
      "loss: 107.799393  [11010/25000]\n",
      "loss: 117.716614  [12010/25000]\n",
      "loss: 206.200409  [13010/25000]\n",
      "loss: 98.887512  [14010/25000]\n",
      "loss: 269.749634  [15010/25000]\n",
      "loss: 114.947090  [16010/25000]\n",
      "loss: 195.567673  [17010/25000]\n",
      "loss: 83.547615  [18010/25000]\n",
      "loss: 53.821533  [19010/25000]\n",
      "loss: 205.581207  [20010/25000]\n",
      "loss: 196.695221  [21010/25000]\n",
      "loss: 178.394485  [22010/25000]\n",
      "loss: 236.204300  [23010/25000]\n",
      "loss: 205.754105  [24010/25000]\n",
      "accuracy: tensor(0.2084)\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 206.470291  [   10/25000]\n",
      "loss: 127.589485  [ 1010/25000]\n",
      "loss: 246.875183  [ 2010/25000]\n",
      "loss: 137.051147  [ 3010/25000]\n",
      "loss: 131.090378  [ 4010/25000]\n",
      "loss: 343.525574  [ 5010/25000]\n",
      "loss: 83.767799  [ 6010/25000]\n",
      "loss: 137.084808  [ 7010/25000]\n",
      "loss: 119.307770  [ 8010/25000]\n",
      "loss: 135.090454  [ 9010/25000]\n",
      "loss: 20.238232  [10010/25000]\n",
      "loss: 107.792633  [11010/25000]\n",
      "loss: 117.700958  [12010/25000]\n",
      "loss: 206.182480  [13010/25000]\n",
      "loss: 98.887726  [14010/25000]\n",
      "loss: 269.743591  [15010/25000]\n",
      "loss: 114.940742  [16010/25000]\n",
      "loss: 195.563080  [17010/25000]\n",
      "loss: 83.536285  [18010/25000]\n",
      "loss: 53.808887  [19010/25000]\n",
      "loss: 205.585159  [20010/25000]\n",
      "loss: 196.698441  [21010/25000]\n",
      "loss: 178.383118  [22010/25000]\n",
      "loss: 236.193054  [23010/25000]\n",
      "loss: 205.746796  [24010/25000]\n",
      "accuracy: tensor(0.2084)\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 206.465591  [   10/25000]\n",
      "loss: 127.578545  [ 1010/25000]\n",
      "loss: 246.860199  [ 2010/25000]\n",
      "loss: 137.047546  [ 3010/25000]\n",
      "loss: 131.079803  [ 4010/25000]\n",
      "loss: 343.511292  [ 5010/25000]\n",
      "loss: 83.754738  [ 6010/25000]\n",
      "loss: 137.076782  [ 7010/25000]\n",
      "loss: 119.299446  [ 8010/25000]\n",
      "loss: 135.075073  [ 9010/25000]\n",
      "loss: 20.235346  [10010/25000]\n",
      "loss: 107.785889  [11010/25000]\n",
      "loss: 117.684990  [12010/25000]\n",
      "loss: 206.164536  [13010/25000]\n",
      "loss: 98.887825  [14010/25000]\n",
      "loss: 269.737701  [15010/25000]\n",
      "loss: 114.934433  [16010/25000]\n",
      "loss: 195.558716  [17010/25000]\n",
      "loss: 83.524910  [18010/25000]\n",
      "loss: 53.796314  [19010/25000]\n",
      "loss: 205.588791  [20010/25000]\n",
      "loss: 196.701797  [21010/25000]\n",
      "loss: 178.371735  [22010/25000]\n",
      "loss: 236.181244  [23010/25000]\n",
      "loss: 205.739456  [24010/25000]\n",
      "accuracy: tensor(0.2083)\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 206.461380  [   10/25000]\n",
      "loss: 127.567619  [ 1010/25000]\n",
      "loss: 246.845154  [ 2010/25000]\n",
      "loss: 137.043854  [ 3010/25000]\n",
      "loss: 131.068939  [ 4010/25000]\n",
      "loss: 343.496979  [ 5010/25000]\n",
      "loss: 83.741661  [ 6010/25000]\n",
      "loss: 137.068863  [ 7010/25000]\n",
      "loss: 119.291130  [ 8010/25000]\n",
      "loss: 135.059464  [ 9010/25000]\n",
      "loss: 20.232288  [10010/25000]\n",
      "loss: 107.779114  [11010/25000]\n",
      "loss: 117.669296  [12010/25000]\n",
      "loss: 206.146759  [13010/25000]\n",
      "loss: 98.888077  [14010/25000]\n",
      "loss: 269.731628  [15010/25000]\n",
      "loss: 114.928116  [16010/25000]\n",
      "loss: 195.554214  [17010/25000]\n",
      "loss: 83.513573  [18010/25000]\n",
      "loss: 53.783680  [19010/25000]\n",
      "loss: 205.593704  [20010/25000]\n",
      "loss: 196.704575  [21010/25000]\n",
      "loss: 178.360367  [22010/25000]\n",
      "loss: 236.169785  [23010/25000]\n",
      "loss: 205.732147  [24010/25000]\n",
      "accuracy: tensor(0.2083)\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 206.457031  [   10/25000]\n",
      "loss: 127.556732  [ 1010/25000]\n",
      "loss: 246.830139  [ 2010/25000]\n",
      "loss: 137.040024  [ 3010/25000]\n",
      "loss: 131.058151  [ 4010/25000]\n",
      "loss: 343.482727  [ 5010/25000]\n",
      "loss: 83.728561  [ 6010/25000]\n",
      "loss: 137.061127  [ 7010/25000]\n",
      "loss: 119.282890  [ 8010/25000]\n",
      "loss: 135.044144  [ 9010/25000]\n",
      "loss: 20.229273  [10010/25000]\n",
      "loss: 107.772430  [11010/25000]\n",
      "loss: 117.653389  [12010/25000]\n",
      "loss: 206.129028  [13010/25000]\n",
      "loss: 98.888321  [14010/25000]\n",
      "loss: 269.725677  [15010/25000]\n",
      "loss: 114.921783  [16010/25000]\n",
      "loss: 195.549927  [17010/25000]\n",
      "loss: 83.502228  [18010/25000]\n",
      "loss: 53.771065  [19010/25000]\n",
      "loss: 205.597382  [20010/25000]\n",
      "loss: 196.708481  [21010/25000]\n",
      "loss: 178.348969  [22010/25000]\n",
      "loss: 236.158081  [23010/25000]\n",
      "loss: 205.724884  [24010/25000]\n",
      "accuracy: tensor(0.2082)\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 206.452408  [   10/25000]\n",
      "loss: 127.545837  [ 1010/25000]\n",
      "loss: 246.815155  [ 2010/25000]\n",
      "loss: 137.036255  [ 3010/25000]\n",
      "loss: 131.047134  [ 4010/25000]\n",
      "loss: 343.468353  [ 5010/25000]\n",
      "loss: 83.715607  [ 6010/25000]\n",
      "loss: 137.053146  [ 7010/25000]\n",
      "loss: 119.274612  [ 8010/25000]\n",
      "loss: 135.028748  [ 9010/25000]\n",
      "loss: 20.226320  [10010/25000]\n",
      "loss: 107.765594  [11010/25000]\n",
      "loss: 117.637901  [12010/25000]\n",
      "loss: 206.111145  [13010/25000]\n",
      "loss: 98.888596  [14010/25000]\n",
      "loss: 269.719513  [15010/25000]\n",
      "loss: 114.915436  [16010/25000]\n",
      "loss: 195.545471  [17010/25000]\n",
      "loss: 83.490967  [18010/25000]\n",
      "loss: 53.758476  [19010/25000]\n",
      "loss: 205.602036  [20010/25000]\n",
      "loss: 196.711075  [21010/25000]\n",
      "loss: 178.337601  [22010/25000]\n",
      "loss: 236.146530  [23010/25000]\n",
      "loss: 205.717560  [24010/25000]\n",
      "accuracy: tensor(0.2082)\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 206.448013  [   10/25000]\n",
      "loss: 127.534889  [ 1010/25000]\n",
      "loss: 246.800217  [ 2010/25000]\n",
      "loss: 137.032654  [ 3010/25000]\n",
      "loss: 131.036362  [ 4010/25000]\n",
      "loss: 343.454102  [ 5010/25000]\n",
      "loss: 83.702538  [ 6010/25000]\n",
      "loss: 137.045380  [ 7010/25000]\n",
      "loss: 119.266335  [ 8010/25000]\n",
      "loss: 135.013275  [ 9010/25000]\n",
      "loss: 20.223320  [10010/25000]\n",
      "loss: 107.758926  [11010/25000]\n",
      "loss: 117.622246  [12010/25000]\n",
      "loss: 206.093338  [13010/25000]\n",
      "loss: 98.888626  [14010/25000]\n",
      "loss: 269.713654  [15010/25000]\n",
      "loss: 114.909065  [16010/25000]\n",
      "loss: 195.541031  [17010/25000]\n",
      "loss: 83.479675  [18010/25000]\n",
      "loss: 53.745937  [19010/25000]\n",
      "loss: 205.605896  [20010/25000]\n",
      "loss: 196.714691  [21010/25000]\n",
      "loss: 178.326263  [22010/25000]\n",
      "loss: 236.135071  [23010/25000]\n",
      "loss: 205.710266  [24010/25000]\n",
      "accuracy: tensor(0.2081)\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 206.443573  [   10/25000]\n",
      "loss: 127.524025  [ 1010/25000]\n",
      "loss: 246.785278  [ 2010/25000]\n",
      "loss: 137.029007  [ 3010/25000]\n",
      "loss: 131.025803  [ 4010/25000]\n",
      "loss: 343.439819  [ 5010/25000]\n",
      "loss: 83.689407  [ 6010/25000]\n",
      "loss: 137.037582  [ 7010/25000]\n",
      "loss: 119.258049  [ 8010/25000]\n",
      "loss: 134.997894  [ 9010/25000]\n",
      "loss: 20.220325  [10010/25000]\n",
      "loss: 107.752205  [11010/25000]\n",
      "loss: 117.606445  [12010/25000]\n",
      "loss: 206.075668  [13010/25000]\n",
      "loss: 98.888817  [14010/25000]\n",
      "loss: 269.707672  [15010/25000]\n",
      "loss: 114.902832  [16010/25000]\n",
      "loss: 195.536743  [17010/25000]\n",
      "loss: 83.468414  [18010/25000]\n",
      "loss: 53.733437  [19010/25000]\n",
      "loss: 205.610443  [20010/25000]\n",
      "loss: 196.718033  [21010/25000]\n",
      "loss: 178.314819  [22010/25000]\n",
      "loss: 236.123474  [23010/25000]\n",
      "loss: 205.703003  [24010/25000]\n",
      "accuracy: tensor(0.2080)\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 206.439178  [   10/25000]\n",
      "loss: 127.513161  [ 1010/25000]\n",
      "loss: 246.770309  [ 2010/25000]\n",
      "loss: 137.025482  [ 3010/25000]\n",
      "loss: 131.015106  [ 4010/25000]\n",
      "loss: 343.425507  [ 5010/25000]\n",
      "loss: 83.676468  [ 6010/25000]\n",
      "loss: 137.029587  [ 7010/25000]\n",
      "loss: 119.249786  [ 8010/25000]\n",
      "loss: 134.982605  [ 9010/25000]\n",
      "loss: 20.217361  [10010/25000]\n",
      "loss: 107.745506  [11010/25000]\n",
      "loss: 117.590569  [12010/25000]\n",
      "loss: 206.057922  [13010/25000]\n",
      "loss: 98.889290  [14010/25000]\n",
      "loss: 269.701782  [15010/25000]\n",
      "loss: 114.896599  [16010/25000]\n",
      "loss: 195.532227  [17010/25000]\n",
      "loss: 83.457123  [18010/25000]\n",
      "loss: 53.720814  [19010/25000]\n",
      "loss: 205.614548  [20010/25000]\n",
      "loss: 196.721420  [21010/25000]\n",
      "loss: 178.303497  [22010/25000]\n",
      "loss: 236.112015  [23010/25000]\n",
      "loss: 205.695740  [24010/25000]\n",
      "accuracy: tensor(0.2080)\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 206.434845  [   10/25000]\n",
      "loss: 127.502327  [ 1010/25000]\n",
      "loss: 246.755386  [ 2010/25000]\n",
      "loss: 137.021851  [ 3010/25000]\n",
      "loss: 131.004410  [ 4010/25000]\n",
      "loss: 343.411224  [ 5010/25000]\n",
      "loss: 83.663475  [ 6010/25000]\n",
      "loss: 137.021744  [ 7010/25000]\n",
      "loss: 119.241562  [ 8010/25000]\n",
      "loss: 134.967270  [ 9010/25000]\n",
      "loss: 20.214329  [10010/25000]\n",
      "loss: 107.738792  [11010/25000]\n",
      "loss: 117.575066  [12010/25000]\n",
      "loss: 206.040024  [13010/25000]\n",
      "loss: 98.889450  [14010/25000]\n",
      "loss: 269.695770  [15010/25000]\n",
      "loss: 114.890236  [16010/25000]\n",
      "loss: 195.527893  [17010/25000]\n",
      "loss: 83.445862  [18010/25000]\n",
      "loss: 53.708351  [19010/25000]\n",
      "loss: 205.618912  [20010/25000]\n",
      "loss: 196.724411  [21010/25000]\n",
      "loss: 178.292297  [22010/25000]\n",
      "loss: 236.100586  [23010/25000]\n",
      "loss: 205.688461  [24010/25000]\n",
      "accuracy: tensor(0.2079)\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 206.430466  [   10/25000]\n",
      "loss: 127.491432  [ 1010/25000]\n",
      "loss: 246.740463  [ 2010/25000]\n",
      "loss: 137.017914  [ 3010/25000]\n",
      "loss: 130.993454  [ 4010/25000]\n",
      "loss: 343.397064  [ 5010/25000]\n",
      "loss: 83.650558  [ 6010/25000]\n",
      "loss: 137.013901  [ 7010/25000]\n",
      "loss: 119.233307  [ 8010/25000]\n",
      "loss: 134.952042  [ 9010/25000]\n",
      "loss: 20.211382  [10010/25000]\n",
      "loss: 107.732140  [11010/25000]\n",
      "loss: 117.559456  [12010/25000]\n",
      "loss: 206.022385  [13010/25000]\n",
      "loss: 98.889473  [14010/25000]\n",
      "loss: 269.689911  [15010/25000]\n",
      "loss: 114.883926  [16010/25000]\n",
      "loss: 195.523499  [17010/25000]\n",
      "loss: 83.434647  [18010/25000]\n",
      "loss: 53.695850  [19010/25000]\n",
      "loss: 205.622559  [20010/25000]\n",
      "loss: 196.727585  [21010/25000]\n",
      "loss: 178.280975  [22010/25000]\n",
      "loss: 236.089157  [23010/25000]\n",
      "loss: 205.681213  [24010/25000]\n",
      "accuracy: tensor(0.2079)\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 206.425980  [   10/25000]\n",
      "loss: 127.480560  [ 1010/25000]\n",
      "loss: 246.725708  [ 2010/25000]\n",
      "loss: 137.014496  [ 3010/25000]\n",
      "loss: 130.982773  [ 4010/25000]\n",
      "loss: 343.382935  [ 5010/25000]\n",
      "loss: 83.637558  [ 6010/25000]\n",
      "loss: 137.006042  [ 7010/25000]\n",
      "loss: 119.225075  [ 8010/25000]\n",
      "loss: 134.936676  [ 9010/25000]\n",
      "loss: 20.208349  [10010/25000]\n",
      "loss: 107.725487  [11010/25000]\n",
      "loss: 117.543747  [12010/25000]\n",
      "loss: 206.004822  [13010/25000]\n",
      "loss: 98.889954  [14010/25000]\n",
      "loss: 269.683899  [15010/25000]\n",
      "loss: 114.877686  [16010/25000]\n",
      "loss: 195.519226  [17010/25000]\n",
      "loss: 83.423340  [18010/25000]\n",
      "loss: 53.683403  [19010/25000]\n",
      "loss: 205.626740  [20010/25000]\n",
      "loss: 196.730652  [21010/25000]\n",
      "loss: 178.269760  [22010/25000]\n",
      "loss: 236.077515  [23010/25000]\n",
      "loss: 205.673981  [24010/25000]\n",
      "accuracy: tensor(0.2078)\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 206.421677  [   10/25000]\n",
      "loss: 127.469704  [ 1010/25000]\n",
      "loss: 246.710800  [ 2010/25000]\n",
      "loss: 137.010696  [ 3010/25000]\n",
      "loss: 130.971970  [ 4010/25000]\n",
      "loss: 343.368683  [ 5010/25000]\n",
      "loss: 83.624512  [ 6010/25000]\n",
      "loss: 136.998093  [ 7010/25000]\n",
      "loss: 119.216858  [ 8010/25000]\n",
      "loss: 134.921478  [ 9010/25000]\n",
      "loss: 20.205416  [10010/25000]\n",
      "loss: 107.718781  [11010/25000]\n",
      "loss: 117.528366  [12010/25000]\n",
      "loss: 205.986908  [13010/25000]\n",
      "loss: 98.890099  [14010/25000]\n",
      "loss: 269.678101  [15010/25000]\n",
      "loss: 114.871414  [16010/25000]\n",
      "loss: 195.514664  [17010/25000]\n",
      "loss: 83.412148  [18010/25000]\n",
      "loss: 53.670887  [19010/25000]\n",
      "loss: 205.630646  [20010/25000]\n",
      "loss: 196.734039  [21010/25000]\n",
      "loss: 178.258484  [22010/25000]\n",
      "loss: 236.066254  [23010/25000]\n",
      "loss: 205.666718  [24010/25000]\n",
      "accuracy: tensor(0.2077)\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 206.417130  [   10/25000]\n",
      "loss: 127.458923  [ 1010/25000]\n",
      "loss: 246.695892  [ 2010/25000]\n",
      "loss: 137.007187  [ 3010/25000]\n",
      "loss: 130.961212  [ 4010/25000]\n",
      "loss: 343.354584  [ 5010/25000]\n",
      "loss: 83.611786  [ 6010/25000]\n",
      "loss: 136.990540  [ 7010/25000]\n",
      "loss: 119.208672  [ 8010/25000]\n",
      "loss: 134.906265  [ 9010/25000]\n",
      "loss: 20.202486  [10010/25000]\n",
      "loss: 107.712051  [11010/25000]\n",
      "loss: 117.512543  [12010/25000]\n",
      "loss: 205.969376  [13010/25000]\n",
      "loss: 98.890038  [14010/25000]\n",
      "loss: 269.672150  [15010/25000]\n",
      "loss: 114.865089  [16010/25000]\n",
      "loss: 195.510590  [17010/25000]\n",
      "loss: 83.401054  [18010/25000]\n",
      "loss: 53.658470  [19010/25000]\n",
      "loss: 205.634918  [20010/25000]\n",
      "loss: 196.737122  [21010/25000]\n",
      "loss: 178.247208  [22010/25000]\n",
      "loss: 236.054901  [23010/25000]\n",
      "loss: 205.659485  [24010/25000]\n",
      "accuracy: tensor(0.2077)\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 206.412537  [   10/25000]\n",
      "loss: 127.448135  [ 1010/25000]\n",
      "loss: 246.681061  [ 2010/25000]\n",
      "loss: 137.003510  [ 3010/25000]\n",
      "loss: 130.950775  [ 4010/25000]\n",
      "loss: 343.340424  [ 5010/25000]\n",
      "loss: 83.598854  [ 6010/25000]\n",
      "loss: 136.982697  [ 7010/25000]\n",
      "loss: 119.200432  [ 8010/25000]\n",
      "loss: 134.890778  [ 9010/25000]\n",
      "loss: 20.199451  [10010/25000]\n",
      "loss: 107.705452  [11010/25000]\n",
      "loss: 117.496918  [12010/25000]\n",
      "loss: 205.951614  [13010/25000]\n",
      "loss: 98.890511  [14010/25000]\n",
      "loss: 269.666199  [15010/25000]\n",
      "loss: 114.858864  [16010/25000]\n",
      "loss: 195.506210  [17010/25000]\n",
      "loss: 83.389854  [18010/25000]\n",
      "loss: 53.646030  [19010/25000]\n",
      "loss: 205.639008  [20010/25000]\n",
      "loss: 196.740005  [21010/25000]\n",
      "loss: 178.235962  [22010/25000]\n",
      "loss: 236.043411  [23010/25000]\n",
      "loss: 205.652267  [24010/25000]\n",
      "accuracy: tensor(0.2076)\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 206.408279  [   10/25000]\n",
      "loss: 127.437370  [ 1010/25000]\n",
      "loss: 246.666245  [ 2010/25000]\n",
      "loss: 137.000153  [ 3010/25000]\n",
      "loss: 130.939804  [ 4010/25000]\n",
      "loss: 343.326202  [ 5010/25000]\n",
      "loss: 83.585892  [ 6010/25000]\n",
      "loss: 136.974701  [ 7010/25000]\n",
      "loss: 119.192284  [ 8010/25000]\n",
      "loss: 134.875687  [ 9010/25000]\n",
      "loss: 20.196619  [10010/25000]\n",
      "loss: 107.698761  [11010/25000]\n",
      "loss: 117.481407  [12010/25000]\n",
      "loss: 205.934006  [13010/25000]\n",
      "loss: 98.890823  [14010/25000]\n",
      "loss: 269.660461  [15010/25000]\n",
      "loss: 114.852692  [16010/25000]\n",
      "loss: 195.501694  [17010/25000]\n",
      "loss: 83.378624  [18010/25000]\n",
      "loss: 53.633633  [19010/25000]\n",
      "loss: 205.643280  [20010/25000]\n",
      "loss: 196.743835  [21010/25000]\n",
      "loss: 178.224762  [22010/25000]\n",
      "loss: 236.032211  [23010/25000]\n",
      "loss: 205.645035  [24010/25000]\n",
      "accuracy: tensor(0.2076)\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 206.403885  [   10/25000]\n",
      "loss: 127.426605  [ 1010/25000]\n",
      "loss: 246.651443  [ 2010/25000]\n",
      "loss: 136.996521  [ 3010/25000]\n",
      "loss: 130.929459  [ 4010/25000]\n",
      "loss: 343.312103  [ 5010/25000]\n",
      "loss: 83.573006  [ 6010/25000]\n",
      "loss: 136.966980  [ 7010/25000]\n",
      "loss: 119.184082  [ 8010/25000]\n",
      "loss: 134.860397  [ 9010/25000]\n",
      "loss: 20.193533  [10010/25000]\n",
      "loss: 107.692070  [11010/25000]\n",
      "loss: 117.465927  [12010/25000]\n",
      "loss: 205.916489  [13010/25000]\n",
      "loss: 98.891220  [14010/25000]\n",
      "loss: 269.654327  [15010/25000]\n",
      "loss: 114.846405  [16010/25000]\n",
      "loss: 195.497330  [17010/25000]\n",
      "loss: 83.367493  [18010/25000]\n",
      "loss: 53.621254  [19010/25000]\n",
      "loss: 205.647614  [20010/25000]\n",
      "loss: 196.746872  [21010/25000]\n",
      "loss: 178.213516  [22010/25000]\n",
      "loss: 236.020584  [23010/25000]\n",
      "loss: 205.637833  [24010/25000]\n",
      "accuracy: tensor(0.2075)\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 206.399673  [   10/25000]\n",
      "loss: 127.415802  [ 1010/25000]\n",
      "loss: 246.636673  [ 2010/25000]\n",
      "loss: 136.992767  [ 3010/25000]\n",
      "loss: 130.918365  [ 4010/25000]\n",
      "loss: 343.297974  [ 5010/25000]\n",
      "loss: 83.560089  [ 6010/25000]\n",
      "loss: 136.959213  [ 7010/25000]\n",
      "loss: 119.175919  [ 8010/25000]\n",
      "loss: 134.845230  [ 9010/25000]\n",
      "loss: 20.190561  [10010/25000]\n",
      "loss: 107.685516  [11010/25000]\n",
      "loss: 117.450478  [12010/25000]\n",
      "loss: 205.898865  [13010/25000]\n",
      "loss: 98.891312  [14010/25000]\n",
      "loss: 269.648407  [15010/25000]\n",
      "loss: 114.840218  [16010/25000]\n",
      "loss: 195.493088  [17010/25000]\n",
      "loss: 83.356232  [18010/25000]\n",
      "loss: 53.608910  [19010/25000]\n",
      "loss: 205.651840  [20010/25000]\n",
      "loss: 196.749924  [21010/25000]\n",
      "loss: 178.202286  [22010/25000]\n",
      "loss: 236.009399  [23010/25000]\n",
      "loss: 205.630661  [24010/25000]\n",
      "accuracy: tensor(0.2075)\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 206.395233  [   10/25000]\n",
      "loss: 127.404984  [ 1010/25000]\n",
      "loss: 246.621918  [ 2010/25000]\n",
      "loss: 136.989349  [ 3010/25000]\n",
      "loss: 130.907623  [ 4010/25000]\n",
      "loss: 343.283905  [ 5010/25000]\n",
      "loss: 83.547256  [ 6010/25000]\n",
      "loss: 136.951447  [ 7010/25000]\n",
      "loss: 119.167763  [ 8010/25000]\n",
      "loss: 134.830002  [ 9010/25000]\n",
      "loss: 20.187664  [10010/25000]\n",
      "loss: 107.678848  [11010/25000]\n",
      "loss: 117.434967  [12010/25000]\n",
      "loss: 205.881134  [13010/25000]\n",
      "loss: 98.891647  [14010/25000]\n",
      "loss: 269.642700  [15010/25000]\n",
      "loss: 114.833954  [16010/25000]\n",
      "loss: 195.488815  [17010/25000]\n",
      "loss: 83.345146  [18010/25000]\n",
      "loss: 53.596458  [19010/25000]\n",
      "loss: 205.655701  [20010/25000]\n",
      "loss: 196.753235  [21010/25000]\n",
      "loss: 178.191101  [22010/25000]\n",
      "loss: 235.997955  [23010/25000]\n",
      "loss: 205.623474  [24010/25000]\n",
      "accuracy: tensor(0.2074)\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 206.390854  [   10/25000]\n",
      "loss: 127.394325  [ 1010/25000]\n",
      "loss: 246.607147  [ 2010/25000]\n",
      "loss: 136.985718  [ 3010/25000]\n",
      "loss: 130.897293  [ 4010/25000]\n",
      "loss: 343.269928  [ 5010/25000]\n",
      "loss: 83.534401  [ 6010/25000]\n",
      "loss: 136.943741  [ 7010/25000]\n",
      "loss: 119.159630  [ 8010/25000]\n",
      "loss: 134.814926  [ 9010/25000]\n",
      "loss: 20.184694  [10010/25000]\n",
      "loss: 107.672234  [11010/25000]\n",
      "loss: 117.419388  [12010/25000]\n",
      "loss: 205.863632  [13010/25000]\n",
      "loss: 98.891747  [14010/25000]\n",
      "loss: 269.636963  [15010/25000]\n",
      "loss: 114.827736  [16010/25000]\n",
      "loss: 195.484467  [17010/25000]\n",
      "loss: 83.333961  [18010/25000]\n",
      "loss: 53.584225  [19010/25000]\n",
      "loss: 205.660004  [20010/25000]\n",
      "loss: 196.756683  [21010/25000]\n",
      "loss: 178.179886  [22010/25000]\n",
      "loss: 235.986816  [23010/25000]\n",
      "loss: 205.616287  [24010/25000]\n",
      "accuracy: tensor(0.2073)\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 206.386658  [   10/25000]\n",
      "loss: 127.383575  [ 1010/25000]\n",
      "loss: 246.592438  [ 2010/25000]\n",
      "loss: 136.982132  [ 3010/25000]\n",
      "loss: 130.886246  [ 4010/25000]\n",
      "loss: 343.255829  [ 5010/25000]\n",
      "loss: 83.521530  [ 6010/25000]\n",
      "loss: 136.935974  [ 7010/25000]\n",
      "loss: 119.151436  [ 8010/25000]\n",
      "loss: 134.799576  [ 9010/25000]\n",
      "loss: 20.181747  [10010/25000]\n",
      "loss: 107.665604  [11010/25000]\n",
      "loss: 117.404099  [12010/25000]\n",
      "loss: 205.846130  [13010/25000]\n",
      "loss: 98.892014  [14010/25000]\n",
      "loss: 269.631012  [15010/25000]\n",
      "loss: 114.821594  [16010/25000]\n",
      "loss: 195.480133  [17010/25000]\n",
      "loss: 83.322960  [18010/25000]\n",
      "loss: 53.571827  [19010/25000]\n",
      "loss: 205.664078  [20010/25000]\n",
      "loss: 196.759842  [21010/25000]\n",
      "loss: 178.168671  [22010/25000]\n",
      "loss: 235.975250  [23010/25000]\n",
      "loss: 205.609100  [24010/25000]\n",
      "accuracy: tensor(0.2073)\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 206.382324  [   10/25000]\n",
      "loss: 127.372864  [ 1010/25000]\n",
      "loss: 246.577682  [ 2010/25000]\n",
      "loss: 136.978607  [ 3010/25000]\n",
      "loss: 130.875992  [ 4010/25000]\n",
      "loss: 343.241638  [ 5010/25000]\n",
      "loss: 83.508698  [ 6010/25000]\n",
      "loss: 136.928146  [ 7010/25000]\n",
      "loss: 119.143372  [ 8010/25000]\n",
      "loss: 134.784576  [ 9010/25000]\n",
      "loss: 20.178808  [10010/25000]\n",
      "loss: 107.658997  [11010/25000]\n",
      "loss: 117.388565  [12010/25000]\n",
      "loss: 205.828629  [13010/25000]\n",
      "loss: 98.892342  [14010/25000]\n",
      "loss: 269.625244  [15010/25000]\n",
      "loss: 114.815216  [16010/25000]\n",
      "loss: 195.475739  [17010/25000]\n",
      "loss: 83.311790  [18010/25000]\n",
      "loss: 53.559513  [19010/25000]\n",
      "loss: 205.668152  [20010/25000]\n",
      "loss: 196.763123  [21010/25000]\n",
      "loss: 178.157578  [22010/25000]\n",
      "loss: 235.963928  [23010/25000]\n",
      "loss: 205.601913  [24010/25000]\n",
      "accuracy: tensor(0.2072)\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 206.377640  [   10/25000]\n",
      "loss: 127.362160  [ 1010/25000]\n",
      "loss: 246.562973  [ 2010/25000]\n",
      "loss: 136.974945  [ 3010/25000]\n",
      "loss: 130.865372  [ 4010/25000]\n",
      "loss: 343.227692  [ 5010/25000]\n",
      "loss: 83.495911  [ 6010/25000]\n",
      "loss: 136.920441  [ 7010/25000]\n",
      "loss: 119.135216  [ 8010/25000]\n",
      "loss: 134.769348  [ 9010/25000]\n",
      "loss: 20.175806  [10010/25000]\n",
      "loss: 107.652382  [11010/25000]\n",
      "loss: 117.372932  [12010/25000]\n",
      "loss: 205.811096  [13010/25000]\n",
      "loss: 98.892830  [14010/25000]\n",
      "loss: 269.619415  [15010/25000]\n",
      "loss: 114.809074  [16010/25000]\n",
      "loss: 195.471405  [17010/25000]\n",
      "loss: 83.300598  [18010/25000]\n",
      "loss: 53.547230  [19010/25000]\n",
      "loss: 205.672089  [20010/25000]\n",
      "loss: 196.766266  [21010/25000]\n",
      "loss: 178.146408  [22010/25000]\n",
      "loss: 235.952713  [23010/25000]\n",
      "loss: 205.594772  [24010/25000]\n",
      "accuracy: tensor(0.2072)\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 206.373383  [   10/25000]\n",
      "loss: 127.351425  [ 1010/25000]\n",
      "loss: 246.548294  [ 2010/25000]\n",
      "loss: 136.971573  [ 3010/25000]\n",
      "loss: 130.854645  [ 4010/25000]\n",
      "loss: 343.213684  [ 5010/25000]\n",
      "loss: 83.483154  [ 6010/25000]\n",
      "loss: 136.912582  [ 7010/25000]\n",
      "loss: 119.127106  [ 8010/25000]\n",
      "loss: 134.754196  [ 9010/25000]\n",
      "loss: 20.172930  [10010/25000]\n",
      "loss: 107.645760  [11010/25000]\n",
      "loss: 117.357536  [12010/25000]\n",
      "loss: 205.793823  [13010/25000]\n",
      "loss: 98.893105  [14010/25000]\n",
      "loss: 269.613617  [15010/25000]\n",
      "loss: 114.802933  [16010/25000]\n",
      "loss: 195.467270  [17010/25000]\n",
      "loss: 83.289665  [18010/25000]\n",
      "loss: 53.534946  [19010/25000]\n",
      "loss: 205.676636  [20010/25000]\n",
      "loss: 196.769531  [21010/25000]\n",
      "loss: 178.135269  [22010/25000]\n",
      "loss: 235.941605  [23010/25000]\n",
      "loss: 205.587616  [24010/25000]\n",
      "accuracy: tensor(0.2071)\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 206.369156  [   10/25000]\n",
      "loss: 127.340721  [ 1010/25000]\n",
      "loss: 246.533630  [ 2010/25000]\n",
      "loss: 136.967850  [ 3010/25000]\n",
      "loss: 130.844162  [ 4010/25000]\n",
      "loss: 343.199615  [ 5010/25000]\n",
      "loss: 83.470238  [ 6010/25000]\n",
      "loss: 136.904877  [ 7010/25000]\n",
      "loss: 119.118988  [ 8010/25000]\n",
      "loss: 134.739227  [ 9010/25000]\n",
      "loss: 20.170025  [10010/25000]\n",
      "loss: 107.639297  [11010/25000]\n",
      "loss: 117.342224  [12010/25000]\n",
      "loss: 205.776321  [13010/25000]\n",
      "loss: 98.893494  [14010/25000]\n",
      "loss: 269.607727  [15010/25000]\n",
      "loss: 114.796738  [16010/25000]\n",
      "loss: 195.462875  [17010/25000]\n",
      "loss: 83.278564  [18010/25000]\n",
      "loss: 53.522640  [19010/25000]\n",
      "loss: 205.680710  [20010/25000]\n",
      "loss: 196.772903  [21010/25000]\n",
      "loss: 178.124176  [22010/25000]\n",
      "loss: 235.930191  [23010/25000]\n",
      "loss: 205.580475  [24010/25000]\n",
      "accuracy: tensor(0.2070)\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 206.365005  [   10/25000]\n",
      "loss: 127.330055  [ 1010/25000]\n",
      "loss: 246.518997  [ 2010/25000]\n",
      "loss: 136.964355  [ 3010/25000]\n",
      "loss: 130.833740  [ 4010/25000]\n",
      "loss: 343.185577  [ 5010/25000]\n",
      "loss: 83.457520  [ 6010/25000]\n",
      "loss: 136.897324  [ 7010/25000]\n",
      "loss: 119.110901  [ 8010/25000]\n",
      "loss: 134.724014  [ 9010/25000]\n",
      "loss: 20.167055  [10010/25000]\n",
      "loss: 107.632599  [11010/25000]\n",
      "loss: 117.326797  [12010/25000]\n",
      "loss: 205.758743  [13010/25000]\n",
      "loss: 98.893616  [14010/25000]\n",
      "loss: 269.601959  [15010/25000]\n",
      "loss: 114.790588  [16010/25000]\n",
      "loss: 195.458588  [17010/25000]\n",
      "loss: 83.267448  [18010/25000]\n",
      "loss: 53.510410  [19010/25000]\n",
      "loss: 205.685287  [20010/25000]\n",
      "loss: 196.776413  [21010/25000]\n",
      "loss: 178.113052  [22010/25000]\n",
      "loss: 235.918945  [23010/25000]\n",
      "loss: 205.573334  [24010/25000]\n",
      "accuracy: tensor(0.2070)\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 206.360764  [   10/25000]\n",
      "loss: 127.319382  [ 1010/25000]\n",
      "loss: 246.504349  [ 2010/25000]\n",
      "loss: 136.961060  [ 3010/25000]\n",
      "loss: 130.822906  [ 4010/25000]\n",
      "loss: 343.171692  [ 5010/25000]\n",
      "loss: 83.444717  [ 6010/25000]\n",
      "loss: 136.889435  [ 7010/25000]\n",
      "loss: 119.102814  [ 8010/25000]\n",
      "loss: 134.708862  [ 9010/25000]\n",
      "loss: 20.164125  [10010/25000]\n",
      "loss: 107.625954  [11010/25000]\n",
      "loss: 117.311218  [12010/25000]\n",
      "loss: 205.741425  [13010/25000]\n",
      "loss: 98.893936  [14010/25000]\n",
      "loss: 269.596161  [15010/25000]\n",
      "loss: 114.784309  [16010/25000]\n",
      "loss: 195.454254  [17010/25000]\n",
      "loss: 83.256393  [18010/25000]\n",
      "loss: 53.498207  [19010/25000]\n",
      "loss: 205.689407  [20010/25000]\n",
      "loss: 196.779648  [21010/25000]\n",
      "loss: 178.101913  [22010/25000]\n",
      "loss: 235.907928  [23010/25000]\n",
      "loss: 205.566208  [24010/25000]\n",
      "accuracy: tensor(0.2069)\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 206.356171  [   10/25000]\n",
      "loss: 127.308746  [ 1010/25000]\n",
      "loss: 246.489700  [ 2010/25000]\n",
      "loss: 136.957382  [ 3010/25000]\n",
      "loss: 130.812408  [ 4010/25000]\n",
      "loss: 343.157745  [ 5010/25000]\n",
      "loss: 83.431984  [ 6010/25000]\n",
      "loss: 136.881790  [ 7010/25000]\n",
      "loss: 119.094727  [ 8010/25000]\n",
      "loss: 134.693970  [ 9010/25000]\n",
      "loss: 20.161213  [10010/25000]\n",
      "loss: 107.619514  [11010/25000]\n",
      "loss: 117.295609  [12010/25000]\n",
      "loss: 205.723923  [13010/25000]\n",
      "loss: 98.894348  [14010/25000]\n",
      "loss: 269.590424  [15010/25000]\n",
      "loss: 114.778168  [16010/25000]\n",
      "loss: 195.449997  [17010/25000]\n",
      "loss: 83.245392  [18010/25000]\n",
      "loss: 53.485977  [19010/25000]\n",
      "loss: 205.693237  [20010/25000]\n",
      "loss: 196.782730  [21010/25000]\n",
      "loss: 178.090836  [22010/25000]\n",
      "loss: 235.896439  [23010/25000]\n",
      "loss: 205.559097  [24010/25000]\n",
      "accuracy: tensor(0.2069)\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 206.351990  [   10/25000]\n",
      "loss: 127.298103  [ 1010/25000]\n",
      "loss: 246.475143  [ 2010/25000]\n",
      "loss: 136.954010  [ 3010/25000]\n",
      "loss: 130.801575  [ 4010/25000]\n",
      "loss: 343.143738  [ 5010/25000]\n",
      "loss: 83.419189  [ 6010/25000]\n",
      "loss: 136.874069  [ 7010/25000]\n",
      "loss: 119.086670  [ 8010/25000]\n",
      "loss: 134.678848  [ 9010/25000]\n",
      "loss: 20.158249  [10010/25000]\n",
      "loss: 107.612999  [11010/25000]\n",
      "loss: 117.280701  [12010/25000]\n",
      "loss: 205.706665  [13010/25000]\n",
      "loss: 98.894508  [14010/25000]\n",
      "loss: 269.584656  [15010/25000]\n",
      "loss: 114.772011  [16010/25000]\n",
      "loss: 195.445877  [17010/25000]\n",
      "loss: 83.234398  [18010/25000]\n",
      "loss: 53.473755  [19010/25000]\n",
      "loss: 205.697708  [20010/25000]\n",
      "loss: 196.785873  [21010/25000]\n",
      "loss: 178.079819  [22010/25000]\n",
      "loss: 235.885345  [23010/25000]\n",
      "loss: 205.551987  [24010/25000]\n",
      "accuracy: tensor(0.2068)\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 206.347717  [   10/25000]\n",
      "loss: 127.287521  [ 1010/25000]\n",
      "loss: 246.460571  [ 2010/25000]\n",
      "loss: 136.950485  [ 3010/25000]\n",
      "loss: 130.791168  [ 4010/25000]\n",
      "loss: 343.129791  [ 5010/25000]\n",
      "loss: 83.406433  [ 6010/25000]\n",
      "loss: 136.866455  [ 7010/25000]\n",
      "loss: 119.078568  [ 8010/25000]\n",
      "loss: 134.663849  [ 9010/25000]\n",
      "loss: 20.155273  [10010/25000]\n",
      "loss: 107.606438  [11010/25000]\n",
      "loss: 117.265472  [12010/25000]\n",
      "loss: 205.689011  [13010/25000]\n",
      "loss: 98.894699  [14010/25000]\n",
      "loss: 269.578796  [15010/25000]\n",
      "loss: 114.765907  [16010/25000]\n",
      "loss: 195.441528  [17010/25000]\n",
      "loss: 83.223312  [18010/25000]\n",
      "loss: 53.461582  [19010/25000]\n",
      "loss: 205.701965  [20010/25000]\n",
      "loss: 196.789429  [21010/25000]\n",
      "loss: 178.068710  [22010/25000]\n",
      "loss: 235.874100  [23010/25000]\n",
      "loss: 205.544846  [24010/25000]\n",
      "accuracy: tensor(0.2068)\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 206.343353  [   10/25000]\n",
      "loss: 127.276855  [ 1010/25000]\n",
      "loss: 246.445923  [ 2010/25000]\n",
      "loss: 136.947098  [ 3010/25000]\n",
      "loss: 130.780792  [ 4010/25000]\n",
      "loss: 343.115936  [ 5010/25000]\n",
      "loss: 83.393799  [ 6010/25000]\n",
      "loss: 136.858765  [ 7010/25000]\n",
      "loss: 119.070549  [ 8010/25000]\n",
      "loss: 134.648911  [ 9010/25000]\n",
      "loss: 20.152437  [10010/25000]\n",
      "loss: 107.599739  [11010/25000]\n",
      "loss: 117.249886  [12010/25000]\n",
      "loss: 205.671722  [13010/25000]\n",
      "loss: 98.895241  [14010/25000]\n",
      "loss: 269.573120  [15010/25000]\n",
      "loss: 114.759743  [16010/25000]\n",
      "loss: 195.437363  [17010/25000]\n",
      "loss: 83.212334  [18010/25000]\n",
      "loss: 53.449394  [19010/25000]\n",
      "loss: 205.706192  [20010/25000]\n",
      "loss: 196.792328  [21010/25000]\n",
      "loss: 178.057678  [22010/25000]\n",
      "loss: 235.863129  [23010/25000]\n",
      "loss: 205.537781  [24010/25000]\n",
      "accuracy: tensor(0.2067)\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 206.339264  [   10/25000]\n",
      "loss: 127.266243  [ 1010/25000]\n",
      "loss: 246.431442  [ 2010/25000]\n",
      "loss: 136.943634  [ 3010/25000]\n",
      "loss: 130.770203  [ 4010/25000]\n",
      "loss: 343.102081  [ 5010/25000]\n",
      "loss: 83.381218  [ 6010/25000]\n",
      "loss: 136.851059  [ 7010/25000]\n",
      "loss: 119.062477  [ 8010/25000]\n",
      "loss: 134.633850  [ 9010/25000]\n",
      "loss: 20.149487  [10010/25000]\n",
      "loss: 107.593262  [11010/25000]\n",
      "loss: 117.234695  [12010/25000]\n",
      "loss: 205.654282  [13010/25000]\n",
      "loss: 98.895576  [14010/25000]\n",
      "loss: 269.567352  [15010/25000]\n",
      "loss: 114.753563  [16010/25000]\n",
      "loss: 195.433029  [17010/25000]\n",
      "loss: 83.201393  [18010/25000]\n",
      "loss: 53.437260  [19010/25000]\n",
      "loss: 205.710052  [20010/25000]\n",
      "loss: 196.795898  [21010/25000]\n",
      "loss: 178.046616  [22010/25000]\n",
      "loss: 235.852203  [23010/25000]\n",
      "loss: 205.530701  [24010/25000]\n",
      "accuracy: tensor(0.2066)\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 206.334778  [   10/25000]\n",
      "loss: 127.255684  [ 1010/25000]\n",
      "loss: 246.416840  [ 2010/25000]\n",
      "loss: 136.940231  [ 3010/25000]\n",
      "loss: 130.759613  [ 4010/25000]\n",
      "loss: 343.088135  [ 5010/25000]\n",
      "loss: 83.368446  [ 6010/25000]\n",
      "loss: 136.843384  [ 7010/25000]\n",
      "loss: 119.054466  [ 8010/25000]\n",
      "loss: 134.618942  [ 9010/25000]\n",
      "loss: 20.146570  [10010/25000]\n",
      "loss: 107.586700  [11010/25000]\n",
      "loss: 117.219337  [12010/25000]\n",
      "loss: 205.636932  [13010/25000]\n",
      "loss: 98.895897  [14010/25000]\n",
      "loss: 269.561615  [15010/25000]\n",
      "loss: 114.747414  [16010/25000]\n",
      "loss: 195.428802  [17010/25000]\n",
      "loss: 83.190338  [18010/25000]\n",
      "loss: 53.425125  [19010/25000]\n",
      "loss: 205.714096  [20010/25000]\n",
      "loss: 196.799026  [21010/25000]\n",
      "loss: 178.035645  [22010/25000]\n",
      "loss: 235.840866  [23010/25000]\n",
      "loss: 205.523636  [24010/25000]\n",
      "accuracy: tensor(0.2066)\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 206.330551  [   10/25000]\n",
      "loss: 127.245094  [ 1010/25000]\n",
      "loss: 246.402344  [ 2010/25000]\n",
      "loss: 136.936646  [ 3010/25000]\n",
      "loss: 130.748795  [ 4010/25000]\n",
      "loss: 343.074219  [ 5010/25000]\n",
      "loss: 83.355751  [ 6010/25000]\n",
      "loss: 136.835632  [ 7010/25000]\n",
      "loss: 119.046425  [ 8010/25000]\n",
      "loss: 134.604080  [ 9010/25000]\n",
      "loss: 20.143745  [10010/25000]\n",
      "loss: 107.580193  [11010/25000]\n",
      "loss: 117.204033  [12010/25000]\n",
      "loss: 205.619553  [13010/25000]\n",
      "loss: 98.896271  [14010/25000]\n",
      "loss: 269.555817  [15010/25000]\n",
      "loss: 114.741257  [16010/25000]\n",
      "loss: 195.424713  [17010/25000]\n",
      "loss: 83.179466  [18010/25000]\n",
      "loss: 53.413021  [19010/25000]\n",
      "loss: 205.718445  [20010/25000]\n",
      "loss: 196.802338  [21010/25000]\n",
      "loss: 178.024643  [22010/25000]\n",
      "loss: 235.829544  [23010/25000]\n",
      "loss: 205.516525  [24010/25000]\n",
      "accuracy: tensor(0.2065)\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 206.326263  [   10/25000]\n",
      "loss: 127.234528  [ 1010/25000]\n",
      "loss: 246.387817  [ 2010/25000]\n",
      "loss: 136.933517  [ 3010/25000]\n",
      "loss: 130.738266  [ 4010/25000]\n",
      "loss: 343.060425  [ 5010/25000]\n",
      "loss: 83.343193  [ 6010/25000]\n",
      "loss: 136.828049  [ 7010/25000]\n",
      "loss: 119.038376  [ 8010/25000]\n",
      "loss: 134.589005  [ 9010/25000]\n",
      "loss: 20.140797  [10010/25000]\n",
      "loss: 107.573708  [11010/25000]\n",
      "loss: 117.188820  [12010/25000]\n",
      "loss: 205.602417  [13010/25000]\n",
      "loss: 98.896454  [14010/25000]\n",
      "loss: 269.550018  [15010/25000]\n",
      "loss: 114.735146  [16010/25000]\n",
      "loss: 195.420486  [17010/25000]\n",
      "loss: 83.168480  [18010/25000]\n",
      "loss: 53.400967  [19010/25000]\n",
      "loss: 205.722702  [20010/25000]\n",
      "loss: 196.805542  [21010/25000]\n",
      "loss: 178.013596  [22010/25000]\n",
      "loss: 235.818359  [23010/25000]\n",
      "loss: 205.509460  [24010/25000]\n",
      "accuracy: tensor(0.2065)\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 206.321976  [   10/25000]\n",
      "loss: 127.223976  [ 1010/25000]\n",
      "loss: 246.373337  [ 2010/25000]\n",
      "loss: 136.930038  [ 3010/25000]\n",
      "loss: 130.728088  [ 4010/25000]\n",
      "loss: 343.046600  [ 5010/25000]\n",
      "loss: 83.330521  [ 6010/25000]\n",
      "loss: 136.820328  [ 7010/25000]\n",
      "loss: 119.030418  [ 8010/25000]\n",
      "loss: 134.574173  [ 9010/25000]\n",
      "loss: 20.137831  [10010/25000]\n",
      "loss: 107.567108  [11010/25000]\n",
      "loss: 117.173523  [12010/25000]\n",
      "loss: 205.585098  [13010/25000]\n",
      "loss: 98.896873  [14010/25000]\n",
      "loss: 269.544312  [15010/25000]\n",
      "loss: 114.729027  [16010/25000]\n",
      "loss: 195.416138  [17010/25000]\n",
      "loss: 83.157509  [18010/25000]\n",
      "loss: 53.388771  [19010/25000]\n",
      "loss: 205.726990  [20010/25000]\n",
      "loss: 196.808777  [21010/25000]\n",
      "loss: 178.002640  [22010/25000]\n",
      "loss: 235.807358  [23010/25000]\n",
      "loss: 205.502426  [24010/25000]\n",
      "accuracy: tensor(0.2064)\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 206.318069  [   10/25000]\n",
      "loss: 127.213440  [ 1010/25000]\n",
      "loss: 246.358826  [ 2010/25000]\n",
      "loss: 136.926407  [ 3010/25000]\n",
      "loss: 130.717514  [ 4010/25000]\n",
      "loss: 343.032745  [ 5010/25000]\n",
      "loss: 83.317970  [ 6010/25000]\n",
      "loss: 136.812836  [ 7010/25000]\n",
      "loss: 119.022346  [ 8010/25000]\n",
      "loss: 134.559250  [ 9010/25000]\n",
      "loss: 20.134964  [10010/25000]\n",
      "loss: 107.560638  [11010/25000]\n",
      "loss: 117.158195  [12010/25000]\n",
      "loss: 205.567963  [13010/25000]\n",
      "loss: 98.897087  [14010/25000]\n",
      "loss: 269.538666  [15010/25000]\n",
      "loss: 114.722931  [16010/25000]\n",
      "loss: 195.411804  [17010/25000]\n",
      "loss: 83.146652  [18010/25000]\n",
      "loss: 53.376732  [19010/25000]\n",
      "loss: 205.731262  [20010/25000]\n",
      "loss: 196.812424  [21010/25000]\n",
      "loss: 177.991684  [22010/25000]\n",
      "loss: 235.796204  [23010/25000]\n",
      "loss: 205.495346  [24010/25000]\n",
      "accuracy: tensor(0.2063)\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 206.313736  [   10/25000]\n",
      "loss: 127.202881  [ 1010/25000]\n",
      "loss: 246.344376  [ 2010/25000]\n",
      "loss: 136.923111  [ 3010/25000]\n",
      "loss: 130.706757  [ 4010/25000]\n",
      "loss: 343.018921  [ 5010/25000]\n",
      "loss: 83.305290  [ 6010/25000]\n",
      "loss: 136.805237  [ 7010/25000]\n",
      "loss: 119.014374  [ 8010/25000]\n",
      "loss: 134.544220  [ 9010/25000]\n",
      "loss: 20.132071  [10010/25000]\n",
      "loss: 107.554138  [11010/25000]\n",
      "loss: 117.143059  [12010/25000]\n",
      "loss: 205.550766  [13010/25000]\n",
      "loss: 98.897537  [14010/25000]\n",
      "loss: 269.532898  [15010/25000]\n",
      "loss: 114.716820  [16010/25000]\n",
      "loss: 195.407578  [17010/25000]\n",
      "loss: 83.135681  [18010/25000]\n",
      "loss: 53.364620  [19010/25000]\n",
      "loss: 205.735001  [20010/25000]\n",
      "loss: 196.815353  [21010/25000]\n",
      "loss: 177.980728  [22010/25000]\n",
      "loss: 235.785019  [23010/25000]\n",
      "loss: 205.488327  [24010/25000]\n",
      "accuracy: tensor(0.2063)\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 206.309448  [   10/25000]\n",
      "loss: 127.192383  [ 1010/25000]\n",
      "loss: 246.329926  [ 2010/25000]\n",
      "loss: 136.919617  [ 3010/25000]\n",
      "loss: 130.696518  [ 4010/25000]\n",
      "loss: 343.005157  [ 5010/25000]\n",
      "loss: 83.292526  [ 6010/25000]\n",
      "loss: 136.797531  [ 7010/25000]\n",
      "loss: 119.006393  [ 8010/25000]\n",
      "loss: 134.529388  [ 9010/25000]\n",
      "loss: 20.129082  [10010/25000]\n",
      "loss: 107.547546  [11010/25000]\n",
      "loss: 117.127754  [12010/25000]\n",
      "loss: 205.533264  [13010/25000]\n",
      "loss: 98.897858  [14010/25000]\n",
      "loss: 269.527435  [15010/25000]\n",
      "loss: 114.710716  [16010/25000]\n",
      "loss: 195.403549  [17010/25000]\n",
      "loss: 83.124786  [18010/25000]\n",
      "loss: 53.352585  [19010/25000]\n",
      "loss: 205.739731  [20010/25000]\n",
      "loss: 196.818939  [21010/25000]\n",
      "loss: 177.969772  [22010/25000]\n",
      "loss: 235.774109  [23010/25000]\n",
      "loss: 205.481293  [24010/25000]\n",
      "accuracy: tensor(0.2062)\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 206.305191  [   10/25000]\n",
      "loss: 127.181877  [ 1010/25000]\n",
      "loss: 246.315506  [ 2010/25000]\n",
      "loss: 136.916214  [ 3010/25000]\n",
      "loss: 130.685883  [ 4010/25000]\n",
      "loss: 342.991394  [ 5010/25000]\n",
      "loss: 83.280136  [ 6010/25000]\n",
      "loss: 136.789841  [ 7010/25000]\n",
      "loss: 118.998436  [ 8010/25000]\n",
      "loss: 134.514603  [ 9010/25000]\n",
      "loss: 20.126301  [10010/25000]\n",
      "loss: 107.541260  [11010/25000]\n",
      "loss: 117.112640  [12010/25000]\n",
      "loss: 205.516113  [13010/25000]\n",
      "loss: 98.898254  [14010/25000]\n",
      "loss: 269.521606  [15010/25000]\n",
      "loss: 114.704597  [16010/25000]\n",
      "loss: 195.399231  [17010/25000]\n",
      "loss: 83.113884  [18010/25000]\n",
      "loss: 53.340591  [19010/25000]\n",
      "loss: 205.743851  [20010/25000]\n",
      "loss: 196.822037  [21010/25000]\n",
      "loss: 177.958786  [22010/25000]\n",
      "loss: 235.763321  [23010/25000]\n",
      "loss: 205.474243  [24010/25000]\n",
      "accuracy: tensor(0.2062)\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 206.301071  [   10/25000]\n",
      "loss: 127.171394  [ 1010/25000]\n",
      "loss: 246.301071  [ 2010/25000]\n",
      "loss: 136.912842  [ 3010/25000]\n",
      "loss: 130.675522  [ 4010/25000]\n",
      "loss: 342.977539  [ 5010/25000]\n",
      "loss: 83.267532  [ 6010/25000]\n",
      "loss: 136.782272  [ 7010/25000]\n",
      "loss: 118.990456  [ 8010/25000]\n",
      "loss: 134.499695  [ 9010/25000]\n",
      "loss: 20.123425  [10010/25000]\n",
      "loss: 107.534760  [11010/25000]\n",
      "loss: 117.097504  [12010/25000]\n",
      "loss: 205.498795  [13010/25000]\n",
      "loss: 98.898651  [14010/25000]\n",
      "loss: 269.515991  [15010/25000]\n",
      "loss: 114.698494  [16010/25000]\n",
      "loss: 195.395035  [17010/25000]\n",
      "loss: 83.102997  [18010/25000]\n",
      "loss: 53.328590  [19010/25000]\n",
      "loss: 205.748383  [20010/25000]\n",
      "loss: 196.825470  [21010/25000]\n",
      "loss: 177.947845  [22010/25000]\n",
      "loss: 235.752151  [23010/25000]\n",
      "loss: 205.467270  [24010/25000]\n",
      "accuracy: tensor(0.2061)\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 206.296570  [   10/25000]\n",
      "loss: 127.160912  [ 1010/25000]\n",
      "loss: 246.286743  [ 2010/25000]\n",
      "loss: 136.909485  [ 3010/25000]\n",
      "loss: 130.665161  [ 4010/25000]\n",
      "loss: 342.963867  [ 5010/25000]\n",
      "loss: 83.254883  [ 6010/25000]\n",
      "loss: 136.774719  [ 7010/25000]\n",
      "loss: 118.982513  [ 8010/25000]\n",
      "loss: 134.484802  [ 9010/25000]\n",
      "loss: 20.120459  [10010/25000]\n",
      "loss: 107.528152  [11010/25000]\n",
      "loss: 117.082207  [12010/25000]\n",
      "loss: 205.481781  [13010/25000]\n",
      "loss: 98.899124  [14010/25000]\n",
      "loss: 269.510193  [15010/25000]\n",
      "loss: 114.692406  [16010/25000]\n",
      "loss: 195.390991  [17010/25000]\n",
      "loss: 83.092140  [18010/25000]\n",
      "loss: 53.316601  [19010/25000]\n",
      "loss: 205.752441  [20010/25000]\n",
      "loss: 196.828751  [21010/25000]\n",
      "loss: 177.936935  [22010/25000]\n",
      "loss: 235.740921  [23010/25000]\n",
      "loss: 205.460236  [24010/25000]\n",
      "accuracy: tensor(0.2061)\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 206.292618  [   10/25000]\n",
      "loss: 127.150429  [ 1010/25000]\n",
      "loss: 246.272308  [ 2010/25000]\n",
      "loss: 136.906235  [ 3010/25000]\n",
      "loss: 130.654678  [ 4010/25000]\n",
      "loss: 342.950165  [ 5010/25000]\n",
      "loss: 83.242363  [ 6010/25000]\n",
      "loss: 136.767136  [ 7010/25000]\n",
      "loss: 118.974571  [ 8010/25000]\n",
      "loss: 134.470032  [ 9010/25000]\n",
      "loss: 20.117657  [10010/25000]\n",
      "loss: 107.521721  [11010/25000]\n",
      "loss: 117.066780  [12010/25000]\n",
      "loss: 205.464432  [13010/25000]\n",
      "loss: 98.899345  [14010/25000]\n",
      "loss: 269.504608  [15010/25000]\n",
      "loss: 114.686340  [16010/25000]\n",
      "loss: 195.386719  [17010/25000]\n",
      "loss: 83.081276  [18010/25000]\n",
      "loss: 53.304611  [19010/25000]\n",
      "loss: 205.756470  [20010/25000]\n",
      "loss: 196.831833  [21010/25000]\n",
      "loss: 177.926086  [22010/25000]\n",
      "loss: 235.729843  [23010/25000]\n",
      "loss: 205.453247  [24010/25000]\n",
      "accuracy: tensor(0.2060)\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 206.288422  [   10/25000]\n",
      "loss: 127.139915  [ 1010/25000]\n",
      "loss: 246.257935  [ 2010/25000]\n",
      "loss: 136.902878  [ 3010/25000]\n",
      "loss: 130.644348  [ 4010/25000]\n",
      "loss: 342.936401  [ 5010/25000]\n",
      "loss: 83.229881  [ 6010/25000]\n",
      "loss: 136.759491  [ 7010/25000]\n",
      "loss: 118.966591  [ 8010/25000]\n",
      "loss: 134.455200  [ 9010/25000]\n",
      "loss: 20.114746  [10010/25000]\n",
      "loss: 107.515244  [11010/25000]\n",
      "loss: 117.051834  [12010/25000]\n",
      "loss: 205.447449  [13010/25000]\n",
      "loss: 98.899811  [14010/25000]\n",
      "loss: 269.499115  [15010/25000]\n",
      "loss: 114.680244  [16010/25000]\n",
      "loss: 195.382553  [17010/25000]\n",
      "loss: 83.070480  [18010/25000]\n",
      "loss: 53.292660  [19010/25000]\n",
      "loss: 205.760529  [20010/25000]\n",
      "loss: 196.835266  [21010/25000]\n",
      "loss: 177.915131  [22010/25000]\n",
      "loss: 235.718796  [23010/25000]\n",
      "loss: 205.446228  [24010/25000]\n",
      "accuracy: tensor(0.2059)\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 206.284378  [   10/25000]\n",
      "loss: 127.129463  [ 1010/25000]\n",
      "loss: 246.243576  [ 2010/25000]\n",
      "loss: 136.899460  [ 3010/25000]\n",
      "loss: 130.633942  [ 4010/25000]\n",
      "loss: 342.922699  [ 5010/25000]\n",
      "loss: 83.217377  [ 6010/25000]\n",
      "loss: 136.752045  [ 7010/25000]\n",
      "loss: 118.958679  [ 8010/25000]\n",
      "loss: 134.440338  [ 9010/25000]\n",
      "loss: 20.111858  [10010/25000]\n",
      "loss: 107.508888  [11010/25000]\n",
      "loss: 117.036896  [12010/25000]\n",
      "loss: 205.430237  [13010/25000]\n",
      "loss: 98.899963  [14010/25000]\n",
      "loss: 269.493347  [15010/25000]\n",
      "loss: 114.674225  [16010/25000]\n",
      "loss: 195.378479  [17010/25000]\n",
      "loss: 83.059570  [18010/25000]\n",
      "loss: 53.280708  [19010/25000]\n",
      "loss: 205.765182  [20010/25000]\n",
      "loss: 196.838440  [21010/25000]\n",
      "loss: 177.904297  [22010/25000]\n",
      "loss: 235.707825  [23010/25000]\n",
      "loss: 205.439240  [24010/25000]\n",
      "accuracy: tensor(0.2059)\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 206.279984  [   10/25000]\n",
      "loss: 127.119026  [ 1010/25000]\n",
      "loss: 246.229263  [ 2010/25000]\n",
      "loss: 136.896332  [ 3010/25000]\n",
      "loss: 130.623596  [ 4010/25000]\n",
      "loss: 342.908936  [ 5010/25000]\n",
      "loss: 83.204735  [ 6010/25000]\n",
      "loss: 136.744385  [ 7010/25000]\n",
      "loss: 118.950745  [ 8010/25000]\n",
      "loss: 134.425507  [ 9010/25000]\n",
      "loss: 20.108994  [10010/25000]\n",
      "loss: 107.502350  [11010/25000]\n",
      "loss: 117.021660  [12010/25000]\n",
      "loss: 205.413208  [13010/25000]\n",
      "loss: 98.900467  [14010/25000]\n",
      "loss: 269.487701  [15010/25000]\n",
      "loss: 114.668182  [16010/25000]\n",
      "loss: 195.374252  [17010/25000]\n",
      "loss: 83.048752  [18010/25000]\n",
      "loss: 53.268829  [19010/25000]\n",
      "loss: 205.769241  [20010/25000]\n",
      "loss: 196.841919  [21010/25000]\n",
      "loss: 177.893433  [22010/25000]\n",
      "loss: 235.697037  [23010/25000]\n",
      "loss: 205.432266  [24010/25000]\n",
      "accuracy: tensor(0.2058)\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 206.275696  [   10/25000]\n",
      "loss: 127.108566  [ 1010/25000]\n",
      "loss: 246.214905  [ 2010/25000]\n",
      "loss: 136.893005  [ 3010/25000]\n",
      "loss: 130.613083  [ 4010/25000]\n",
      "loss: 342.895325  [ 5010/25000]\n",
      "loss: 83.192215  [ 6010/25000]\n",
      "loss: 136.736893  [ 7010/25000]\n",
      "loss: 118.942848  [ 8010/25000]\n",
      "loss: 134.410797  [ 9010/25000]\n",
      "loss: 20.106007  [10010/25000]\n",
      "loss: 107.495956  [11010/25000]\n",
      "loss: 117.006485  [12010/25000]\n",
      "loss: 205.396179  [13010/25000]\n",
      "loss: 98.900925  [14010/25000]\n",
      "loss: 269.482117  [15010/25000]\n",
      "loss: 114.662132  [16010/25000]\n",
      "loss: 195.370163  [17010/25000]\n",
      "loss: 83.037994  [18010/25000]\n",
      "loss: 53.256805  [19010/25000]\n",
      "loss: 205.773590  [20010/25000]\n",
      "loss: 196.845062  [21010/25000]\n",
      "loss: 177.882584  [22010/25000]\n",
      "loss: 235.685974  [23010/25000]\n",
      "loss: 205.425308  [24010/25000]\n",
      "accuracy: tensor(0.2058)\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 206.271408  [   10/25000]\n",
      "loss: 127.098221  [ 1010/25000]\n",
      "loss: 246.200607  [ 2010/25000]\n",
      "loss: 136.889526  [ 3010/25000]\n",
      "loss: 130.602692  [ 4010/25000]\n",
      "loss: 342.881653  [ 5010/25000]\n",
      "loss: 83.179855  [ 6010/25000]\n",
      "loss: 136.729279  [ 7010/25000]\n",
      "loss: 118.934944  [ 8010/25000]\n",
      "loss: 134.396011  [ 9010/25000]\n",
      "loss: 20.103188  [10010/25000]\n",
      "loss: 107.489639  [11010/25000]\n",
      "loss: 116.991394  [12010/25000]\n",
      "loss: 205.378983  [13010/25000]\n",
      "loss: 98.901291  [14010/25000]\n",
      "loss: 269.476532  [15010/25000]\n",
      "loss: 114.656052  [16010/25000]\n",
      "loss: 195.365982  [17010/25000]\n",
      "loss: 83.027161  [18010/25000]\n",
      "loss: 53.244938  [19010/25000]\n",
      "loss: 205.777740  [20010/25000]\n",
      "loss: 196.848373  [21010/25000]\n",
      "loss: 177.871765  [22010/25000]\n",
      "loss: 235.674866  [23010/25000]\n",
      "loss: 205.418320  [24010/25000]\n",
      "accuracy: tensor(0.2057)\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 206.267487  [   10/25000]\n",
      "loss: 127.087822  [ 1010/25000]\n",
      "loss: 246.186310  [ 2010/25000]\n",
      "loss: 136.886246  [ 3010/25000]\n",
      "loss: 130.592209  [ 4010/25000]\n",
      "loss: 342.868011  [ 5010/25000]\n",
      "loss: 83.167381  [ 6010/25000]\n",
      "loss: 136.721756  [ 7010/25000]\n",
      "loss: 118.927063  [ 8010/25000]\n",
      "loss: 134.381287  [ 9010/25000]\n",
      "loss: 20.100340  [10010/25000]\n",
      "loss: 107.483109  [11010/25000]\n",
      "loss: 116.976357  [12010/25000]\n",
      "loss: 205.361908  [13010/25000]\n",
      "loss: 98.901726  [14010/25000]\n",
      "loss: 269.470825  [15010/25000]\n",
      "loss: 114.649971  [16010/25000]\n",
      "loss: 195.361801  [17010/25000]\n",
      "loss: 83.016472  [18010/25000]\n",
      "loss: 53.233067  [19010/25000]\n",
      "loss: 205.782318  [20010/25000]\n",
      "loss: 196.851746  [21010/25000]\n",
      "loss: 177.860825  [22010/25000]\n",
      "loss: 235.664124  [23010/25000]\n",
      "loss: 205.411362  [24010/25000]\n",
      "accuracy: tensor(0.2056)\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 206.263367  [   10/25000]\n",
      "loss: 127.077461  [ 1010/25000]\n",
      "loss: 246.172058  [ 2010/25000]\n",
      "loss: 136.882828  [ 3010/25000]\n",
      "loss: 130.581772  [ 4010/25000]\n",
      "loss: 342.854370  [ 5010/25000]\n",
      "loss: 83.154831  [ 6010/25000]\n",
      "loss: 136.714233  [ 7010/25000]\n",
      "loss: 118.919151  [ 8010/25000]\n",
      "loss: 134.366608  [ 9010/25000]\n",
      "loss: 20.097483  [10010/25000]\n",
      "loss: 107.476631  [11010/25000]\n",
      "loss: 116.961365  [12010/25000]\n",
      "loss: 205.344879  [13010/25000]\n",
      "loss: 98.902161  [14010/25000]\n",
      "loss: 269.465240  [15010/25000]\n",
      "loss: 114.643997  [16010/25000]\n",
      "loss: 195.357697  [17010/25000]\n",
      "loss: 83.005646  [18010/25000]\n",
      "loss: 53.221188  [19010/25000]\n",
      "loss: 205.786255  [20010/25000]\n",
      "loss: 196.855118  [21010/25000]\n",
      "loss: 177.850082  [22010/25000]\n",
      "loss: 235.653259  [23010/25000]\n",
      "loss: 205.404419  [24010/25000]\n",
      "accuracy: tensor(0.2056)\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 206.259140  [   10/25000]\n",
      "loss: 127.067070  [ 1010/25000]\n",
      "loss: 246.157776  [ 2010/25000]\n",
      "loss: 136.879822  [ 3010/25000]\n",
      "loss: 130.571716  [ 4010/25000]\n",
      "loss: 342.840820  [ 5010/25000]\n",
      "loss: 83.142448  [ 6010/25000]\n",
      "loss: 136.706680  [ 7010/25000]\n",
      "loss: 118.911270  [ 8010/25000]\n",
      "loss: 134.351868  [ 9010/25000]\n",
      "loss: 20.094694  [10010/25000]\n",
      "loss: 107.470284  [11010/25000]\n",
      "loss: 116.946388  [12010/25000]\n",
      "loss: 205.328079  [13010/25000]\n",
      "loss: 98.902512  [14010/25000]\n",
      "loss: 269.459595  [15010/25000]\n",
      "loss: 114.637932  [16010/25000]\n",
      "loss: 195.353516  [17010/25000]\n",
      "loss: 82.994865  [18010/25000]\n",
      "loss: 53.209335  [19010/25000]\n",
      "loss: 205.790680  [20010/25000]\n",
      "loss: 196.858246  [21010/25000]\n",
      "loss: 177.839294  [22010/25000]\n",
      "loss: 235.642365  [23010/25000]\n",
      "loss: 205.397476  [24010/25000]\n",
      "accuracy: tensor(0.2055)\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 206.255066  [   10/25000]\n",
      "loss: 127.056717  [ 1010/25000]\n",
      "loss: 246.143509  [ 2010/25000]\n",
      "loss: 136.876450  [ 3010/25000]\n",
      "loss: 130.561188  [ 4010/25000]\n",
      "loss: 342.827148  [ 5010/25000]\n",
      "loss: 83.130035  [ 6010/25000]\n",
      "loss: 136.699127  [ 7010/25000]\n",
      "loss: 118.903412  [ 8010/25000]\n",
      "loss: 134.337143  [ 9010/25000]\n",
      "loss: 20.091742  [10010/25000]\n",
      "loss: 107.463905  [11010/25000]\n",
      "loss: 116.931335  [12010/25000]\n",
      "loss: 205.310760  [13010/25000]\n",
      "loss: 98.902901  [14010/25000]\n",
      "loss: 269.454010  [15010/25000]\n",
      "loss: 114.631912  [16010/25000]\n",
      "loss: 195.349396  [17010/25000]\n",
      "loss: 82.984131  [18010/25000]\n",
      "loss: 53.197521  [19010/25000]\n",
      "loss: 205.794647  [20010/25000]\n",
      "loss: 196.861328  [21010/25000]\n",
      "loss: 177.828568  [22010/25000]\n",
      "loss: 235.631409  [23010/25000]\n",
      "loss: 205.390549  [24010/25000]\n",
      "accuracy: tensor(0.2055)\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 206.250931  [   10/25000]\n",
      "loss: 127.046349  [ 1010/25000]\n",
      "loss: 246.129303  [ 2010/25000]\n",
      "loss: 136.872925  [ 3010/25000]\n",
      "loss: 130.550980  [ 4010/25000]\n",
      "loss: 342.813507  [ 5010/25000]\n",
      "loss: 83.117577  [ 6010/25000]\n",
      "loss: 136.691757  [ 7010/25000]\n",
      "loss: 118.895546  [ 8010/25000]\n",
      "loss: 134.322662  [ 9010/25000]\n",
      "loss: 20.088924  [10010/25000]\n",
      "loss: 107.457474  [11010/25000]\n",
      "loss: 116.916252  [12010/25000]\n",
      "loss: 205.294098  [13010/25000]\n",
      "loss: 98.903206  [14010/25000]\n",
      "loss: 269.448517  [15010/25000]\n",
      "loss: 114.625938  [16010/25000]\n",
      "loss: 195.345306  [17010/25000]\n",
      "loss: 82.973419  [18010/25000]\n",
      "loss: 53.185699  [19010/25000]\n",
      "loss: 205.798782  [20010/25000]\n",
      "loss: 196.865036  [21010/25000]\n",
      "loss: 177.817734  [22010/25000]\n",
      "loss: 235.620377  [23010/25000]\n",
      "loss: 205.383606  [24010/25000]\n",
      "accuracy: tensor(0.2054)\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 206.246872  [   10/25000]\n",
      "loss: 127.035950  [ 1010/25000]\n",
      "loss: 246.115036  [ 2010/25000]\n",
      "loss: 136.869919  [ 3010/25000]\n",
      "loss: 130.540710  [ 4010/25000]\n",
      "loss: 342.799988  [ 5010/25000]\n",
      "loss: 83.105202  [ 6010/25000]\n",
      "loss: 136.684204  [ 7010/25000]\n",
      "loss: 118.887718  [ 8010/25000]\n",
      "loss: 134.308044  [ 9010/25000]\n",
      "loss: 20.086090  [10010/25000]\n",
      "loss: 107.451096  [11010/25000]\n",
      "loss: 116.901337  [12010/25000]\n",
      "loss: 205.276871  [13010/25000]\n",
      "loss: 98.903839  [14010/25000]\n",
      "loss: 269.442963  [15010/25000]\n",
      "loss: 114.619965  [16010/25000]\n",
      "loss: 195.341293  [17010/25000]\n",
      "loss: 82.962669  [18010/25000]\n",
      "loss: 53.173878  [19010/25000]\n",
      "loss: 205.803207  [20010/25000]\n",
      "loss: 196.868011  [21010/25000]\n",
      "loss: 177.806946  [22010/25000]\n",
      "loss: 235.609650  [23010/25000]\n",
      "loss: 205.376694  [24010/25000]\n",
      "accuracy: tensor(0.2054)\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 206.242661  [   10/25000]\n",
      "loss: 127.025604  [ 1010/25000]\n",
      "loss: 246.100922  [ 2010/25000]\n",
      "loss: 136.866608  [ 3010/25000]\n",
      "loss: 130.530075  [ 4010/25000]\n",
      "loss: 342.786438  [ 5010/25000]\n",
      "loss: 83.092621  [ 6010/25000]\n",
      "loss: 136.676773  [ 7010/25000]\n",
      "loss: 118.879845  [ 8010/25000]\n",
      "loss: 134.293152  [ 9010/25000]\n",
      "loss: 20.083138  [10010/25000]\n",
      "loss: 107.444588  [11010/25000]\n",
      "loss: 116.886482  [12010/25000]\n",
      "loss: 205.260269  [13010/25000]\n",
      "loss: 98.904320  [14010/25000]\n",
      "loss: 269.437469  [15010/25000]\n",
      "loss: 114.613983  [16010/25000]\n",
      "loss: 195.337128  [17010/25000]\n",
      "loss: 82.951912  [18010/25000]\n",
      "loss: 53.162090  [19010/25000]\n",
      "loss: 205.807388  [20010/25000]\n",
      "loss: 196.871780  [21010/25000]\n",
      "loss: 177.796158  [22010/25000]\n",
      "loss: 235.598892  [23010/25000]\n",
      "loss: 205.369766  [24010/25000]\n",
      "accuracy: tensor(0.2053)\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 206.238647  [   10/25000]\n",
      "loss: 127.015312  [ 1010/25000]\n",
      "loss: 246.086731  [ 2010/25000]\n",
      "loss: 136.863190  [ 3010/25000]\n",
      "loss: 130.519836  [ 4010/25000]\n",
      "loss: 342.772858  [ 5010/25000]\n",
      "loss: 83.080345  [ 6010/25000]\n",
      "loss: 136.669098  [ 7010/25000]\n",
      "loss: 118.871994  [ 8010/25000]\n",
      "loss: 134.278610  [ 9010/25000]\n",
      "loss: 20.080364  [10010/25000]\n",
      "loss: 107.438385  [11010/25000]\n",
      "loss: 116.871330  [12010/25000]\n",
      "loss: 205.243179  [13010/25000]\n",
      "loss: 98.904602  [14010/25000]\n",
      "loss: 269.431915  [15010/25000]\n",
      "loss: 114.607933  [16010/25000]\n",
      "loss: 195.332947  [17010/25000]\n",
      "loss: 82.941223  [18010/25000]\n",
      "loss: 53.150265  [19010/25000]\n",
      "loss: 205.811386  [20010/25000]\n",
      "loss: 196.874786  [21010/25000]\n",
      "loss: 177.785385  [22010/25000]\n",
      "loss: 235.587906  [23010/25000]\n",
      "loss: 205.362915  [24010/25000]\n",
      "accuracy: tensor(0.2052)\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 206.234497  [   10/25000]\n",
      "loss: 127.004990  [ 1010/25000]\n",
      "loss: 246.072479  [ 2010/25000]\n",
      "loss: 136.860016  [ 3010/25000]\n",
      "loss: 130.509338  [ 4010/25000]\n",
      "loss: 342.759369  [ 5010/25000]\n",
      "loss: 83.068008  [ 6010/25000]\n",
      "loss: 136.661682  [ 7010/25000]\n",
      "loss: 118.864182  [ 8010/25000]\n",
      "loss: 134.264175  [ 9010/25000]\n",
      "loss: 20.077534  [10010/25000]\n",
      "loss: 107.431915  [11010/25000]\n",
      "loss: 116.856407  [12010/25000]\n",
      "loss: 205.226166  [13010/25000]\n",
      "loss: 98.904831  [14010/25000]\n",
      "loss: 269.426270  [15010/25000]\n",
      "loss: 114.601959  [16010/25000]\n",
      "loss: 195.328827  [17010/25000]\n",
      "loss: 82.930534  [18010/25000]\n",
      "loss: 53.138519  [19010/25000]\n",
      "loss: 205.816116  [20010/25000]\n",
      "loss: 196.878021  [21010/25000]\n",
      "loss: 177.774673  [22010/25000]\n",
      "loss: 235.577011  [23010/25000]\n",
      "loss: 205.356003  [24010/25000]\n",
      "accuracy: tensor(0.2052)\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 206.230286  [   10/25000]\n",
      "loss: 126.994637  [ 1010/25000]\n",
      "loss: 246.058365  [ 2010/25000]\n",
      "loss: 136.856888  [ 3010/25000]\n",
      "loss: 130.499252  [ 4010/25000]\n",
      "loss: 342.745850  [ 5010/25000]\n",
      "loss: 83.055519  [ 6010/25000]\n",
      "loss: 136.654144  [ 7010/25000]\n",
      "loss: 118.856369  [ 8010/25000]\n",
      "loss: 134.249466  [ 9010/25000]\n",
      "loss: 20.074638  [10010/25000]\n",
      "loss: 107.425560  [11010/25000]\n",
      "loss: 116.841560  [12010/25000]\n",
      "loss: 205.209183  [13010/25000]\n",
      "loss: 98.905212  [14010/25000]\n",
      "loss: 269.420929  [15010/25000]\n",
      "loss: 114.595978  [16010/25000]\n",
      "loss: 195.324799  [17010/25000]\n",
      "loss: 82.919914  [18010/25000]\n",
      "loss: 53.126778  [19010/25000]\n",
      "loss: 205.820312  [20010/25000]\n",
      "loss: 196.881897  [21010/25000]\n",
      "loss: 177.764038  [22010/25000]\n",
      "loss: 235.566330  [23010/25000]\n",
      "loss: 205.349075  [24010/25000]\n",
      "accuracy: tensor(0.2051)\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 206.226257  [   10/25000]\n",
      "loss: 126.984299  [ 1010/25000]\n",
      "loss: 246.044235  [ 2010/25000]\n",
      "loss: 136.853531  [ 3010/25000]\n",
      "loss: 130.488998  [ 4010/25000]\n",
      "loss: 342.732391  [ 5010/25000]\n",
      "loss: 83.043274  [ 6010/25000]\n",
      "loss: 136.646774  [ 7010/25000]\n",
      "loss: 118.848557  [ 8010/25000]\n",
      "loss: 134.234802  [ 9010/25000]\n",
      "loss: 20.071846  [10010/25000]\n",
      "loss: 107.419220  [11010/25000]\n",
      "loss: 116.826515  [12010/25000]\n",
      "loss: 205.192322  [13010/25000]\n",
      "loss: 98.906075  [14010/25000]\n",
      "loss: 269.415283  [15010/25000]\n",
      "loss: 114.590027  [16010/25000]\n",
      "loss: 195.320786  [17010/25000]\n",
      "loss: 82.909157  [18010/25000]\n",
      "loss: 53.115009  [19010/25000]\n",
      "loss: 205.824265  [20010/25000]\n",
      "loss: 196.884705  [21010/25000]\n",
      "loss: 177.753235  [22010/25000]\n",
      "loss: 235.555222  [23010/25000]\n",
      "loss: 205.342224  [24010/25000]\n",
      "accuracy: tensor(0.2051)\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 206.222260  [   10/25000]\n",
      "loss: 126.974060  [ 1010/25000]\n",
      "loss: 246.030136  [ 2010/25000]\n",
      "loss: 136.850388  [ 3010/25000]\n",
      "loss: 130.478638  [ 4010/25000]\n",
      "loss: 342.718842  [ 5010/25000]\n",
      "loss: 83.030914  [ 6010/25000]\n",
      "loss: 136.639389  [ 7010/25000]\n",
      "loss: 118.840714  [ 8010/25000]\n",
      "loss: 134.220276  [ 9010/25000]\n",
      "loss: 20.069046  [10010/25000]\n",
      "loss: 107.412956  [11010/25000]\n",
      "loss: 116.811584  [12010/25000]\n",
      "loss: 205.175476  [13010/25000]\n",
      "loss: 98.906525  [14010/25000]\n",
      "loss: 269.409790  [15010/25000]\n",
      "loss: 114.584053  [16010/25000]\n",
      "loss: 195.316849  [17010/25000]\n",
      "loss: 82.898514  [18010/25000]\n",
      "loss: 53.103294  [19010/25000]\n",
      "loss: 205.828705  [20010/25000]\n",
      "loss: 196.888199  [21010/25000]\n",
      "loss: 177.742493  [22010/25000]\n",
      "loss: 235.544632  [23010/25000]\n",
      "loss: 205.335358  [24010/25000]\n",
      "accuracy: tensor(0.2050)\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 206.218109  [   10/25000]\n",
      "loss: 126.963860  [ 1010/25000]\n",
      "loss: 246.016068  [ 2010/25000]\n",
      "loss: 136.847122  [ 3010/25000]\n",
      "loss: 130.468063  [ 4010/25000]\n",
      "loss: 342.705353  [ 5010/25000]\n",
      "loss: 83.018631  [ 6010/25000]\n",
      "loss: 136.631836  [ 7010/25000]\n",
      "loss: 118.832939  [ 8010/25000]\n",
      "loss: 134.205658  [ 9010/25000]\n",
      "loss: 20.066046  [10010/25000]\n",
      "loss: 107.406464  [11010/25000]\n",
      "loss: 116.796913  [12010/25000]\n",
      "loss: 205.158615  [13010/25000]\n",
      "loss: 98.906906  [14010/25000]\n",
      "loss: 269.404419  [15010/25000]\n",
      "loss: 114.578026  [16010/25000]\n",
      "loss: 195.312561  [17010/25000]\n",
      "loss: 82.887840  [18010/25000]\n",
      "loss: 53.091618  [19010/25000]\n",
      "loss: 205.833054  [20010/25000]\n",
      "loss: 196.891739  [21010/25000]\n",
      "loss: 177.731812  [22010/25000]\n",
      "loss: 235.533737  [23010/25000]\n",
      "loss: 205.328461  [24010/25000]\n",
      "accuracy: tensor(0.2049)\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 206.214142  [   10/25000]\n",
      "loss: 126.953613  [ 1010/25000]\n",
      "loss: 246.001938  [ 2010/25000]\n",
      "loss: 136.843872  [ 3010/25000]\n",
      "loss: 130.457718  [ 4010/25000]\n",
      "loss: 342.691925  [ 5010/25000]\n",
      "loss: 83.006180  [ 6010/25000]\n",
      "loss: 136.624451  [ 7010/25000]\n",
      "loss: 118.825119  [ 8010/25000]\n",
      "loss: 134.191193  [ 9010/25000]\n",
      "loss: 20.063318  [10010/25000]\n",
      "loss: 107.400185  [11010/25000]\n",
      "loss: 116.781700  [12010/25000]\n",
      "loss: 205.141678  [13010/25000]\n",
      "loss: 98.907341  [14010/25000]\n",
      "loss: 269.398804  [15010/25000]\n",
      "loss: 114.572166  [16010/25000]\n",
      "loss: 195.308578  [17010/25000]\n",
      "loss: 82.877228  [18010/25000]\n",
      "loss: 53.079956  [19010/25000]\n",
      "loss: 205.837128  [20010/25000]\n",
      "loss: 196.894897  [21010/25000]\n",
      "loss: 177.721146  [22010/25000]\n",
      "loss: 235.523010  [23010/25000]\n",
      "loss: 205.321640  [24010/25000]\n",
      "accuracy: tensor(0.2049)\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 206.210052  [   10/25000]\n",
      "loss: 126.943390  [ 1010/25000]\n",
      "loss: 245.987839  [ 2010/25000]\n",
      "loss: 136.840729  [ 3010/25000]\n",
      "loss: 130.447601  [ 4010/25000]\n",
      "loss: 342.678436  [ 5010/25000]\n",
      "loss: 82.993935  [ 6010/25000]\n",
      "loss: 136.616791  [ 7010/25000]\n",
      "loss: 118.817360  [ 8010/25000]\n",
      "loss: 134.176620  [ 9010/25000]\n",
      "loss: 20.060495  [10010/25000]\n",
      "loss: 107.393860  [11010/25000]\n",
      "loss: 116.766953  [12010/25000]\n",
      "loss: 205.124863  [13010/25000]\n",
      "loss: 98.907814  [14010/25000]\n",
      "loss: 269.393311  [15010/25000]\n",
      "loss: 114.566254  [16010/25000]\n",
      "loss: 195.304459  [17010/25000]\n",
      "loss: 82.866600  [18010/25000]\n",
      "loss: 53.068256  [19010/25000]\n",
      "loss: 205.841446  [20010/25000]\n",
      "loss: 196.898392  [21010/25000]\n",
      "loss: 177.710510  [22010/25000]\n",
      "loss: 235.512421  [23010/25000]\n",
      "loss: 205.314758  [24010/25000]\n",
      "accuracy: tensor(0.2048)\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 206.205826  [   10/25000]\n",
      "loss: 126.933105  [ 1010/25000]\n",
      "loss: 245.973785  [ 2010/25000]\n",
      "loss: 136.837708  [ 3010/25000]\n",
      "loss: 130.437607  [ 4010/25000]\n",
      "loss: 342.665039  [ 5010/25000]\n",
      "loss: 82.981583  [ 6010/25000]\n",
      "loss: 136.609390  [ 7010/25000]\n",
      "loss: 118.809563  [ 8010/25000]\n",
      "loss: 134.162064  [ 9010/25000]\n",
      "loss: 20.057646  [10010/25000]\n",
      "loss: 107.387596  [11010/25000]\n",
      "loss: 116.752228  [12010/25000]\n",
      "loss: 205.108215  [13010/25000]\n",
      "loss: 98.908310  [14010/25000]\n",
      "loss: 269.387787  [15010/25000]\n",
      "loss: 114.560188  [16010/25000]\n",
      "loss: 195.300552  [17010/25000]\n",
      "loss: 82.855965  [18010/25000]\n",
      "loss: 53.056587  [19010/25000]\n",
      "loss: 205.845657  [20010/25000]\n",
      "loss: 196.901703  [21010/25000]\n",
      "loss: 177.699829  [22010/25000]\n",
      "loss: 235.501755  [23010/25000]\n",
      "loss: 205.307907  [24010/25000]\n",
      "accuracy: tensor(0.2048)\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 206.201920  [   10/25000]\n",
      "loss: 126.922874  [ 1010/25000]\n",
      "loss: 245.959747  [ 2010/25000]\n",
      "loss: 136.834412  [ 3010/25000]\n",
      "loss: 130.427322  [ 4010/25000]\n",
      "loss: 342.651642  [ 5010/25000]\n",
      "loss: 82.969353  [ 6010/25000]\n",
      "loss: 136.602203  [ 7010/25000]\n",
      "loss: 118.801849  [ 8010/25000]\n",
      "loss: 134.147446  [ 9010/25000]\n",
      "loss: 20.054861  [10010/25000]\n",
      "loss: 107.381218  [11010/25000]\n",
      "loss: 116.737404  [12010/25000]\n",
      "loss: 205.091400  [13010/25000]\n",
      "loss: 98.908646  [14010/25000]\n",
      "loss: 269.382355  [15010/25000]\n",
      "loss: 114.554268  [16010/25000]\n",
      "loss: 195.296249  [17010/25000]\n",
      "loss: 82.845451  [18010/25000]\n",
      "loss: 53.044960  [19010/25000]\n",
      "loss: 205.849884  [20010/25000]\n",
      "loss: 196.904999  [21010/25000]\n",
      "loss: 177.689178  [22010/25000]\n",
      "loss: 235.490784  [23010/25000]\n",
      "loss: 205.301086  [24010/25000]\n",
      "accuracy: tensor(0.2047)\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 206.197754  [   10/25000]\n",
      "loss: 126.912636  [ 1010/25000]\n",
      "loss: 245.945755  [ 2010/25000]\n",
      "loss: 136.831329  [ 3010/25000]\n",
      "loss: 130.417496  [ 4010/25000]\n",
      "loss: 342.638245  [ 5010/25000]\n",
      "loss: 82.957283  [ 6010/25000]\n",
      "loss: 136.594681  [ 7010/25000]\n",
      "loss: 118.794090  [ 8010/25000]\n",
      "loss: 134.133026  [ 9010/25000]\n",
      "loss: 20.052013  [10010/25000]\n",
      "loss: 107.374901  [11010/25000]\n",
      "loss: 116.722504  [12010/25000]\n",
      "loss: 205.074768  [13010/25000]\n",
      "loss: 98.909065  [14010/25000]\n",
      "loss: 269.376953  [15010/25000]\n",
      "loss: 114.548332  [16010/25000]\n",
      "loss: 195.292297  [17010/25000]\n",
      "loss: 82.834793  [18010/25000]\n",
      "loss: 53.033379  [19010/25000]\n",
      "loss: 205.854568  [20010/25000]\n",
      "loss: 196.908356  [21010/25000]\n",
      "loss: 177.678528  [22010/25000]\n",
      "loss: 235.479904  [23010/25000]\n",
      "loss: 205.294220  [24010/25000]\n",
      "accuracy: tensor(0.2047)\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 206.193420  [   10/25000]\n",
      "loss: 126.902435  [ 1010/25000]\n",
      "loss: 245.931717  [ 2010/25000]\n",
      "loss: 136.827927  [ 3010/25000]\n",
      "loss: 130.406845  [ 4010/25000]\n",
      "loss: 342.624847  [ 5010/25000]\n",
      "loss: 82.944916  [ 6010/25000]\n",
      "loss: 136.587311  [ 7010/25000]\n",
      "loss: 118.786278  [ 8010/25000]\n",
      "loss: 134.118591  [ 9010/25000]\n",
      "loss: 20.049253  [10010/25000]\n",
      "loss: 107.368744  [11010/25000]\n",
      "loss: 116.707520  [12010/25000]\n",
      "loss: 205.057846  [13010/25000]\n",
      "loss: 98.909676  [14010/25000]\n",
      "loss: 269.371429  [15010/25000]\n",
      "loss: 114.542480  [16010/25000]\n",
      "loss: 195.288315  [17010/25000]\n",
      "loss: 82.824150  [18010/25000]\n",
      "loss: 53.021729  [19010/25000]\n",
      "loss: 205.858704  [20010/25000]\n",
      "loss: 196.911407  [21010/25000]\n",
      "loss: 177.667923  [22010/25000]\n",
      "loss: 235.469284  [23010/25000]\n",
      "loss: 205.287415  [24010/25000]\n",
      "accuracy: tensor(0.2046)\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 206.189667  [   10/25000]\n",
      "loss: 126.892288  [ 1010/25000]\n",
      "loss: 245.917709  [ 2010/25000]\n",
      "loss: 136.824707  [ 3010/25000]\n",
      "loss: 130.396637  [ 4010/25000]\n",
      "loss: 342.611481  [ 5010/25000]\n",
      "loss: 82.932693  [ 6010/25000]\n",
      "loss: 136.579788  [ 7010/25000]\n",
      "loss: 118.778587  [ 8010/25000]\n",
      "loss: 134.104279  [ 9010/25000]\n",
      "loss: 20.046413  [10010/25000]\n",
      "loss: 107.362381  [11010/25000]\n",
      "loss: 116.692940  [12010/25000]\n",
      "loss: 205.041214  [13010/25000]\n",
      "loss: 98.910088  [14010/25000]\n",
      "loss: 269.365967  [15010/25000]\n",
      "loss: 114.536545  [16010/25000]\n",
      "loss: 195.284256  [17010/25000]\n",
      "loss: 82.813728  [18010/25000]\n",
      "loss: 53.010136  [19010/25000]\n",
      "loss: 205.862991  [20010/25000]\n",
      "loss: 196.915192  [21010/25000]\n",
      "loss: 177.657410  [22010/25000]\n",
      "loss: 235.459000  [23010/25000]\n",
      "loss: 205.280624  [24010/25000]\n",
      "accuracy: tensor(0.2045)\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 206.185684  [   10/25000]\n",
      "loss: 126.882111  [ 1010/25000]\n",
      "loss: 245.903687  [ 2010/25000]\n",
      "loss: 136.821991  [ 3010/25000]\n",
      "loss: 130.386810  [ 4010/25000]\n",
      "loss: 342.598175  [ 5010/25000]\n",
      "loss: 82.920479  [ 6010/25000]\n",
      "loss: 136.572540  [ 7010/25000]\n",
      "loss: 118.770905  [ 8010/25000]\n",
      "loss: 134.089859  [ 9010/25000]\n",
      "loss: 20.043625  [10010/25000]\n",
      "loss: 107.356125  [11010/25000]\n",
      "loss: 116.678253  [12010/25000]\n",
      "loss: 205.024292  [13010/25000]\n",
      "loss: 98.910637  [14010/25000]\n",
      "loss: 269.360626  [15010/25000]\n",
      "loss: 114.530739  [16010/25000]\n",
      "loss: 195.280228  [17010/25000]\n",
      "loss: 82.803093  [18010/25000]\n",
      "loss: 52.998520  [19010/25000]\n",
      "loss: 205.867233  [20010/25000]\n",
      "loss: 196.918549  [21010/25000]\n",
      "loss: 177.646744  [22010/25000]\n",
      "loss: 235.448196  [23010/25000]\n",
      "loss: 205.273804  [24010/25000]\n",
      "accuracy: tensor(0.2045)\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 206.181778  [   10/25000]\n",
      "loss: 126.871925  [ 1010/25000]\n",
      "loss: 245.889786  [ 2010/25000]\n",
      "loss: 136.818832  [ 3010/25000]\n",
      "loss: 130.376205  [ 4010/25000]\n",
      "loss: 342.584778  [ 5010/25000]\n",
      "loss: 82.908310  [ 6010/25000]\n",
      "loss: 136.565033  [ 7010/25000]\n",
      "loss: 118.763161  [ 8010/25000]\n",
      "loss: 134.075256  [ 9010/25000]\n",
      "loss: 20.040764  [10010/25000]\n",
      "loss: 107.349808  [11010/25000]\n",
      "loss: 116.663498  [12010/25000]\n",
      "loss: 205.007584  [13010/25000]\n",
      "loss: 98.910866  [14010/25000]\n",
      "loss: 269.355072  [15010/25000]\n",
      "loss: 114.524796  [16010/25000]\n",
      "loss: 195.276215  [17010/25000]\n",
      "loss: 82.792511  [18010/25000]\n",
      "loss: 52.987003  [19010/25000]\n",
      "loss: 205.871490  [20010/25000]\n",
      "loss: 196.921799  [21010/25000]\n",
      "loss: 177.636169  [22010/25000]\n",
      "loss: 235.437408  [23010/25000]\n",
      "loss: 205.267014  [24010/25000]\n",
      "accuracy: tensor(0.2044)\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 206.177643  [   10/25000]\n",
      "loss: 126.861786  [ 1010/25000]\n",
      "loss: 245.875824  [ 2010/25000]\n",
      "loss: 136.815445  [ 3010/25000]\n",
      "loss: 130.366013  [ 4010/25000]\n",
      "loss: 342.571442  [ 5010/25000]\n",
      "loss: 82.896042  [ 6010/25000]\n",
      "loss: 136.557678  [ 7010/25000]\n",
      "loss: 118.755486  [ 8010/25000]\n",
      "loss: 134.060989  [ 9010/25000]\n",
      "loss: 20.038002  [10010/25000]\n",
      "loss: 107.343483  [11010/25000]\n",
      "loss: 116.648689  [12010/25000]\n",
      "loss: 204.990952  [13010/25000]\n",
      "loss: 98.911598  [14010/25000]\n",
      "loss: 269.349701  [15010/25000]\n",
      "loss: 114.518875  [16010/25000]\n",
      "loss: 195.272308  [17010/25000]\n",
      "loss: 82.782059  [18010/25000]\n",
      "loss: 52.975418  [19010/25000]\n",
      "loss: 205.875793  [20010/25000]\n",
      "loss: 196.925156  [21010/25000]\n",
      "loss: 177.625610  [22010/25000]\n",
      "loss: 235.426666  [23010/25000]\n",
      "loss: 205.260193  [24010/25000]\n",
      "accuracy: tensor(0.2044)\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 206.173737  [   10/25000]\n",
      "loss: 126.851677  [ 1010/25000]\n",
      "loss: 245.861893  [ 2010/25000]\n",
      "loss: 136.812271  [ 3010/25000]\n",
      "loss: 130.355911  [ 4010/25000]\n",
      "loss: 342.558197  [ 5010/25000]\n",
      "loss: 82.883904  [ 6010/25000]\n",
      "loss: 136.550171  [ 7010/25000]\n",
      "loss: 118.747734  [ 8010/25000]\n",
      "loss: 134.046539  [ 9010/25000]\n",
      "loss: 20.035131  [10010/25000]\n",
      "loss: 107.337219  [11010/25000]\n",
      "loss: 116.633812  [12010/25000]\n",
      "loss: 204.974182  [13010/25000]\n",
      "loss: 98.912186  [14010/25000]\n",
      "loss: 269.344299  [15010/25000]\n",
      "loss: 114.512947  [16010/25000]\n",
      "loss: 195.268326  [17010/25000]\n",
      "loss: 82.771523  [18010/25000]\n",
      "loss: 52.963932  [19010/25000]\n",
      "loss: 205.879883  [20010/25000]\n",
      "loss: 196.928345  [21010/25000]\n",
      "loss: 177.615082  [22010/25000]\n",
      "loss: 235.416306  [23010/25000]\n",
      "loss: 205.253418  [24010/25000]\n",
      "accuracy: tensor(0.2043)\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 206.169479  [   10/25000]\n",
      "loss: 126.841515  [ 1010/25000]\n",
      "loss: 245.847961  [ 2010/25000]\n",
      "loss: 136.809372  [ 3010/25000]\n",
      "loss: 130.346207  [ 4010/25000]\n",
      "loss: 342.544830  [ 5010/25000]\n",
      "loss: 82.871727  [ 6010/25000]\n",
      "loss: 136.543076  [ 7010/25000]\n",
      "loss: 118.740097  [ 8010/25000]\n",
      "loss: 134.032181  [ 9010/25000]\n",
      "loss: 20.032408  [10010/25000]\n",
      "loss: 107.330956  [11010/25000]\n",
      "loss: 116.619171  [12010/25000]\n",
      "loss: 204.957397  [13010/25000]\n",
      "loss: 98.912659  [14010/25000]\n",
      "loss: 269.339050  [15010/25000]\n",
      "loss: 114.507103  [16010/25000]\n",
      "loss: 195.264282  [17010/25000]\n",
      "loss: 82.761017  [18010/25000]\n",
      "loss: 52.952370  [19010/25000]\n",
      "loss: 205.884415  [20010/25000]\n",
      "loss: 196.932068  [21010/25000]\n",
      "loss: 177.604446  [22010/25000]\n",
      "loss: 235.405502  [23010/25000]\n",
      "loss: 205.246674  [24010/25000]\n",
      "accuracy: tensor(0.2042)\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 206.165405  [   10/25000]\n",
      "loss: 126.831345  [ 1010/25000]\n",
      "loss: 245.834045  [ 2010/25000]\n",
      "loss: 136.806412  [ 3010/25000]\n",
      "loss: 130.335938  [ 4010/25000]\n",
      "loss: 342.531555  [ 5010/25000]\n",
      "loss: 82.859543  [ 6010/25000]\n",
      "loss: 136.535629  [ 7010/25000]\n",
      "loss: 118.732346  [ 8010/25000]\n",
      "loss: 134.017838  [ 9010/25000]\n",
      "loss: 20.029566  [10010/25000]\n",
      "loss: 107.324768  [11010/25000]\n",
      "loss: 116.604645  [12010/25000]\n",
      "loss: 204.940903  [13010/25000]\n",
      "loss: 98.913216  [14010/25000]\n",
      "loss: 269.333557  [15010/25000]\n",
      "loss: 114.501175  [16010/25000]\n",
      "loss: 195.260483  [17010/25000]\n",
      "loss: 82.750511  [18010/25000]\n",
      "loss: 52.940815  [19010/25000]\n",
      "loss: 205.888626  [20010/25000]\n",
      "loss: 196.935287  [21010/25000]\n",
      "loss: 177.593933  [22010/25000]\n",
      "loss: 235.395111  [23010/25000]\n",
      "loss: 205.239899  [24010/25000]\n",
      "accuracy: tensor(0.2042)\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 206.161469  [   10/25000]\n",
      "loss: 126.821297  [ 1010/25000]\n",
      "loss: 245.820190  [ 2010/25000]\n",
      "loss: 136.803177  [ 3010/25000]\n",
      "loss: 130.325546  [ 4010/25000]\n",
      "loss: 342.518372  [ 5010/25000]\n",
      "loss: 82.847565  [ 6010/25000]\n",
      "loss: 136.528259  [ 7010/25000]\n",
      "loss: 118.724724  [ 8010/25000]\n",
      "loss: 134.003525  [ 9010/25000]\n",
      "loss: 20.026697  [10010/25000]\n",
      "loss: 107.318542  [11010/25000]\n",
      "loss: 116.589775  [12010/25000]\n",
      "loss: 204.924469  [13010/25000]\n",
      "loss: 98.913673  [14010/25000]\n",
      "loss: 269.328247  [15010/25000]\n",
      "loss: 114.495316  [16010/25000]\n",
      "loss: 195.256363  [17010/25000]\n",
      "loss: 82.740028  [18010/25000]\n",
      "loss: 52.929352  [19010/25000]\n",
      "loss: 205.892853  [20010/25000]\n",
      "loss: 196.938187  [21010/25000]\n",
      "loss: 177.583405  [22010/25000]\n",
      "loss: 235.384399  [23010/25000]\n",
      "loss: 205.233139  [24010/25000]\n",
      "accuracy: tensor(0.2041)\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 206.157410  [   10/25000]\n",
      "loss: 126.811172  [ 1010/25000]\n",
      "loss: 245.806305  [ 2010/25000]\n",
      "loss: 136.800003  [ 3010/25000]\n",
      "loss: 130.315659  [ 4010/25000]\n",
      "loss: 342.505005  [ 5010/25000]\n",
      "loss: 82.835182  [ 6010/25000]\n",
      "loss: 136.520905  [ 7010/25000]\n",
      "loss: 118.716980  [ 8010/25000]\n",
      "loss: 133.989166  [ 9010/25000]\n",
      "loss: 20.023993  [10010/25000]\n",
      "loss: 107.312210  [11010/25000]\n",
      "loss: 116.575150  [12010/25000]\n",
      "loss: 204.907700  [13010/25000]\n",
      "loss: 98.914124  [14010/25000]\n",
      "loss: 269.322876  [15010/25000]\n",
      "loss: 114.489502  [16010/25000]\n",
      "loss: 195.252396  [17010/25000]\n",
      "loss: 82.729568  [18010/25000]\n",
      "loss: 52.917988  [19010/25000]\n",
      "loss: 205.897278  [20010/25000]\n",
      "loss: 196.941849  [21010/25000]\n",
      "loss: 177.572952  [22010/25000]\n",
      "loss: 235.373688  [23010/25000]\n",
      "loss: 205.226364  [24010/25000]\n",
      "accuracy: tensor(0.2041)\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 206.153503  [   10/25000]\n",
      "loss: 126.801132  [ 1010/25000]\n",
      "loss: 245.792419  [ 2010/25000]\n",
      "loss: 136.796875  [ 3010/25000]\n",
      "loss: 130.305374  [ 4010/25000]\n",
      "loss: 342.491730  [ 5010/25000]\n",
      "loss: 82.823128  [ 6010/25000]\n",
      "loss: 136.513580  [ 7010/25000]\n",
      "loss: 118.709358  [ 8010/25000]\n",
      "loss: 133.974762  [ 9010/25000]\n",
      "loss: 20.021173  [10010/25000]\n",
      "loss: 107.306015  [11010/25000]\n",
      "loss: 116.560211  [12010/25000]\n",
      "loss: 204.891098  [13010/25000]\n",
      "loss: 98.914696  [14010/25000]\n",
      "loss: 269.317505  [15010/25000]\n",
      "loss: 114.483536  [16010/25000]\n",
      "loss: 195.248444  [17010/25000]\n",
      "loss: 82.719109  [18010/25000]\n",
      "loss: 52.906471  [19010/25000]\n",
      "loss: 205.901566  [20010/25000]\n",
      "loss: 196.945679  [21010/25000]\n",
      "loss: 177.562439  [22010/25000]\n",
      "loss: 235.363022  [23010/25000]\n",
      "loss: 205.219650  [24010/25000]\n",
      "accuracy: tensor(0.2040)\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 206.149551  [   10/25000]\n",
      "loss: 126.791054  [ 1010/25000]\n",
      "loss: 245.778595  [ 2010/25000]\n",
      "loss: 136.793823  [ 3010/25000]\n",
      "loss: 130.295364  [ 4010/25000]\n",
      "loss: 342.478607  [ 5010/25000]\n",
      "loss: 82.811066  [ 6010/25000]\n",
      "loss: 136.506256  [ 7010/25000]\n",
      "loss: 118.701729  [ 8010/25000]\n",
      "loss: 133.960556  [ 9010/25000]\n",
      "loss: 20.018417  [10010/25000]\n",
      "loss: 107.299744  [11010/25000]\n",
      "loss: 116.545860  [12010/25000]\n",
      "loss: 204.874512  [13010/25000]\n",
      "loss: 98.915131  [14010/25000]\n",
      "loss: 269.312103  [15010/25000]\n",
      "loss: 114.477707  [16010/25000]\n",
      "loss: 195.244553  [17010/25000]\n",
      "loss: 82.708710  [18010/25000]\n",
      "loss: 52.895016  [19010/25000]\n",
      "loss: 205.906097  [20010/25000]\n",
      "loss: 196.948532  [21010/25000]\n",
      "loss: 177.551910  [22010/25000]\n",
      "loss: 235.352722  [23010/25000]\n",
      "loss: 205.212891  [24010/25000]\n",
      "accuracy: tensor(0.2040)\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 206.145554  [   10/25000]\n",
      "loss: 126.781013  [ 1010/25000]\n",
      "loss: 245.764740  [ 2010/25000]\n",
      "loss: 136.790726  [ 3010/25000]\n",
      "loss: 130.285278  [ 4010/25000]\n",
      "loss: 342.465393  [ 5010/25000]\n",
      "loss: 82.799004  [ 6010/25000]\n",
      "loss: 136.498840  [ 7010/25000]\n",
      "loss: 118.694016  [ 8010/25000]\n",
      "loss: 133.946350  [ 9010/25000]\n",
      "loss: 20.015579  [10010/25000]\n",
      "loss: 107.293526  [11010/25000]\n",
      "loss: 116.531097  [12010/25000]\n",
      "loss: 204.858109  [13010/25000]\n",
      "loss: 98.915428  [14010/25000]\n",
      "loss: 269.306824  [15010/25000]\n",
      "loss: 114.471855  [16010/25000]\n",
      "loss: 195.240448  [17010/25000]\n",
      "loss: 82.698311  [18010/25000]\n",
      "loss: 52.883614  [19010/25000]\n",
      "loss: 205.910202  [20010/25000]\n",
      "loss: 196.952286  [21010/25000]\n",
      "loss: 177.541519  [22010/25000]\n",
      "loss: 235.342148  [23010/25000]\n",
      "loss: 205.206146  [24010/25000]\n",
      "accuracy: tensor(0.2039)\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 206.141525  [   10/25000]\n",
      "loss: 126.770897  [ 1010/25000]\n",
      "loss: 245.750931  [ 2010/25000]\n",
      "loss: 136.787613  [ 3010/25000]\n",
      "loss: 130.275024  [ 4010/25000]\n",
      "loss: 342.452148  [ 5010/25000]\n",
      "loss: 82.786789  [ 6010/25000]\n",
      "loss: 136.491562  [ 7010/25000]\n",
      "loss: 118.686417  [ 8010/25000]\n",
      "loss: 133.932037  [ 9010/25000]\n",
      "loss: 20.012819  [10010/25000]\n",
      "loss: 107.287277  [11010/25000]\n",
      "loss: 116.516663  [12010/25000]\n",
      "loss: 204.841400  [13010/25000]\n",
      "loss: 98.916283  [14010/25000]\n",
      "loss: 269.301483  [15010/25000]\n",
      "loss: 114.465996  [16010/25000]\n",
      "loss: 195.236404  [17010/25000]\n",
      "loss: 82.687782  [18010/25000]\n",
      "loss: 52.872158  [19010/25000]\n",
      "loss: 205.914490  [20010/25000]\n",
      "loss: 196.955276  [21010/25000]\n",
      "loss: 177.530991  [22010/25000]\n",
      "loss: 235.331726  [23010/25000]\n",
      "loss: 205.199417  [24010/25000]\n",
      "accuracy: tensor(0.2038)\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 206.137817  [   10/25000]\n",
      "loss: 126.760857  [ 1010/25000]\n",
      "loss: 245.737106  [ 2010/25000]\n",
      "loss: 136.784714  [ 3010/25000]\n",
      "loss: 130.264954  [ 4010/25000]\n",
      "loss: 342.439026  [ 5010/25000]\n",
      "loss: 82.774788  [ 6010/25000]\n",
      "loss: 136.484329  [ 7010/25000]\n",
      "loss: 118.678780  [ 8010/25000]\n",
      "loss: 133.917526  [ 9010/25000]\n",
      "loss: 20.010057  [10010/25000]\n",
      "loss: 107.281151  [11010/25000]\n",
      "loss: 116.501823  [12010/25000]\n",
      "loss: 204.824921  [13010/25000]\n",
      "loss: 98.916794  [14010/25000]\n",
      "loss: 269.296112  [15010/25000]\n",
      "loss: 114.460167  [16010/25000]\n",
      "loss: 195.232376  [17010/25000]\n",
      "loss: 82.677383  [18010/25000]\n",
      "loss: 52.860703  [19010/25000]\n",
      "loss: 205.919037  [20010/25000]\n",
      "loss: 196.959000  [21010/25000]\n",
      "loss: 177.520584  [22010/25000]\n",
      "loss: 235.320923  [23010/25000]\n",
      "loss: 205.192688  [24010/25000]\n",
      "accuracy: tensor(0.2038)\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 206.133911  [   10/25000]\n",
      "loss: 126.750755  [ 1010/25000]\n",
      "loss: 245.723404  [ 2010/25000]\n",
      "loss: 136.781616  [ 3010/25000]\n",
      "loss: 130.255081  [ 4010/25000]\n",
      "loss: 342.425812  [ 5010/25000]\n",
      "loss: 82.762741  [ 6010/25000]\n",
      "loss: 136.476929  [ 7010/25000]\n",
      "loss: 118.671181  [ 8010/25000]\n",
      "loss: 133.903580  [ 9010/25000]\n",
      "loss: 20.007248  [10010/25000]\n",
      "loss: 107.274963  [11010/25000]\n",
      "loss: 116.487206  [12010/25000]\n",
      "loss: 204.808334  [13010/25000]\n",
      "loss: 98.917366  [14010/25000]\n",
      "loss: 269.290771  [15010/25000]\n",
      "loss: 114.454384  [16010/25000]\n",
      "loss: 195.228378  [17010/25000]\n",
      "loss: 82.666969  [18010/25000]\n",
      "loss: 52.849422  [19010/25000]\n",
      "loss: 205.923462  [20010/25000]\n",
      "loss: 196.962097  [21010/25000]\n",
      "loss: 177.510162  [22010/25000]\n",
      "loss: 235.310501  [23010/25000]\n",
      "loss: 205.185989  [24010/25000]\n",
      "accuracy: tensor(0.2037)\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 206.129700  [   10/25000]\n",
      "loss: 126.740799  [ 1010/25000]\n",
      "loss: 245.709610  [ 2010/25000]\n",
      "loss: 136.778580  [ 3010/25000]\n",
      "loss: 130.244888  [ 4010/25000]\n",
      "loss: 342.412689  [ 5010/25000]\n",
      "loss: 82.750618  [ 6010/25000]\n",
      "loss: 136.469681  [ 7010/25000]\n",
      "loss: 118.663574  [ 8010/25000]\n",
      "loss: 133.889023  [ 9010/25000]\n",
      "loss: 20.004477  [10010/25000]\n",
      "loss: 107.268707  [11010/25000]\n",
      "loss: 116.472786  [12010/25000]\n",
      "loss: 204.791809  [13010/25000]\n",
      "loss: 98.917923  [14010/25000]\n",
      "loss: 269.285339  [15010/25000]\n",
      "loss: 114.448578  [16010/25000]\n",
      "loss: 195.224564  [17010/25000]\n",
      "loss: 82.656517  [18010/25000]\n",
      "loss: 52.838043  [19010/25000]\n",
      "loss: 205.927811  [20010/25000]\n",
      "loss: 196.965469  [21010/25000]\n",
      "loss: 177.499664  [22010/25000]\n",
      "loss: 235.300034  [23010/25000]\n",
      "loss: 205.179291  [24010/25000]\n",
      "accuracy: tensor(0.2037)\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 206.125778  [   10/25000]\n",
      "loss: 126.730774  [ 1010/25000]\n",
      "loss: 245.695847  [ 2010/25000]\n",
      "loss: 136.775574  [ 3010/25000]\n",
      "loss: 130.234787  [ 4010/25000]\n",
      "loss: 342.399567  [ 5010/25000]\n",
      "loss: 82.738693  [ 6010/25000]\n",
      "loss: 136.462448  [ 7010/25000]\n",
      "loss: 118.655930  [ 8010/25000]\n",
      "loss: 133.874817  [ 9010/25000]\n",
      "loss: 20.001717  [10010/25000]\n",
      "loss: 107.262482  [11010/25000]\n",
      "loss: 116.458397  [12010/25000]\n",
      "loss: 204.775391  [13010/25000]\n",
      "loss: 98.918327  [14010/25000]\n",
      "loss: 269.280090  [15010/25000]\n",
      "loss: 114.442741  [16010/25000]\n",
      "loss: 195.220703  [17010/25000]\n",
      "loss: 82.646202  [18010/25000]\n",
      "loss: 52.826679  [19010/25000]\n",
      "loss: 205.931824  [20010/25000]\n",
      "loss: 196.969101  [21010/25000]\n",
      "loss: 177.489243  [22010/25000]\n",
      "loss: 235.289703  [23010/25000]\n",
      "loss: 205.172577  [24010/25000]\n",
      "accuracy: tensor(0.2036)\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 206.121948  [   10/25000]\n",
      "loss: 126.720818  [ 1010/25000]\n",
      "loss: 245.682129  [ 2010/25000]\n",
      "loss: 136.772400  [ 3010/25000]\n",
      "loss: 130.224594  [ 4010/25000]\n",
      "loss: 342.386444  [ 5010/25000]\n",
      "loss: 82.726639  [ 6010/25000]\n",
      "loss: 136.455139  [ 7010/25000]\n",
      "loss: 118.648376  [ 8010/25000]\n",
      "loss: 133.860687  [ 9010/25000]\n",
      "loss: 19.998991  [10010/25000]\n",
      "loss: 107.256424  [11010/25000]\n",
      "loss: 116.443748  [12010/25000]\n",
      "loss: 204.759048  [13010/25000]\n",
      "loss: 98.919006  [14010/25000]\n",
      "loss: 269.274933  [15010/25000]\n",
      "loss: 114.436913  [16010/25000]\n",
      "loss: 195.216751  [17010/25000]\n",
      "loss: 82.635803  [18010/25000]\n",
      "loss: 52.815323  [19010/25000]\n",
      "loss: 205.936264  [20010/25000]\n",
      "loss: 196.972534  [21010/25000]\n",
      "loss: 177.478729  [22010/25000]\n",
      "loss: 235.279099  [23010/25000]\n",
      "loss: 205.165924  [24010/25000]\n",
      "accuracy: tensor(0.2035)\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 206.117722  [   10/25000]\n",
      "loss: 126.710823  [ 1010/25000]\n",
      "loss: 245.668320  [ 2010/25000]\n",
      "loss: 136.769547  [ 3010/25000]\n",
      "loss: 130.214691  [ 4010/25000]\n",
      "loss: 342.373291  [ 5010/25000]\n",
      "loss: 82.714645  [ 6010/25000]\n",
      "loss: 136.447815  [ 7010/25000]\n",
      "loss: 118.640770  [ 8010/25000]\n",
      "loss: 133.846664  [ 9010/25000]\n",
      "loss: 19.996113  [10010/25000]\n",
      "loss: 107.250168  [11010/25000]\n",
      "loss: 116.429024  [12010/25000]\n",
      "loss: 204.742599  [13010/25000]\n",
      "loss: 98.919479  [14010/25000]\n",
      "loss: 269.269501  [15010/25000]\n",
      "loss: 114.431091  [16010/25000]\n",
      "loss: 195.212875  [17010/25000]\n",
      "loss: 82.625481  [18010/25000]\n",
      "loss: 52.803993  [19010/25000]\n",
      "loss: 205.940765  [20010/25000]\n",
      "loss: 196.975677  [21010/25000]\n",
      "loss: 177.468399  [22010/25000]\n",
      "loss: 235.268951  [23010/25000]\n",
      "loss: 205.159225  [24010/25000]\n",
      "accuracy: tensor(0.2035)\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 206.113968  [   10/25000]\n",
      "loss: 126.700851  [ 1010/25000]\n",
      "loss: 245.654663  [ 2010/25000]\n",
      "loss: 136.766479  [ 3010/25000]\n",
      "loss: 130.204651  [ 4010/25000]\n",
      "loss: 342.360168  [ 5010/25000]\n",
      "loss: 82.702507  [ 6010/25000]\n",
      "loss: 136.440750  [ 7010/25000]\n",
      "loss: 118.633209  [ 8010/25000]\n",
      "loss: 133.832321  [ 9010/25000]\n",
      "loss: 19.993418  [10010/25000]\n",
      "loss: 107.243973  [11010/25000]\n",
      "loss: 116.414528  [12010/25000]\n",
      "loss: 204.726196  [13010/25000]\n",
      "loss: 98.920013  [14010/25000]\n",
      "loss: 269.264313  [15010/25000]\n",
      "loss: 114.425354  [16010/25000]\n",
      "loss: 195.209000  [17010/25000]\n",
      "loss: 82.615128  [18010/25000]\n",
      "loss: 52.792660  [19010/25000]\n",
      "loss: 205.945023  [20010/25000]\n",
      "loss: 196.979126  [21010/25000]\n",
      "loss: 177.458054  [22010/25000]\n",
      "loss: 235.258347  [23010/25000]\n",
      "loss: 205.152542  [24010/25000]\n",
      "accuracy: tensor(0.2034)\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 206.110153  [   10/25000]\n",
      "loss: 126.690857  [ 1010/25000]\n",
      "loss: 245.640961  [ 2010/25000]\n",
      "loss: 136.763519  [ 3010/25000]\n",
      "loss: 130.194824  [ 4010/25000]\n",
      "loss: 342.347107  [ 5010/25000]\n",
      "loss: 82.690598  [ 6010/25000]\n",
      "loss: 136.433304  [ 7010/25000]\n",
      "loss: 118.625580  [ 8010/25000]\n",
      "loss: 133.818222  [ 9010/25000]\n",
      "loss: 19.990681  [10010/25000]\n",
      "loss: 107.237793  [11010/25000]\n",
      "loss: 116.400223  [12010/25000]\n",
      "loss: 204.709839  [13010/25000]\n",
      "loss: 98.920692  [14010/25000]\n",
      "loss: 269.258911  [15010/25000]\n",
      "loss: 114.419533  [16010/25000]\n",
      "loss: 195.205017  [17010/25000]\n",
      "loss: 82.604767  [18010/25000]\n",
      "loss: 52.781403  [19010/25000]\n",
      "loss: 205.949173  [20010/25000]\n",
      "loss: 196.982651  [21010/25000]\n",
      "loss: 177.447632  [22010/25000]\n",
      "loss: 235.247894  [23010/25000]\n",
      "loss: 205.145905  [24010/25000]\n",
      "accuracy: tensor(0.2034)\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 206.106216  [   10/25000]\n",
      "loss: 126.680870  [ 1010/25000]\n",
      "loss: 245.627304  [ 2010/25000]\n",
      "loss: 136.760666  [ 3010/25000]\n",
      "loss: 130.184875  [ 4010/25000]\n",
      "loss: 342.334076  [ 5010/25000]\n",
      "loss: 82.678688  [ 6010/25000]\n",
      "loss: 136.426132  [ 7010/25000]\n",
      "loss: 118.618057  [ 8010/25000]\n",
      "loss: 133.804077  [ 9010/25000]\n",
      "loss: 19.987902  [10010/25000]\n",
      "loss: 107.231697  [11010/25000]\n",
      "loss: 116.385521  [12010/25000]\n",
      "loss: 204.693314  [13010/25000]\n",
      "loss: 98.921288  [14010/25000]\n",
      "loss: 269.253662  [15010/25000]\n",
      "loss: 114.413727  [16010/25000]\n",
      "loss: 195.201096  [17010/25000]\n",
      "loss: 82.594376  [18010/25000]\n",
      "loss: 52.770073  [19010/25000]\n",
      "loss: 205.953735  [20010/25000]\n",
      "loss: 196.985840  [21010/25000]\n",
      "loss: 177.437271  [22010/25000]\n",
      "loss: 235.237259  [23010/25000]\n",
      "loss: 205.139206  [24010/25000]\n",
      "accuracy: tensor(0.2033)\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 206.102066  [   10/25000]\n",
      "loss: 126.670944  [ 1010/25000]\n",
      "loss: 245.613586  [ 2010/25000]\n",
      "loss: 136.757599  [ 3010/25000]\n",
      "loss: 130.174530  [ 4010/25000]\n",
      "loss: 342.320984  [ 5010/25000]\n",
      "loss: 82.666618  [ 6010/25000]\n",
      "loss: 136.418808  [ 7010/25000]\n",
      "loss: 118.610497  [ 8010/25000]\n",
      "loss: 133.789795  [ 9010/25000]\n",
      "loss: 19.985132  [10010/25000]\n",
      "loss: 107.225578  [11010/25000]\n",
      "loss: 116.371208  [12010/25000]\n",
      "loss: 204.676941  [13010/25000]\n",
      "loss: 98.921761  [14010/25000]\n",
      "loss: 269.248505  [15010/25000]\n",
      "loss: 114.407990  [16010/25000]\n",
      "loss: 195.197388  [17010/25000]\n",
      "loss: 82.584084  [18010/25000]\n",
      "loss: 52.758854  [19010/25000]\n",
      "loss: 205.958099  [20010/25000]\n",
      "loss: 196.989258  [21010/25000]\n",
      "loss: 177.426880  [22010/25000]\n",
      "loss: 235.226868  [23010/25000]\n",
      "loss: 205.132553  [24010/25000]\n",
      "accuracy: tensor(0.2033)\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 206.098328  [   10/25000]\n",
      "loss: 126.660995  [ 1010/25000]\n",
      "loss: 245.599945  [ 2010/25000]\n",
      "loss: 136.754623  [ 3010/25000]\n",
      "loss: 130.164673  [ 4010/25000]\n",
      "loss: 342.307892  [ 5010/25000]\n",
      "loss: 82.654617  [ 6010/25000]\n",
      "loss: 136.411591  [ 7010/25000]\n",
      "loss: 118.602928  [ 8010/25000]\n",
      "loss: 133.775757  [ 9010/25000]\n",
      "loss: 19.982393  [10010/25000]\n",
      "loss: 107.219444  [11010/25000]\n",
      "loss: 116.356682  [12010/25000]\n",
      "loss: 204.660858  [13010/25000]\n",
      "loss: 98.922440  [14010/25000]\n",
      "loss: 269.243256  [15010/25000]\n",
      "loss: 114.402107  [16010/25000]\n",
      "loss: 195.193573  [17010/25000]\n",
      "loss: 82.573753  [18010/25000]\n",
      "loss: 52.747574  [19010/25000]\n",
      "loss: 205.962067  [20010/25000]\n",
      "loss: 196.992538  [21010/25000]\n",
      "loss: 177.416519  [22010/25000]\n",
      "loss: 235.216568  [23010/25000]\n",
      "loss: 205.125885  [24010/25000]\n",
      "accuracy: tensor(0.2032)\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 206.094299  [   10/25000]\n",
      "loss: 126.651100  [ 1010/25000]\n",
      "loss: 245.586227  [ 2010/25000]\n",
      "loss: 136.751480  [ 3010/25000]\n",
      "loss: 130.154633  [ 4010/25000]\n",
      "loss: 342.294891  [ 5010/25000]\n",
      "loss: 82.642784  [ 6010/25000]\n",
      "loss: 136.404495  [ 7010/25000]\n",
      "loss: 118.595413  [ 8010/25000]\n",
      "loss: 133.761581  [ 9010/25000]\n",
      "loss: 19.979647  [10010/25000]\n",
      "loss: 107.213348  [11010/25000]\n",
      "loss: 116.342316  [12010/25000]\n",
      "loss: 204.644302  [13010/25000]\n",
      "loss: 98.922791  [14010/25000]\n",
      "loss: 269.238068  [15010/25000]\n",
      "loss: 114.396423  [16010/25000]\n",
      "loss: 195.189575  [17010/25000]\n",
      "loss: 82.563538  [18010/25000]\n",
      "loss: 52.736359  [19010/25000]\n",
      "loss: 205.966812  [20010/25000]\n",
      "loss: 196.996140  [21010/25000]\n",
      "loss: 177.406235  [22010/25000]\n",
      "loss: 235.206177  [23010/25000]\n",
      "loss: 205.119263  [24010/25000]\n",
      "accuracy: tensor(0.2031)\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 206.090622  [   10/25000]\n",
      "loss: 126.641182  [ 1010/25000]\n",
      "loss: 245.572662  [ 2010/25000]\n",
      "loss: 136.748734  [ 3010/25000]\n",
      "loss: 130.144714  [ 4010/25000]\n",
      "loss: 342.281799  [ 5010/25000]\n",
      "loss: 82.630791  [ 6010/25000]\n",
      "loss: 136.397202  [ 7010/25000]\n",
      "loss: 118.587914  [ 8010/25000]\n",
      "loss: 133.747650  [ 9010/25000]\n",
      "loss: 19.976885  [10010/25000]\n",
      "loss: 107.207176  [11010/25000]\n",
      "loss: 116.327873  [12010/25000]\n",
      "loss: 204.627930  [13010/25000]\n",
      "loss: 98.923515  [14010/25000]\n",
      "loss: 269.232605  [15010/25000]\n",
      "loss: 114.390648  [16010/25000]\n",
      "loss: 195.185638  [17010/25000]\n",
      "loss: 82.553131  [18010/25000]\n",
      "loss: 52.725163  [19010/25000]\n",
      "loss: 205.970642  [20010/25000]\n",
      "loss: 196.999603  [21010/25000]\n",
      "loss: 177.395859  [22010/25000]\n",
      "loss: 235.195816  [23010/25000]\n",
      "loss: 205.112610  [24010/25000]\n",
      "accuracy: tensor(0.2031)\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 206.086548  [   10/25000]\n",
      "loss: 126.631287  [ 1010/25000]\n",
      "loss: 245.558990  [ 2010/25000]\n",
      "loss: 136.745743  [ 3010/25000]\n",
      "loss: 130.134476  [ 4010/25000]\n",
      "loss: 342.268829  [ 5010/25000]\n",
      "loss: 82.618935  [ 6010/25000]\n",
      "loss: 136.389954  [ 7010/25000]\n",
      "loss: 118.580353  [ 8010/25000]\n",
      "loss: 133.733490  [ 9010/25000]\n",
      "loss: 19.974154  [10010/25000]\n",
      "loss: 107.201057  [11010/25000]\n",
      "loss: 116.313263  [12010/25000]\n",
      "loss: 204.611191  [13010/25000]\n",
      "loss: 98.924095  [14010/25000]\n",
      "loss: 269.227386  [15010/25000]\n",
      "loss: 114.384872  [16010/25000]\n",
      "loss: 195.181732  [17010/25000]\n",
      "loss: 82.542961  [18010/25000]\n",
      "loss: 52.713867  [19010/25000]\n",
      "loss: 205.975113  [20010/25000]\n",
      "loss: 197.002991  [21010/25000]\n",
      "loss: 177.385620  [22010/25000]\n",
      "loss: 235.185425  [23010/25000]\n",
      "loss: 205.106003  [24010/25000]\n",
      "accuracy: tensor(0.2030)\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 206.082611  [   10/25000]\n",
      "loss: 126.621376  [ 1010/25000]\n",
      "loss: 245.545486  [ 2010/25000]\n",
      "loss: 136.742676  [ 3010/25000]\n",
      "loss: 130.124649  [ 4010/25000]\n",
      "loss: 342.255890  [ 5010/25000]\n",
      "loss: 82.606979  [ 6010/25000]\n",
      "loss: 136.382721  [ 7010/25000]\n",
      "loss: 118.572845  [ 8010/25000]\n",
      "loss: 133.719543  [ 9010/25000]\n",
      "loss: 19.971394  [10010/25000]\n",
      "loss: 107.194923  [11010/25000]\n",
      "loss: 116.299118  [12010/25000]\n",
      "loss: 204.595230  [13010/25000]\n",
      "loss: 98.924599  [14010/25000]\n",
      "loss: 269.222168  [15010/25000]\n",
      "loss: 114.379150  [16010/25000]\n",
      "loss: 195.177811  [17010/25000]\n",
      "loss: 82.532745  [18010/25000]\n",
      "loss: 52.702709  [19010/25000]\n",
      "loss: 205.979126  [20010/25000]\n",
      "loss: 197.006210  [21010/25000]\n",
      "loss: 177.375305  [22010/25000]\n",
      "loss: 235.174896  [23010/25000]\n",
      "loss: 205.099396  [24010/25000]\n",
      "accuracy: tensor(0.2030)\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 206.078659  [   10/25000]\n",
      "loss: 126.611481  [ 1010/25000]\n",
      "loss: 245.531891  [ 2010/25000]\n",
      "loss: 136.739746  [ 3010/25000]\n",
      "loss: 130.114746  [ 4010/25000]\n",
      "loss: 342.242889  [ 5010/25000]\n",
      "loss: 82.595078  [ 6010/25000]\n",
      "loss: 136.375610  [ 7010/25000]\n",
      "loss: 118.565369  [ 8010/25000]\n",
      "loss: 133.705383  [ 9010/25000]\n",
      "loss: 19.968678  [10010/25000]\n",
      "loss: 107.188789  [11010/25000]\n",
      "loss: 116.284416  [12010/25000]\n",
      "loss: 204.578873  [13010/25000]\n",
      "loss: 98.925262  [14010/25000]\n",
      "loss: 269.217072  [15010/25000]\n",
      "loss: 114.373360  [16010/25000]\n",
      "loss: 195.174011  [17010/25000]\n",
      "loss: 82.522385  [18010/25000]\n",
      "loss: 52.691528  [19010/25000]\n",
      "loss: 205.983444  [20010/25000]\n",
      "loss: 197.009842  [21010/25000]\n",
      "loss: 177.365051  [22010/25000]\n",
      "loss: 235.164734  [23010/25000]\n",
      "loss: 205.092819  [24010/25000]\n",
      "accuracy: tensor(0.2029)\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 206.074890  [   10/25000]\n",
      "loss: 126.601601  [ 1010/25000]\n",
      "loss: 245.518280  [ 2010/25000]\n",
      "loss: 136.737000  [ 3010/25000]\n",
      "loss: 130.104889  [ 4010/25000]\n",
      "loss: 342.229919  [ 5010/25000]\n",
      "loss: 82.583206  [ 6010/25000]\n",
      "loss: 136.368362  [ 7010/25000]\n",
      "loss: 118.557831  [ 8010/25000]\n",
      "loss: 133.691376  [ 9010/25000]\n",
      "loss: 19.965954  [10010/25000]\n",
      "loss: 107.182663  [11010/25000]\n",
      "loss: 116.270081  [12010/25000]\n",
      "loss: 204.562698  [13010/25000]\n",
      "loss: 98.925957  [14010/25000]\n",
      "loss: 269.211792  [15010/25000]\n",
      "loss: 114.367607  [16010/25000]\n",
      "loss: 195.170074  [17010/25000]\n",
      "loss: 82.512184  [18010/25000]\n",
      "loss: 52.680386  [19010/25000]\n",
      "loss: 205.988007  [20010/25000]\n",
      "loss: 197.013031  [21010/25000]\n",
      "loss: 177.354721  [22010/25000]\n",
      "loss: 235.154419  [23010/25000]\n",
      "loss: 205.086151  [24010/25000]\n",
      "accuracy: tensor(0.2028)\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 206.071136  [   10/25000]\n",
      "loss: 126.591766  [ 1010/25000]\n",
      "loss: 245.504761  [ 2010/25000]\n",
      "loss: 136.733948  [ 3010/25000]\n",
      "loss: 130.094910  [ 4010/25000]\n",
      "loss: 342.216949  [ 5010/25000]\n",
      "loss: 82.571381  [ 6010/25000]\n",
      "loss: 136.361237  [ 7010/25000]\n",
      "loss: 118.550354  [ 8010/25000]\n",
      "loss: 133.677292  [ 9010/25000]\n",
      "loss: 19.963234  [10010/25000]\n",
      "loss: 107.176544  [11010/25000]\n",
      "loss: 116.255768  [12010/25000]\n",
      "loss: 204.546341  [13010/25000]\n",
      "loss: 98.926537  [14010/25000]\n",
      "loss: 269.206726  [15010/25000]\n",
      "loss: 114.361877  [16010/25000]\n",
      "loss: 195.166351  [17010/25000]\n",
      "loss: 82.501984  [18010/25000]\n",
      "loss: 52.669201  [19010/25000]\n",
      "loss: 205.992142  [20010/25000]\n",
      "loss: 197.016739  [21010/25000]\n",
      "loss: 177.344467  [22010/25000]\n",
      "loss: 235.144028  [23010/25000]\n",
      "loss: 205.079590  [24010/25000]\n",
      "accuracy: tensor(0.2028)\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 206.067307  [   10/25000]\n",
      "loss: 126.581993  [ 1010/25000]\n",
      "loss: 245.491226  [ 2010/25000]\n",
      "loss: 136.731049  [ 3010/25000]\n",
      "loss: 130.084778  [ 4010/25000]\n",
      "loss: 342.204010  [ 5010/25000]\n",
      "loss: 82.559471  [ 6010/25000]\n",
      "loss: 136.354019  [ 7010/25000]\n",
      "loss: 118.542877  [ 8010/25000]\n",
      "loss: 133.663254  [ 9010/25000]\n",
      "loss: 19.960424  [10010/25000]\n",
      "loss: 107.170486  [11010/25000]\n",
      "loss: 116.241417  [12010/25000]\n",
      "loss: 204.530258  [13010/25000]\n",
      "loss: 98.927078  [14010/25000]\n",
      "loss: 269.201355  [15010/25000]\n",
      "loss: 114.356178  [16010/25000]\n",
      "loss: 195.162476  [17010/25000]\n",
      "loss: 82.491722  [18010/25000]\n",
      "loss: 52.658062  [19010/25000]\n",
      "loss: 205.996719  [20010/25000]\n",
      "loss: 197.019882  [21010/25000]\n",
      "loss: 177.334183  [22010/25000]\n",
      "loss: 235.133835  [23010/25000]\n",
      "loss: 205.072983  [24010/25000]\n",
      "accuracy: tensor(0.2027)\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 206.063263  [   10/25000]\n",
      "loss: 126.572090  [ 1010/25000]\n",
      "loss: 245.477661  [ 2010/25000]\n",
      "loss: 136.728149  [ 3010/25000]\n",
      "loss: 130.074921  [ 4010/25000]\n",
      "loss: 342.191162  [ 5010/25000]\n",
      "loss: 82.547707  [ 6010/25000]\n",
      "loss: 136.346832  [ 7010/25000]\n",
      "loss: 118.535393  [ 8010/25000]\n",
      "loss: 133.649323  [ 9010/25000]\n",
      "loss: 19.957731  [10010/25000]\n",
      "loss: 107.164398  [11010/25000]\n",
      "loss: 116.227219  [12010/25000]\n",
      "loss: 204.514206  [13010/25000]\n",
      "loss: 98.927841  [14010/25000]\n",
      "loss: 269.196045  [15010/25000]\n",
      "loss: 114.350487  [16010/25000]\n",
      "loss: 195.158554  [17010/25000]\n",
      "loss: 82.481445  [18010/25000]\n",
      "loss: 52.646973  [19010/25000]\n",
      "loss: 206.000931  [20010/25000]\n",
      "loss: 197.023254  [21010/25000]\n",
      "loss: 177.323929  [22010/25000]\n",
      "loss: 235.123383  [23010/25000]\n",
      "loss: 205.066406  [24010/25000]\n",
      "accuracy: tensor(0.2027)\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 206.059662  [   10/25000]\n",
      "loss: 126.562256  [ 1010/25000]\n",
      "loss: 245.464157  [ 2010/25000]\n",
      "loss: 136.725250  [ 3010/25000]\n",
      "loss: 130.065094  [ 4010/25000]\n",
      "loss: 342.178162  [ 5010/25000]\n",
      "loss: 82.535866  [ 6010/25000]\n",
      "loss: 136.339645  [ 7010/25000]\n",
      "loss: 118.527931  [ 8010/25000]\n",
      "loss: 133.635330  [ 9010/25000]\n",
      "loss: 19.954998  [10010/25000]\n",
      "loss: 107.158356  [11010/25000]\n",
      "loss: 116.212891  [12010/25000]\n",
      "loss: 204.498032  [13010/25000]\n",
      "loss: 98.928474  [14010/25000]\n",
      "loss: 269.191010  [15010/25000]\n",
      "loss: 114.344704  [16010/25000]\n",
      "loss: 195.154694  [17010/25000]\n",
      "loss: 82.471336  [18010/25000]\n",
      "loss: 52.635826  [19010/25000]\n",
      "loss: 206.005112  [20010/25000]\n",
      "loss: 197.026718  [21010/25000]\n",
      "loss: 177.313705  [22010/25000]\n",
      "loss: 235.113144  [23010/25000]\n",
      "loss: 205.059860  [24010/25000]\n",
      "accuracy: tensor(0.2026)\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 206.055786  [   10/25000]\n",
      "loss: 126.552429  [ 1010/25000]\n",
      "loss: 245.450729  [ 2010/25000]\n",
      "loss: 136.722366  [ 3010/25000]\n",
      "loss: 130.055359  [ 4010/25000]\n",
      "loss: 342.165314  [ 5010/25000]\n",
      "loss: 82.524139  [ 6010/25000]\n",
      "loss: 136.332504  [ 7010/25000]\n",
      "loss: 118.520500  [ 8010/25000]\n",
      "loss: 133.621399  [ 9010/25000]\n",
      "loss: 19.952257  [10010/25000]\n",
      "loss: 107.152267  [11010/25000]\n",
      "loss: 116.198555  [12010/25000]\n",
      "loss: 204.481659  [13010/25000]\n",
      "loss: 98.928787  [14010/25000]\n",
      "loss: 269.185852  [15010/25000]\n",
      "loss: 114.338943  [16010/25000]\n",
      "loss: 195.150925  [17010/25000]\n",
      "loss: 82.461151  [18010/25000]\n",
      "loss: 52.624760  [19010/25000]\n",
      "loss: 206.009949  [20010/25000]\n",
      "loss: 197.030258  [21010/25000]\n",
      "loss: 177.303558  [22010/25000]\n",
      "loss: 235.102966  [23010/25000]\n",
      "loss: 205.053238  [24010/25000]\n",
      "accuracy: tensor(0.2026)\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 206.051987  [   10/25000]\n",
      "loss: 126.542610  [ 1010/25000]\n",
      "loss: 245.437210  [ 2010/25000]\n",
      "loss: 136.719757  [ 3010/25000]\n",
      "loss: 130.045303  [ 4010/25000]\n",
      "loss: 342.152374  [ 5010/25000]\n",
      "loss: 82.512268  [ 6010/25000]\n",
      "loss: 136.325302  [ 7010/25000]\n",
      "loss: 118.513031  [ 8010/25000]\n",
      "loss: 133.607437  [ 9010/25000]\n",
      "loss: 19.949659  [10010/25000]\n",
      "loss: 107.146202  [11010/25000]\n",
      "loss: 116.184219  [12010/25000]\n",
      "loss: 204.465424  [13010/25000]\n",
      "loss: 98.929558  [14010/25000]\n",
      "loss: 269.180786  [15010/25000]\n",
      "loss: 114.333260  [16010/25000]\n",
      "loss: 195.147064  [17010/25000]\n",
      "loss: 82.450928  [18010/25000]\n",
      "loss: 52.613617  [19010/25000]\n",
      "loss: 206.013977  [20010/25000]\n",
      "loss: 197.033401  [21010/25000]\n",
      "loss: 177.293320  [22010/25000]\n",
      "loss: 235.092728  [23010/25000]\n",
      "loss: 205.046692  [24010/25000]\n",
      "accuracy: tensor(0.2025)\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 206.048157  [   10/25000]\n",
      "loss: 126.532860  [ 1010/25000]\n",
      "loss: 245.423737  [ 2010/25000]\n",
      "loss: 136.716705  [ 3010/25000]\n",
      "loss: 130.035599  [ 4010/25000]\n",
      "loss: 342.139618  [ 5010/25000]\n",
      "loss: 82.500488  [ 6010/25000]\n",
      "loss: 136.318176  [ 7010/25000]\n",
      "loss: 118.505569  [ 8010/25000]\n",
      "loss: 133.593613  [ 9010/25000]\n",
      "loss: 19.946823  [10010/25000]\n",
      "loss: 107.140236  [11010/25000]\n",
      "loss: 116.169876  [12010/25000]\n",
      "loss: 204.449371  [13010/25000]\n",
      "loss: 98.930061  [14010/25000]\n",
      "loss: 269.175690  [15010/25000]\n",
      "loss: 114.327530  [16010/25000]\n",
      "loss: 195.143280  [17010/25000]\n",
      "loss: 82.440918  [18010/25000]\n",
      "loss: 52.602623  [19010/25000]\n",
      "loss: 206.018692  [20010/25000]\n",
      "loss: 197.036835  [21010/25000]\n",
      "loss: 177.283051  [22010/25000]\n",
      "loss: 235.082504  [23010/25000]\n",
      "loss: 205.040161  [24010/25000]\n",
      "accuracy: tensor(0.2024)\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 206.044220  [   10/25000]\n",
      "loss: 126.523087  [ 1010/25000]\n",
      "loss: 245.410248  [ 2010/25000]\n",
      "loss: 136.713959  [ 3010/25000]\n",
      "loss: 130.025681  [ 4010/25000]\n",
      "loss: 342.126801  [ 5010/25000]\n",
      "loss: 82.488701  [ 6010/25000]\n",
      "loss: 136.311035  [ 7010/25000]\n",
      "loss: 118.498123  [ 8010/25000]\n",
      "loss: 133.579544  [ 9010/25000]\n",
      "loss: 19.944117  [10010/25000]\n",
      "loss: 107.134178  [11010/25000]\n",
      "loss: 116.155579  [12010/25000]\n",
      "loss: 204.433060  [13010/25000]\n",
      "loss: 98.930901  [14010/25000]\n",
      "loss: 269.170502  [15010/25000]\n",
      "loss: 114.321953  [16010/25000]\n",
      "loss: 195.139496  [17010/25000]\n",
      "loss: 82.430634  [18010/25000]\n",
      "loss: 52.591537  [19010/25000]\n",
      "loss: 206.022675  [20010/25000]\n",
      "loss: 197.040543  [21010/25000]\n",
      "loss: 177.272873  [22010/25000]\n",
      "loss: 235.071991  [23010/25000]\n",
      "loss: 205.033600  [24010/25000]\n",
      "accuracy: tensor(0.2024)\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 206.040344  [   10/25000]\n",
      "loss: 126.513290  [ 1010/25000]\n",
      "loss: 245.396851  [ 2010/25000]\n",
      "loss: 136.711121  [ 3010/25000]\n",
      "loss: 130.015778  [ 4010/25000]\n",
      "loss: 342.113861  [ 5010/25000]\n",
      "loss: 82.476852  [ 6010/25000]\n",
      "loss: 136.303970  [ 7010/25000]\n",
      "loss: 118.490730  [ 8010/25000]\n",
      "loss: 133.565414  [ 9010/25000]\n",
      "loss: 19.941441  [10010/25000]\n",
      "loss: 107.128197  [11010/25000]\n",
      "loss: 116.141464  [12010/25000]\n",
      "loss: 204.417068  [13010/25000]\n",
      "loss: 98.931496  [14010/25000]\n",
      "loss: 269.165344  [15010/25000]\n",
      "loss: 114.316231  [16010/25000]\n",
      "loss: 195.135742  [17010/25000]\n",
      "loss: 82.420517  [18010/25000]\n",
      "loss: 52.580528  [19010/25000]\n",
      "loss: 206.027496  [20010/25000]\n",
      "loss: 197.044067  [21010/25000]\n",
      "loss: 177.262711  [22010/25000]\n",
      "loss: 235.061874  [23010/25000]\n",
      "loss: 205.027069  [24010/25000]\n",
      "accuracy: tensor(0.2023)\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 206.036743  [   10/25000]\n",
      "loss: 126.503494  [ 1010/25000]\n",
      "loss: 245.383377  [ 2010/25000]\n",
      "loss: 136.707855  [ 3010/25000]\n",
      "loss: 130.005737  [ 4010/25000]\n",
      "loss: 342.101013  [ 5010/25000]\n",
      "loss: 82.465096  [ 6010/25000]\n",
      "loss: 136.296814  [ 7010/25000]\n",
      "loss: 118.483322  [ 8010/25000]\n",
      "loss: 133.551636  [ 9010/25000]\n",
      "loss: 19.938654  [10010/25000]\n",
      "loss: 107.122070  [11010/25000]\n",
      "loss: 116.127159  [12010/25000]\n",
      "loss: 204.400726  [13010/25000]\n",
      "loss: 98.932137  [14010/25000]\n",
      "loss: 269.160156  [15010/25000]\n",
      "loss: 114.310471  [16010/25000]\n",
      "loss: 195.131927  [17010/25000]\n",
      "loss: 82.410393  [18010/25000]\n",
      "loss: 52.569469  [19010/25000]\n",
      "loss: 206.031403  [20010/25000]\n",
      "loss: 197.047150  [21010/25000]\n",
      "loss: 177.252533  [22010/25000]\n",
      "loss: 235.051682  [23010/25000]\n",
      "loss: 205.020523  [24010/25000]\n",
      "accuracy: tensor(0.2023)\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 206.032730  [   10/25000]\n",
      "loss: 126.493797  [ 1010/25000]\n",
      "loss: 245.369995  [ 2010/25000]\n",
      "loss: 136.705276  [ 3010/25000]\n",
      "loss: 129.995972  [ 4010/25000]\n",
      "loss: 342.088287  [ 5010/25000]\n",
      "loss: 82.453476  [ 6010/25000]\n",
      "loss: 136.289856  [ 7010/25000]\n",
      "loss: 118.475906  [ 8010/25000]\n",
      "loss: 133.537857  [ 9010/25000]\n",
      "loss: 19.936121  [10010/25000]\n",
      "loss: 107.116074  [11010/25000]\n",
      "loss: 116.113068  [12010/25000]\n",
      "loss: 204.384827  [13010/25000]\n",
      "loss: 98.932823  [14010/25000]\n",
      "loss: 269.155029  [15010/25000]\n",
      "loss: 114.304832  [16010/25000]\n",
      "loss: 195.128128  [17010/25000]\n",
      "loss: 82.400238  [18010/25000]\n",
      "loss: 52.558475  [19010/25000]\n",
      "loss: 206.036316  [20010/25000]\n",
      "loss: 197.050766  [21010/25000]\n",
      "loss: 177.242447  [22010/25000]\n",
      "loss: 235.041550  [23010/25000]\n",
      "loss: 205.014023  [24010/25000]\n",
      "accuracy: tensor(0.2022)\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 206.029037  [   10/25000]\n",
      "loss: 126.484024  [ 1010/25000]\n",
      "loss: 245.356598  [ 2010/25000]\n",
      "loss: 136.702637  [ 3010/25000]\n",
      "loss: 129.986328  [ 4010/25000]\n",
      "loss: 342.075470  [ 5010/25000]\n",
      "loss: 82.441818  [ 6010/25000]\n",
      "loss: 136.282623  [ 7010/25000]\n",
      "loss: 118.468475  [ 8010/25000]\n",
      "loss: 133.524124  [ 9010/25000]\n",
      "loss: 19.933264  [10010/25000]\n",
      "loss: 107.110069  [11010/25000]\n",
      "loss: 116.098885  [12010/25000]\n",
      "loss: 204.368454  [13010/25000]\n",
      "loss: 98.933250  [14010/25000]\n",
      "loss: 269.149933  [15010/25000]\n",
      "loss: 114.299255  [16010/25000]\n",
      "loss: 195.124298  [17010/25000]\n",
      "loss: 82.390175  [18010/25000]\n",
      "loss: 52.547516  [19010/25000]\n",
      "loss: 206.040329  [20010/25000]\n",
      "loss: 197.054062  [21010/25000]\n",
      "loss: 177.232300  [22010/25000]\n",
      "loss: 235.031479  [23010/25000]\n",
      "loss: 205.007477  [24010/25000]\n",
      "accuracy: tensor(0.2021)\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 206.025314  [   10/25000]\n",
      "loss: 126.474304  [ 1010/25000]\n",
      "loss: 245.343246  [ 2010/25000]\n",
      "loss: 136.699646  [ 3010/25000]\n",
      "loss: 129.976410  [ 4010/25000]\n",
      "loss: 342.062683  [ 5010/25000]\n",
      "loss: 82.429932  [ 6010/25000]\n",
      "loss: 136.275665  [ 7010/25000]\n",
      "loss: 118.461113  [ 8010/25000]\n",
      "loss: 133.510178  [ 9010/25000]\n",
      "loss: 19.930527  [10010/25000]\n",
      "loss: 107.104004  [11010/25000]\n",
      "loss: 116.084473  [12010/25000]\n",
      "loss: 204.352600  [13010/25000]\n",
      "loss: 98.933968  [14010/25000]\n",
      "loss: 269.144745  [15010/25000]\n",
      "loss: 114.293610  [16010/25000]\n",
      "loss: 195.120590  [17010/25000]\n",
      "loss: 82.380081  [18010/25000]\n",
      "loss: 52.536484  [19010/25000]\n",
      "loss: 206.044724  [20010/25000]\n",
      "loss: 197.057541  [21010/25000]\n",
      "loss: 177.222183  [22010/25000]\n",
      "loss: 235.021210  [23010/25000]\n",
      "loss: 205.000977  [24010/25000]\n",
      "accuracy: tensor(0.2021)\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 206.021744  [   10/25000]\n",
      "loss: 126.464592  [ 1010/25000]\n",
      "loss: 245.329895  [ 2010/25000]\n",
      "loss: 136.696899  [ 3010/25000]\n",
      "loss: 129.966873  [ 4010/25000]\n",
      "loss: 342.049927  [ 5010/25000]\n",
      "loss: 82.418327  [ 6010/25000]\n",
      "loss: 136.268417  [ 7010/25000]\n",
      "loss: 118.453712  [ 8010/25000]\n",
      "loss: 133.496292  [ 9010/25000]\n",
      "loss: 19.927944  [10010/25000]\n",
      "loss: 107.097969  [11010/25000]\n",
      "loss: 116.070351  [12010/25000]\n",
      "loss: 204.336502  [13010/25000]\n",
      "loss: 98.934616  [14010/25000]\n",
      "loss: 269.139740  [15010/25000]\n",
      "loss: 114.287888  [16010/25000]\n",
      "loss: 195.116760  [17010/25000]\n",
      "loss: 82.370018  [18010/25000]\n",
      "loss: 52.525578  [19010/25000]\n",
      "loss: 206.049408  [20010/25000]\n",
      "loss: 197.060822  [21010/25000]\n",
      "loss: 177.212051  [22010/25000]\n",
      "loss: 235.011108  [23010/25000]\n",
      "loss: 204.994492  [24010/25000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     train(train_dataloader, model, loss_fn, optimizer)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[1;32m      7\u001b[0m all_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cvf/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/cvf/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/cvf/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/cvf/lib/python3.12/site-packages/torch/utils/data/dataset.py:208\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    204\u001b[0m         tensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors\n\u001b[1;32m    205\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4883a7a-5fcd-4f9d-afce-a75240beecee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
